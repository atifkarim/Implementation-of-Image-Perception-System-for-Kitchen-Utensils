{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import io, color, exposure, transform\n",
    "from skimage.color import rgb2gray\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split  #it came from update scikit learn. https://stackoverflow.com/questions/40704484/importerror-no-module-named-model-selection\n",
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "import keras\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D,Conv1D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_first')\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "from matplotlib.pylab import rcParams\n",
    "\n",
    "#import keras\n",
    "\n",
    "NUM_CLASSES = 19 # change it with respect to the desired class\n",
    "IMG_SIZE = 197 # change it if it desired\n",
    "IMG_depth = 3 # for RGB 3, for B&W it will be 1\n",
    "\n",
    "from keras.applications import VGG19, MobileNet, ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current time: 2019-10-29 11:26:48\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "current_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(\"current time:\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_img(img):\n",
    "    # Histogram normalization in y\n",
    "    hsv = color.rgb2hsv(img)\n",
    "    hsv[:,:,2] = exposure.equalize_hist(hsv[:,:,2])\n",
    "    img = color.hsv2rgb(hsv)\n",
    "\n",
    "    # central scrop\n",
    "    min_side = min(img.shape[:-1])\n",
    "    centre = img.shape[0]//2, img.shape[1]//2\n",
    "    img = img[centre[0]-min_side//2:centre[0]+min_side//2,centre[1]-min_side//2:centre[1]+min_side//2,:]\n",
    "#    img = rgb2gray(img)\n",
    "\n",
    "    # rescale to standard size\n",
    "    img = transform.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "    # roll color axis to axis 0\n",
    "    img = np.rollaxis(img,-1) #this line is doing the channel first operation\n",
    "\n",
    "    return img\n",
    "\n",
    "def get_class(img_path):\n",
    "    return int(img_path.split('/')[-2])\n",
    "#     return str(img_path.split('/')[-2]) # returning the folder name. If use -1 that means image name. consider the img_path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/atif/machine_learning_stuff/model_file_keras/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet50_base = ResNet50(include_top=False, weights='imagenet', input_tensor=None, input_shape=(IMG_depth,IMG_SIZE,IMG_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1200/61560\n",
      "Processed 2400/61560\n",
      "Processed 3600/61560\n",
      "Processed 4800/61560\n",
      "Processed 6000/61560\n",
      "Processed 7200/61560\n",
      "Processed 8400/61560\n",
      "Processed 9600/61560\n",
      "Processed 10800/61560\n",
      "Processed 12000/61560\n",
      "Processed 13200/61560\n",
      "Processed 14400/61560\n",
      "Processed 15600/61560\n",
      "Processed 16800/61560\n",
      "Processed 18000/61560\n",
      "Processed 19200/61560\n",
      "Processed 20400/61560\n",
      "Processed 21600/61560\n",
      "Processed 22800/61560\n",
      "Processed 24000/61560\n",
      "Processed 25200/61560\n",
      "Processed 26400/61560\n",
      "Processed 27600/61560\n",
      "Processed 28800/61560\n",
      "Processed 30000/61560\n",
      "Processed 31200/61560\n",
      "Processed 32400/61560\n",
      "Processed 33600/61560\n",
      "Processed 34800/61560\n",
      "Processed 36000/61560\n",
      "Processed 37200/61560\n",
      "Processed 38400/61560\n",
      "Processed 39600/61560\n",
      "Processed 40800/61560\n",
      "Processed 42000/61560\n",
      "Processed 43200/61560\n",
      "Processed 44400/61560\n",
      "Processed 45600/61560\n",
      "Processed 46800/61560\n",
      "Processed 48000/61560\n",
      "Processed 49200/61560\n",
      "Processed 50400/61560\n",
      "Processed 51600/61560\n"
     ]
    }
   ],
   "source": [
    "imgs = []\n",
    "labels = []\n",
    "root_dir = '/home/atif/machine_learning_stuff/ml_image/train_image_classification_better_resolution/crop/'\n",
    "#path='/home/atif/training_by_several_learning_process/flower_photos/00000/'\n",
    "\n",
    "#all_img_paths = glob.glob(path+ '5547758_eea9edfd54_n_000.jpg')\n",
    "\n",
    "all_img_paths = glob.glob(os.path.join(root_dir, '*/*')) #I have done the training with .png format image. If another type of image will come \n",
    "                                                                                    #them .png will be changed by that extension\n",
    "np.random.shuffle(all_img_paths)\n",
    "for img_path in all_img_paths:\n",
    "    try:\n",
    "        img = preprocess_img(io.imread(img_path))\n",
    "        label = get_class(img_path)\n",
    "        imgs.append(img)\n",
    "        labels.append(label)\n",
    "\n",
    "        if len(imgs)%1200 == 0: print(\"Processed {}/{}\".format(len(imgs), len(all_img_paths)))\n",
    "            #print(\"get it 2\")\n",
    "    except (IOError, OSError):\n",
    "        print('missed', img_path)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(imgs, dtype='float32') #Keeping the image as an array\n",
    "X = X.reshape(len(imgs),IMG_depth,IMG_SIZE,IMG_SIZE) # write (IMG_SIZE,IMG_SIZE,1 if you want channel last; 1= grayscale;3=RGB)\n",
    "# Y = np.eye(NUM_CLASSES, dtype='uint8')[labels]\n",
    "Y = keras.utils.to_categorical(labels, NUM_CLASSES)\n",
    "\n",
    "print('X shape: ', X.shape,' type: ',type(X))\n",
    "print('Y shape: ', Y.shape,' type: ',type(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base_1 = VGG19(weights='imagenet', include_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv_base = VGG19(weights='imagenet', include_top=False, input_shape=(3,48,48))\n",
    "\n",
    "# pre_trained_weight = VGG19(weights=path+'vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5',include_top=False, input_shape=(IMG_depth,IMG_SIZE,IMG_SIZE))\n",
    "\n",
    "pre_trained_weight = ResNet50(weights=path+'resnet/'+'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5',include_top=False, input_shape=(IMG_depth,IMG_SIZE,IMG_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if want to download weight file\n",
    "\n",
    "# from keras.applications import InceptionResNetV2\n",
    "\n",
    "# conv_base = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(48,48,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from keras.applications import InceptionResNetV2\n",
    "\n",
    "# conv_base = InceptionResNetV2(weights='/home/atif/machine_learning_stuff/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "#                               include_top=False, input_shape=(3,150,150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.topology.InputLayer object at 0x7f08bf0def28> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f08bf0dec18> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f08bf0de710> False\n",
      "<keras.layers.core.Activation object at 0x7f08bfb156a0> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f08bfb28c18> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f08bf0d3978> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f08bfb34b00> False\n",
      "<keras.layers.core.Activation object at 0x7f08bf672630> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f08bf4beda0> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f08bf206e10> False\n",
      "<keras.layers.core.Activation object at 0x7f08bf8ecf98> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f08bf8503c8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f08bf1cf898> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f08bf5e2710> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f08bfbc4668> False\n",
      "<keras.layers.merge.Add object at 0x7f08beff9630> False\n",
      "<keras.layers.core.Activation object at 0x7f08befa1f60> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f08befa1eb8> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f08bef547f0> False\n",
      "<keras.layers.core.Activation object at 0x7f08bef28cf8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f08beefde80> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f08beef5f60> False\n",
      "<keras.layers.core.Activation object at 0x7f08bee43ef0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f08bee2f5c0> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f08bedc1908> False\n",
      "<keras.layers.merge.Add object at 0x7f08bed94b70> False\n",
      "<keras.layers.core.Activation object at 0x7f08bed66860> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f08bed73d68> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f08bed73828> False\n",
      "<keras.layers.core.Activation object at 0x7f08becc2f28> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f08bc454240> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f08bceefb70> False\n",
      "<keras.layers.core.Activation object at 0x7f08bcec9eb8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f08bfa597b8> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f08bc426c88> False\n",
      "<keras.layers.merge.Add object at 0x7f08bc42f7f0> False\n",
      "<keras.layers.core.Activation object at 0x7f08bfd5f780> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f08bc4b41d0> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f08bc4b4eb8> False\n",
      "<keras.layers.core.Activation object at 0x7f08bc48ca58> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f08bc4d8518> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f08bc4c22e8> False\n",
      "<keras.layers.core.Activation object at 0x7f08bc52ea58> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f08bc4fb780> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f08bc54fac8> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f08bc565320> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f08bc5a7780> False\n",
      "<keras.layers.merge.Add object at 0x7f08bc57f048> False\n",
      "<keras.layers.core.Activation object at 0x7f08bc5e0a58> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f08bc5e0e10> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f08bc5ca278> False\n",
      "<keras.layers.core.Activation object at 0x7f08bc62ab70> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f08bc66e860> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f08bc64e080> False\n",
      "<keras.layers.core.Activation object at 0x7f08bc63a400> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f08bc691940> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f08bc6f3048> False\n",
      "<keras.layers.merge.Add object at 0x7f08bc6ddbe0> False\n",
      "<keras.layers.core.Activation object at 0x7f08bc7349e8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f08bc72b1d0> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f08bc72bb70> False\n",
      "<keras.layers.core.Activation object at 0x7f08bc700f28> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f08bc757898> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f08bc73ab00> False\n",
      "<keras.layers.core.Activation object at 0x7f08bc7a31d0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f08bc779940> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f08bc7dd160> False\n",
      "<keras.layers.merge.Add object at 0x7f08bc7c75f8> False\n",
      "<keras.layers.core.Activation object at 0x7f08bc81cba8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f08bc813438> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f08bc813e10> False\n",
      "<keras.layers.core.Activation object at 0x7f08bc86bac8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f08bc840828> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f08bc8a00f0> False\n",
      "<keras.layers.core.Activation object at 0x7f08bc88b0b8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f08bc8e2550> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f08bc8c4048> False\n",
      "<keras.layers.merge.Add object at 0x7f08bc92dc18> False\n",
      "<keras.layers.core.Activation object at 0x7f08bc905b00> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f08bc8fb390> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f08bc8fba90> False\n",
      "<keras.layers.core.Activation object at 0x7f08bc9518d0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f08bc9a9780> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f08bc98b080> False\n",
      "<keras.layers.core.Activation object at 0x7f08bc9f60b8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f08bc9cc7f0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f08bca18240> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f08bca2b048> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f08bca6fa58> False\n",
      "<keras.layers.merge.Add object at 0x7f08bca45438> False\n",
      "<keras.layers.core.Activation object at 0x7f08bcaa74a8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f08bcaa76a0> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f08bca905f8> False\n",
      "<keras.layers.core.Activation object at 0x7f08bcaf3c18> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f08bcb339b0> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f08bcb167f0> False\n",
      "<keras.layers.core.Activation object at 0x7f08bcb024e0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f08bcb57a58> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f08bcb391d0> False\n",
      "<keras.layers.merge.Add object at 0x7f08bcba5da0> False\n",
      "<keras.layers.core.Activation object at 0x7f08bcb7acc0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f08bcbf0470> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f08bcbf0d68> False\n",
      "<keras.layers.core.Activation object at 0x7f08bcbc7fd0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f08bcc1b940> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f08bcbfe240> False\n",
      "<keras.layers.core.Activation object at 0x7f08bcc69c50> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f08bcc40550> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f08bcca3160> False\n",
      "<keras.layers.merge.Add object at 0x7f08bcc8ecf8> False\n",
      "<keras.layers.core.Activation object at 0x7f08bcce2b70> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f08bccd82b0> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f08bccd8c18> False\n",
      "<keras.layers.core.Activation object at 0x7f08bcd32d30> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f08bcd048d0> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f08bcd691d0> False\n",
      "<keras.layers.core.Activation object at 0x7f08bcd54358> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f08bcda9978> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f08bcd95518> False\n",
      "<keras.layers.merge.Add object at 0x7f08bcde3cc0> False\n",
      "<keras.layers.core.Activation object at 0x7f08bcdf7630> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f08bcded438> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f08bcdeda90> False\n",
      "<keras.layers.core.Activation object at 0x7f08bce25198> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f08bcdfc908> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f08bdd39978> False\n",
      "<keras.layers.core.Activation object at 0x7f08bdcdf7f0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f08bdcae908> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f08bdc74d30> False\n",
      "<keras.layers.merge.Add object at 0x7f08bdc12e10> False\n",
      "<keras.layers.core.Activation object at 0x7f08bdbeee80> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f08bdbeecc0> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f08bdb83ba8> False\n",
      "<keras.layers.core.Activation object at 0x7f08bdb6f9e8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f08bdb336a0> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f08bdafcc88> False\n",
      "<keras.layers.core.Activation object at 0x7f08bda9bba8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f08bda71c18> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f08bda33f60> False\n",
      "<keras.layers.merge.Add object at 0x7f08bd9f6390> False\n",
      "<keras.layers.core.Activation object at 0x7f08bd9b4f60> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f08bd9b4f98> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f08bd950eb8> False\n",
      "<keras.layers.core.Activation object at 0x7f08bd92a630> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f08bd8f89b0> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f08bd8bde80> False\n",
      "<keras.layers.core.Activation object at 0x7f08bd85bf28> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f08bd7c7d30> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f08bd7b6f60> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f08bd7f6e10> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f08bd701320> False\n",
      "<keras.layers.merge.Add object at 0x7f08bd6eb358> False\n",
      "<keras.layers.core.Activation object at 0x7f08bd6a2cf8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f08bd6a2eb8> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f08bd656da0> False\n",
      "<keras.layers.core.Activation object at 0x7f08bd630518> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f08bd588e10> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f08bd5fde48> False\n",
      "<keras.layers.core.Activation object at 0x7f08bd577588> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f08bd4c15c0> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f08bd48aba8> False\n",
      "<keras.layers.merge.Add object at 0x7f08bd4abac8> False\n",
      "<keras.layers.core.Activation object at 0x7f08bd47f978> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f08bd425780> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f08bd3ddb38> False\n",
      "<keras.layers.core.Activation object at 0x7f08bd3890b8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f08bd341f60> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f08bd311940> False\n",
      "<keras.layers.core.Activation object at 0x7f08bd3387b8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f08bd2868d0> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f08bd24bcf8> True\n",
      "<keras.layers.merge.Add object at 0x7f08bd26be10> True\n",
      "<keras.layers.core.Activation object at 0x7f08bc37ee48> True\n",
      "<keras.layers.pooling.AveragePooling2D object at 0x7f08bc37ec88> True\n"
     ]
    }
   ],
   "source": [
    "for layer in pre_trained_weight.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "# Check the trainable status of the individual layers\n",
    "for layer in pre_trained_weight.layers:\n",
    "    print(layer, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pre_trained_weight.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(pre_trained_weight)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/atif/tf_gpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "model = cnn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 2048, 1, 1)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              8392704   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 19)                77843     \n",
      "=================================================================\n",
      "Total params: 32,058,259\n",
      "Trainable params: 8,474,643\n",
      "Non-trainable params: 23,583,616\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Number of trainable weights before freezing the conv base:', len(model.trainable_weights))\n",
    "# conv_base.trainable = False\n",
    "# print('Number of trainable weights after freezing the conv base:', len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "sgd = SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "          optimizer=sgd,\n",
    "          metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    return lr * (0.1 ** int(epoch / 10))\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "do_train_model=model.fit(X, Y,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2,verbose=2,\n",
    "          #np.resize(img, (-1, <image shape>)\n",
    "          callbacks=[LearningRateScheduler(lr_schedule),ModelCheckpoint(path+str(current_time)+'_vgg19_epoch_'+str(epochs)+'.h5', save_best_only=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4%2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "8\n",
      "10\n",
      "12\n",
      "13\n",
      "15\n",
      "20\n",
      "24\n",
      "26\n",
      "30\n",
      "37\n",
      "39\n",
      "40\n",
      "52\n",
      "60\n",
      "65\n",
      "74\n",
      "78\n",
      "104\n",
      "111\n",
      "120\n",
      "130\n",
      "148\n",
      "156\n",
      "185\n",
      "195\n",
      "222\n",
      "260\n",
      "296\n",
      "312\n",
      "370\n",
      "390\n",
      "444\n",
      "481\n",
      "520\n",
      "555\n",
      "740\n",
      "780\n",
      "888\n",
      "962\n",
      "1110\n",
      "1443\n",
      "1480\n",
      "1560\n",
      "1924\n",
      "2220\n",
      "2405\n",
      "2886\n",
      "3848\n",
      "4440\n",
      "4810\n",
      "5772\n",
      "7215\n",
      "9620\n",
      "11544\n",
      "14430\n",
      "19240\n",
      "28860\n",
      "57720\n"
     ]
    }
   ],
   "source": [
    "x = 57720\n",
    "\n",
    "for i in range(1,x+1):\n",
    "    if x%i == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
