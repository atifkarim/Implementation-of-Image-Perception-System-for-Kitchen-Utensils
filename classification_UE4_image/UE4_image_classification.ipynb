{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook code for image preprocessing, raining and testing(image by image and overall accuracy) of UE4 image will be developed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/atif/tf_gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/atif/tf_gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/atif/tf_gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/atif/tf_gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/atif/tf_gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/atif/tf_gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from skimage import io, color, exposure, transform\n",
    "from skimage.color import rgb2gray\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split  #it came from update scikit learn. https://stackoverflow.com/questions/40704484/importerror-no-module-named-model-selection\n",
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "import keras\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D,Conv1D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_first')\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "from matplotlib.pylab import rcParams\n",
    "\n",
    "#import keras\n",
    "\n",
    "NUM_CLASSES = 16 # change it with respect to the desired class\n",
    "IMG_SIZE = 48 # change it if it desired\n",
    "IMG_depth = 3 # for RGB 3, for B&W it will be 1\n",
    "from keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5py.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_img(img):\n",
    "    # Histogram normalization in y\n",
    "    hsv = color.rgb2hsv(img)\n",
    "    hsv[:,:,2] = exposure.equalize_hist(hsv[:,:,2])\n",
    "    img = color.hsv2rgb(hsv)\n",
    "\n",
    "    # central scrop\n",
    "    min_side = min(img.shape[:-1])\n",
    "    centre = img.shape[0]//2, img.shape[1]//2\n",
    "    img = img[centre[0]-min_side//2:centre[0]+min_side//2,centre[1]-min_side//2:centre[1]+min_side//2,:]\n",
    "#    img = rgb2gray(img)\n",
    "\n",
    "    # rescale to standard size\n",
    "    img = transform.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "    # roll color axis to axis 0\n",
    "    img = np.rollaxis(img,-1) # this lin is doing the channel fisrt operation\n",
    "\n",
    "    return img\n",
    "\n",
    "def get_class(img_path):\n",
    "    return int(img_path.split('/')[-2])\n",
    "#     return str(img_path.split('/')[-2]) # returning the folder name. If use -1 that means image name. consider the img_path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imgs = []\n",
    "labels = []\n",
    "root_dir = '/home/atif/machine_learning_stuff/ml_image/train_image_AI/'\n",
    "#path='/home/atif/training_by_several_learning_process/flower_photos/00000/'\n",
    "\n",
    "#all_img_paths = glob.glob(path+ '5547758_eea9edfd54_n_000.jpg')\n",
    "\n",
    "all_img_paths = glob.glob(os.path.join(root_dir, '*/*.png')) #I have done the training with .png format image. If another type of image will come \n",
    "                                                                                    #them .png will be changed by that extension\n",
    "np.random.shuffle(all_img_paths)\n",
    "for img_path in all_img_paths:\n",
    "    try:\n",
    "        img = preprocess_img(io.imread(img_path))\n",
    "        label = get_class(img_path)\n",
    "        imgs.append(img)\n",
    "        labels.append(label)\n",
    "\n",
    "        if len(imgs)%1200 == 0: print(\"Processed {}/{}\".format(len(imgs), len(all_img_paths)))\n",
    "            #print(\"get it 2\")\n",
    "    except (IOError, OSError):\n",
    "        print('missed', img_path)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = np.array(imgs, dtype='float32') #Keeping the image as an array\n",
    "X = X.reshape(len(imgs),IMG_depth,IMG_SIZE,IMG_SIZE) # write (IMG_SIZE,IMG_SIZE,1 if you want channel last; 1= grayscale;3=RGB)\n",
    "# Y = np.eye(NUM_CLASSES, dtype='uint8')[labels]\n",
    "Y = keras.utils.to_categorical(labels, NUM_CLASSES)\n",
    "\n",
    "print('X shape: ', X.shape,' type: ',type(X))\n",
    "print('Y shape: ', Y.shape,' type: ',type(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                     input_shape=(3, IMG_SIZE, IMG_SIZE),\n",
    "                     activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3), padding='same',\n",
    "                     input_shape=(3, IMG_SIZE, IMG_SIZE),\n",
    "                     activation='relu'))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same',\n",
    "                     activation='relu'))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same',\n",
    "                     activation='relu'))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(2048, activation='relu'))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "model = cnn_model()\n",
    "\n",
    "lr = 0.01\n",
    "sgd = SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "          optimizer=sgd,\n",
    "          metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cnn_model():\n",
    "#     model = Sequential()\n",
    "\n",
    "#     model.add(Conv2D(64, (3, 3), padding='same',\n",
    "#                      input_shape=(3, IMG_SIZE, IMG_SIZE),\n",
    "#                      activation='relu'))\n",
    "#     model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#     model.add(Dropout(0.2))\n",
    "    \n",
    "#     model.add(Conv2D(256, (3, 3), padding='same',\n",
    "#                      input_shape=(3, IMG_SIZE, IMG_SIZE),\n",
    "#                      activation='relu'))\n",
    "#     model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#     model.add(Dropout(0.2))\n",
    "\n",
    "#     model.add(Conv2D(1024, (3, 3), padding='same',\n",
    "#                      activation='relu'))\n",
    "#     model.add(Conv2D(1024, (3, 3), activation='relu'))\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#     model.add(Dropout(0.2))\n",
    "\n",
    "#     model.add(Conv2D(2048, (3, 3), padding='same',\n",
    "#                      activation='relu'))\n",
    "#     model.add(Conv2D(2048, (3, 3), activation='relu'))\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#     model.add(Dropout(0.2))\n",
    "\n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dense(4096, activation='relu'))\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "#     return model\n",
    "\n",
    "# model = cnn_model()\n",
    "\n",
    "# lr = 0.01\n",
    "# sgd = SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# model.compile(loss='categorical_crossentropy',\n",
    "#           optimizer=sgd,\n",
    "#           metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/atif/machine_learning_stuff/model_file_keras/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "current_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(\"current time:\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    return lr * (0.1 ** int(epoch / 10))\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 2\n",
    "do_train_model=model.fit(X, Y,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2,verbose=2,\n",
    "          #np.resize(img, (-1, <image shape>)\n",
    "          callbacks=[LearningRateScheduler(lr_schedule),ModelCheckpoint(path+str(current_time)+'_new_model_epoch_'+str(epochs)+'.h5', save_best_only=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(do_train_model.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(do_train_model.history['acc'], '-o', color = 'red')\n",
    "plt.plot(do_train_model.history['val_acc'],'-^', color = 'green')\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_accuracy', 'validation_accuracy'], loc='best')\n",
    "plt.rcParams['figure.figsize'] =(20,10)\n",
    "plt.savefig(path+str(current_time)+'_epoch_vs_accuracy.jpg')\n",
    "# plt.show()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "print(do_train_model.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(do_train_model.history['loss'],'-o', color = 'red')\n",
    "plt.plot(do_train_model.history['val_loss'],'-^', color = 'green')\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_loss', 'validation_loss'], loc='best')\n",
    "plt.savefig(path+str(current_time)+'_epoch_vs_loss.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/atif/tf_gpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/atif/tf_gpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2885: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/atif/tf_gpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1349: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "# model = load_model('/home/atif/machine_learning_stuff/model_file_keras/general_2_sep_ep_30_epoch.h5')\n",
    "model = load_model(path+'2019-09-20 10:46:46_new_model_epoch_2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check total accuracy of the model using all test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename:  denkmit_edelstahk_reiniger (1).jpg \t classId:  5\n",
      "filename:  denkmit_edelstahk_reiniger (2).jpg \t classId:  5\n",
      "filename:  denkmit_edelstahk_reiniger (3).jpg \t classId:  5\n",
      "filename:  denkmit_edelstahk_reiniger (4).jpg \t classId:  5\n",
      "filename:  denkmit_edelstahk_reiniger (5).jpg \t classId:  5\n",
      "filename:  denkmit_edelstahk_reiniger (6).jpg \t classId:  5\n",
      "filename:  denkmit_edelstahk_reiniger (7).jpg \t classId:  5\n",
      "filename:  denkmit_Entkalker (1).jpg \t classId:  7\n",
      "filename:  denkmit_Entkalker (2).jpg \t classId:  7\n",
      "filename:  denkmit_Entkalker (3).jpg \t classId:  7\n",
      "filename:  denkmit_Entkalker (4).jpg \t classId:  7\n",
      "filename:  denkmit_Entkalker (5).jpg \t classId:  7\n",
      "filename:  denkmit_Entkalker (6).jpg \t classId:  7\n",
      "filename:  denkmit_geschirrreiniger_REVOLUTION (1).jpg \t classId:  10\n",
      "filename:  denkmit_geschirrreiniger_REVOLUTION (2).jpg \t classId:  10\n",
      "filename:  denkmit_geschirrreiniger_REVOLUTION (3).jpg \t classId:  10\n",
      "filename:  denkmit_geschirrreiniger_REVOLUTION (4).jpg \t classId:  10\n",
      "filename:  denkmit_geschirrreiniger_REVOLUTION (5).jpg \t classId:  10\n",
      "filename:  denkmit_geschirrreiniger_REVOLUTION (6).jpg \t classId:  10\n",
      "filename:  Denkmit_geschirr_reiniger_classic (1).jpg \t classId:  9\n",
      "filename:  Denkmit_geschirr_reiniger_classic (3).jpg \t classId:  9\n",
      "filename:  Denkmit_geschirr_reiniger_classic (4).jpg \t classId:  9\n",
      "filename:  Denkmit_geschirr_reiniger_classic (5).jpg \t classId:  9\n",
      "filename:  Denkmit_geschirr_reiniger_classic (6).jpg \t classId:  9\n",
      "filename:  denkmit_geschirr_reiniger_multipower (1).jpg \t classId:  8\n",
      "filename:  denkmit_geschirr_reiniger_multipower (2).jpg \t classId:  8\n",
      "filename:  denkmit_geschirr_reiniger_multipower (3).jpg \t classId:  8\n",
      "filename:  denkmit_geschirr_reiniger_multipower (4).jpg \t classId:  8\n",
      "filename:  denkmit_geschirr_reiniger_multipower (5).jpg \t classId:  8\n",
      "filename:  denkmit_geschirr_reiniger_multipower (6).jpg \t classId:  8\n",
      "filename:  denkmit_geschirr_reiniger_NATURE (1).jpg \t classId:  11\n",
      "filename:  denkmit_geschirr_reiniger_NATURE (2).jpg \t classId:  11\n",
      "filename:  denkmit_geschirr_reiniger_NATURE (3).jpg \t classId:  11\n",
      "filename:  denkmit_geschirr_reiniger_NATURE (4).jpg \t classId:  11\n",
      "filename:  denkmit_geschirr_reiniger_NATURE (5).jpg \t classId:  11\n",
      "filename:  calgonit_finish_speizalsalz (3).jpg \t classId:  3\n",
      "filename:  Denkmit_geschirr_reiniger_classic (2).jpg \t classId:  9\n",
      "filename:  denkmit_hygiene_Allzweck_reiniger (1).jpg \t classId:  12\n",
      "filename:  denkmit_spezalsalz (4).jpg \t classId:  14\n",
      "filename:  calgonit_finish_speizalsalz (4).jpg \t classId:  3\n",
      "filename:  calgonit_finish_speizalsalz (5).jpg \t classId:  3\n",
      "filename:  calgonit_finish_speizalsalz (6).jpg \t classId:  3\n",
      "filename:  calgonit_maschine_pfleger (1).jpg \t classId:  2\n",
      "filename:  calgonit_maschine_pfleger (2).jpg \t classId:  2\n",
      "filename:  calgonit_maschine_pfleger (3).jpg \t classId:  2\n",
      "filename:  calgonit_maschine_pfleger (4).jpg \t classId:  2\n",
      "filename:  calgonit_finish_classic (1).jpg \t classId:  0\n",
      "filename:  calgonit_finish_classic (2).jpg \t classId:  0\n",
      "filename:  calgonit_finish_classic (3).jpg \t classId:  0\n",
      "filename:  calgonit_finish_classic (4).jpg \t classId:  0\n",
      "filename:  calgonit_finish_classic (5).jpg \t classId:  0\n",
      "filename:  calgonit_finish_klarspueler (1).jpg \t classId:  1\n",
      "filename:  calgonit_finish_klarspueler (2).jpg \t classId:  1\n",
      "filename:  calgonit_finish_klarspueler (3).jpg \t classId:  1\n",
      "filename:  calgonit_finish_klarspueler (4).jpg \t classId:  1\n",
      "filename:  calgonit_finish_klarspueler (5).jpg \t classId:  1\n",
      "filename:  calgonit_finish_klarspueler (6).jpg \t classId:  1\n",
      "filename:  calgonit_finish_speizalsalz (1).jpg \t classId:  3\n",
      "filename:  calgonit_finish_speizalsalz (2).jpg \t classId:  3\n",
      "filename:  denkmit_spezalsalz (5).jpg \t classId:  14\n",
      "filename:  denkmit_spezalsalz (6).jpg \t classId:  14\n",
      "filename:  denkmit_spezalsalz (7).jpg \t classId:  14\n",
      "filename:  denkmit_spezalsalz (8).jpg \t classId:  14\n",
      "filename:  denkmit_spezalsalz (9).jpg \t classId:  14\n",
      "filename:  somat (1).jpg \t classId:  15\n",
      "filename:  somat (2).jpg \t classId:  15\n",
      "filename:  somat_3.jpg \t classId:  15\n",
      "filename:  somat_4.jpg \t classId:  15\n",
      "filename:  somat_5.jpg \t classId:  15\n",
      "filename:  somat_6.jpg \t classId:  15\n",
      "filename:  somat_7.jpg \t classId:  15\n",
      "filename:  somat_8.jpg \t classId:  15\n",
      "filename:  denkmit_hygiene_Allzweck_reiniger (2).jpg \t classId:  12\n",
      "filename:  denkmit_hygiene_Allzweck_reiniger (3).jpg \t classId:  12\n",
      "filename:  denkmit_hygiene_Allzweck_reiniger (4).jpg \t classId:  12\n",
      "filename:  denkmit_hygiene_Allzweck_reiniger (5).jpg \t classId:  12\n",
      "filename:  denkmit_mascine_pfleger (1).jpg \t classId:  13\n",
      "filename:  denkmit_mascine_pfleger (2).jpg \t classId:  13\n",
      "filename:  denkmit_mascine_pfleger (3).jpg \t classId:  13\n",
      "filename:  denkmit_mascine_pfleger (4).jpg \t classId:  13\n",
      "filename:  denkmit_mascine_pfleger (5).jpg \t classId:  13\n",
      "filename:  denkmit_mascine_pfleger (6).jpg \t classId:  13\n",
      "filename:  denkmit_spezalsalz (1).jpg \t classId:  14\n",
      "filename:  denkmit_spezalsalz (2).jpg \t classId:  14\n",
      "filename:  denkmit_spezalsalz (3).jpg \t classId:  14\n",
      "filename:  2_SM_CalgonitFinishVorratspack_14_1_90_60_lit_cropped.jpg \t classId:  4\n",
      "filename:  3_SM_CalgonitFinishVorratspack_14_2_90_60_lit_cropped.jpg \t classId:  4\n",
      "filename:  34_SM_DenkMitEdelstahlReinigerSpray_20_33_90_60_lit_cropped.jpg \t classId:  6\n",
      "filename:  35_SM_DenkMitEdelstahlReinigerSpray_20_34_90_60_lit_cropped.jpg \t classId:  6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "test = pd.read_csv('/home/atif/machine_learning_stuff/ml_image/test_image_keras_IAI.csv',sep=';')\n",
    "# test_image_path =  '/home/atif/machine_learning_stuff/ml_image/test_image_crop/'\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "i = 0\n",
    "for file_name, class_id  in zip(list(test['Filename']), list(test['ClassId'])):\n",
    "    print('filename: ',file_name,'\\t classId: ',class_id)\n",
    "    #print('classId: ',class_id)\n",
    "    img_path = os.path.join('/home/atif/machine_learning_stuff/ml_image/test_image_26_aug/',file_name)\n",
    "#     img_path = glob.glob(os.path.join(test_image_path, '*/*.jpg'))\n",
    "    X_test.append(preprocess_img(io.imread(img_path)))\n",
    "    y_test.append(class_id)\n",
    "    \n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/atif/machine_learning_stuff/ml_image/test_image_26_aug/35_SM_DenkMitEdelstahlReinigerSpray_20_34_90_60_lit_cropped.jpg\n"
     ]
    }
   ],
   "source": [
    "print(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5,  5,  5,  5,  5,  5,  5,  7,  7,  7,  7,  7,  7, 10, 10, 10, 10,\n",
       "       10, 10,  9,  9,  9,  9,  9,  8,  8,  8,  8,  8,  8, 11, 11, 11, 11,\n",
       "       11,  3,  9, 12, 14,  3,  3,  3,  2,  2,  2,  2,  0,  0,  0,  0,  0,\n",
       "        1,  1,  1,  1,  1,  1,  3,  3, 14, 14, 14, 14, 14, 15, 15, 15, 15,\n",
       "       15, 15, 15, 15, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 14, 14, 14,\n",
       "        4,  4,  6,  6])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# finding accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy = 0.7191011235955056\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_test)\n",
    "acc = np.sum(y_pred==y_test)/np.size(y_pred)\n",
    "print(\"Test accuracy = {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check true vs true/false result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count =0\n",
    "right_count=0\n",
    "wrong_count=0\n",
    "for i,j in enumerate(y_test):\n",
    "    count +=1\n",
    "    if j == y_pred[i]:\n",
    "        right_count+=1\n",
    "#         print(count,'-'*5,j,'-'*5,y_pred[i])\n",
    "        \n",
    "    else:\n",
    "#         pass\n",
    "        wrong_count+=1\n",
    "        print(count,'°'*40,j,'-'*5,y_pred[i])\n",
    "print('total: ',count)\n",
    "print('right_count: ',right_count)\n",
    "print('wrong_count',wrong_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# do accuracy calculationfrom scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy = (right_count/y_pred.shape[0])*100\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# confusion matrix calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "results = confusion_matrix(y_test, y_pred)\n",
    "print(results)\n",
    "print(type(results))\n",
    "print(results.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# confusion matrix visualization with seaborn heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_cm = pd.DataFrame(results, range(16),\n",
    "                  range(16))\n",
    "plt.figure(figsize = (10,7))\n",
    "plt.tight_layout()\n",
    "sn.set(font_scale=1.4)#for label size\n",
    "\n",
    "ax = sn.heatmap(df_cm, annot=True,annot_kws={\"size\": 14},xticklabels=True, yticklabels=True)# font size\n",
    "ax.set(xlabel='predicted_class', ylabel='true_class')\n",
    "ax.set_ylim(16)\n",
    "figure = ax.get_figure()    \n",
    "# figure.savefig('12_sep_general_new_model_no_augmentation_confusion.png', dpi=400)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# confusion matrix visualization with matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "plt.imshow(cm, cmap=plt.cm.Accent)\n",
    "plt.xlabel(\"Predicted labels\")\n",
    "plt.ylabel(\"True labels\")\n",
    "plt.xticks([], [])\n",
    "# plt.xticks(y_pred)\n",
    "plt.yticks([], [])\n",
    "# plt.xticks(y_test)\n",
    "plt.title('Confusion matrix ')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check class image by image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "test_image_path = r'/home/atif/machine_learning_stuff/ml_image/test_image_26_aug/'\n",
    "\n",
    "my_name = ['SM_CalgonitFinish_2','SM_CalgonitFinishKlarspueler_5','SM_CalgonitFinishMaschinenpfleger_8','SM_CalgonitFinishSpezialSalz_11',\n",
    "           'SM_CalgonitFinishVorratspack_14','SM_DenkMitEdelstahlreiniger_17','SM_DenkMitEdelstahlReinigerSpray_20','SM_DenkMitEntkalker_23',\n",
    "           'SM_DenkMitGeschirrReiniger_26','SM_DenkMitGeschirrReinigerClassic_29','SM_DenkMitGeschirrReinigerEvo_32','SM_DenkMitGeschirrReinigerNature_35',\n",
    "           'SM_DenkMitHygieneAllzweckreiniger_38','SM_DenkMitMaschinenpfleger_41','SM_DenkMitSpezialsalz_44','SM_SomatClassic_53']\n",
    "\n",
    "img_path = glob.glob(test_image_path+ '/*.jpg')\n",
    "for image in img_path:\n",
    "    X_test=[]\n",
    "    X_test.append(preprocess_img(io.imread(image)))\n",
    "    X_test = np.array(X_test)\n",
    "#     plt.imshow(X_test)\n",
    "    X_test = X_test.reshape(len(X_test),3,IMG_SIZE,IMG_SIZE)\n",
    "    \n",
    "    print('image name is: ',image)\n",
    "    predicted_class = model.predict_classes(X_test)\n",
    "    print(\"predicted class: \",predicted_class)\n",
    "#     print('type-of predicted calss: ', type(predicted_class))\n",
    "    print('class name is: ',my_name[predicted_class[0]])\n",
    "    \n",
    "#     probability = model.predict_proba(X_test)\n",
    "#     print(\"probability: \",probability)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training with data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    rescale=1/255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_augmentation = cnn_model()\n",
    "# let's train the model using SGD + momentum (how original).\n",
    "lr = 0.01\n",
    "sgd = SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_augmentation.compile(loss='categorical_crossentropy',\n",
    "          optimizer=sgd,\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    return lr*(0.1**int(epoch/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epoch = 50\n",
    "batch_size = 32\n",
    "model_augmentation.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),\n",
    "                            steps_per_epoch=X_train.shape[0],\n",
    "                            epochs=nb_epoch,\n",
    "                            validation_data=(X_val, Y_val),\n",
    "                            callbacks=[LearningRateScheduler(lr_schedule),\n",
    "                                       ModelCheckpoint(path+str(current_time)+'_AUGMENTATION_'+str(epochs)+'.h5',save_best_only=True)]\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
