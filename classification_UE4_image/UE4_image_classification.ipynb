{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook code for image preprocessing, raining and testing(image by image and overall accuracy) of UE4 image will be developed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import io, color, exposure, transform\n",
    "from skimage.color import rgb2gray\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split  #it came from update scikit learn. https://stackoverflow.com/questions/40704484/importerror-no-module-named-model-selection\n",
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "import keras\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D,Conv1D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_first')\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "from matplotlib.pylab import rcParams\n",
    "\n",
    "#import keras\n",
    "\n",
    "NUM_CLASSES = 16 # change it with respect to the desired class\n",
    "IMG_SIZE = 48 # change it if it desired\n",
    "IMG_depth = 3 # for RGB 3, for B&W it will be 1\n",
    "from keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5py.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_img(img):\n",
    "    # Histogram normalization in y\n",
    "    hsv = color.rgb2hsv(img)\n",
    "    hsv[:,:,2] = exposure.equalize_hist(hsv[:,:,2])\n",
    "    img = color.hsv2rgb(hsv)\n",
    "\n",
    "    # central scrop\n",
    "    min_side = min(img.shape[:-1])\n",
    "    centre = img.shape[0]//2, img.shape[1]//2\n",
    "    img = img[centre[0]-min_side//2:centre[0]+min_side//2,centre[1]-min_side//2:centre[1]+min_side//2,:]\n",
    "#    img = rgb2gray(img)\n",
    "\n",
    "    # rescale to standard size\n",
    "    img = transform.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "    # roll color axis to axis 0\n",
    "    img = np.rollaxis(img,-1) # this lin is doing the channel fisrt operation\n",
    "\n",
    "    return img\n",
    "\n",
    "def get_class(img_path):\n",
    "    return int(img_path.split('/')[-2])\n",
    "#     return str(img_path.split('/')[-2]) # returning the folder name. If use -1 that means image name. consider the img_path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1200/57600\n",
      "Processed 2400/57600\n",
      "Processed 3600/57600\n",
      "Processed 4800/57600\n",
      "Processed 6000/57600\n",
      "Processed 7200/57600\n",
      "Processed 8400/57600\n",
      "Processed 9600/57600\n",
      "Processed 10800/57600\n",
      "Processed 12000/57600\n",
      "Processed 13200/57600\n",
      "Processed 14400/57600\n",
      "Processed 15600/57600\n",
      "Processed 16800/57600\n",
      "Processed 18000/57600\n",
      "Processed 19200/57600\n",
      "Processed 20400/57600\n",
      "Processed 21600/57600\n",
      "Processed 22800/57600\n",
      "Processed 24000/57600\n",
      "Processed 25200/57600\n",
      "Processed 26400/57600\n",
      "Processed 27600/57600\n",
      "Processed 28800/57600\n",
      "Processed 30000/57600\n",
      "Processed 31200/57600\n",
      "Processed 32400/57600\n",
      "Processed 33600/57600\n",
      "Processed 34800/57600\n",
      "Processed 36000/57600\n",
      "Processed 37200/57600\n",
      "Processed 38400/57600\n",
      "Processed 39600/57600\n",
      "Processed 40800/57600\n",
      "Processed 42000/57600\n",
      "Processed 43200/57600\n",
      "Processed 44400/57600\n",
      "Processed 45600/57600\n",
      "Processed 46800/57600\n",
      "Processed 48000/57600\n",
      "Processed 49200/57600\n",
      "Processed 50400/57600\n",
      "Processed 51600/57600\n",
      "Processed 52800/57600\n",
      "Processed 54000/57600\n",
      "Processed 55200/57600\n",
      "Processed 56400/57600\n",
      "Processed 57600/57600\n"
     ]
    }
   ],
   "source": [
    "imgs = []\n",
    "labels = []\n",
    "root_dir = '/home/atif/machine_learning_stuff/ml_image/train_image_AI/'\n",
    "#path='/home/atif/training_by_several_learning_process/flower_photos/00000/'\n",
    "\n",
    "#all_img_paths = glob.glob(path+ '5547758_eea9edfd54_n_000.jpg')\n",
    "\n",
    "all_img_paths = glob.glob(os.path.join(root_dir, '*/*.png')) #I have done the training with .png format image. If another type of image will come \n",
    "                                                                                    #them .png will be changed by that extension\n",
    "np.random.shuffle(all_img_paths)\n",
    "for img_path in all_img_paths:\n",
    "    try:\n",
    "        img = preprocess_img(io.imread(img_path))\n",
    "        label = get_class(img_path)\n",
    "        imgs.append(img)\n",
    "        labels.append(label)\n",
    "\n",
    "        if len(imgs)%1200 == 0: print(\"Processed {}/{}\".format(len(imgs), len(all_img_paths)))\n",
    "            #print(\"get it 2\")\n",
    "    except (IOError, OSError):\n",
    "        print('missed', img_path)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (57600, 3, 48, 48)  type:  <class 'numpy.ndarray'>\n",
      "Y shape:  (57600, 16)  type:  <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "X = np.array(imgs, dtype='float32') #Keeping the image as an array\n",
    "X = X.reshape(len(imgs),IMG_depth,IMG_SIZE,IMG_SIZE) # write (IMG_SIZE,IMG_SIZE,1 if you want channel last; 1= grayscale;3=RGB)\n",
    "# Y = np.eye(NUM_CLASSES, dtype='uint8')[labels]\n",
    "Y = keras.utils.to_categorical(labels, NUM_CLASSES)\n",
    "\n",
    "print('X shape: ', X.shape,' type: ',type(X))\n",
    "print('Y shape: ', Y.shape,' type: ',type(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                     input_shape=(3, IMG_SIZE, IMG_SIZE),\n",
    "                     activation='relu'))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), padding='same',\n",
    "                     input_shape=(3, IMG_SIZE, IMG_SIZE),\n",
    "                     activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same',\n",
    "                     activation='relu'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same',\n",
    "                     activation='relu'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "model = cnn_model()\n",
    "\n",
    "lr = 0.01\n",
    "sgd = SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "          optimizer=sgd,\n",
    "          metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 32, 48, 48)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 32, 46, 46)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 32, 23, 23)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 32, 23, 23)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 64, 23, 23)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 64, 21, 21)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 64, 10, 10)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 64, 10, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 128, 10, 10)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 128, 8, 8)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 128, 4, 4)         0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128, 4, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 128, 4, 4)         147584    \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 128, 2, 2)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 128, 1, 1)         0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 128, 1, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 656,432\n",
      "Trainable params: 656,432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/atif/machine_learning_stuff/model_file_keras/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current time: 2019-09-09 14:08:34.208492\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "current_time = datetime.datetime.now()\n",
    "print(\"current time:\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Train on 46080 samples, validate on 11520 samples\n",
      "Epoch 1/50\n",
      " - 22s - loss: 1.7873 - acc: 0.3834 - val_loss: 0.5924 - val_acc: 0.8063\n",
      "Epoch 2/50\n",
      " - 21s - loss: 0.3726 - acc: 0.8768 - val_loss: 0.1262 - val_acc: 0.9592\n",
      "Epoch 3/50\n",
      " - 21s - loss: 0.1644 - acc: 0.9465 - val_loss: 0.0538 - val_acc: 0.9824\n",
      "Epoch 4/50\n",
      " - 21s - loss: 0.1113 - acc: 0.9638 - val_loss: 0.0356 - val_acc: 0.9879\n",
      "Epoch 5/50\n",
      " - 21s - loss: 0.0947 - acc: 0.9713 - val_loss: 0.0203 - val_acc: 0.9929\n",
      "Epoch 6/50\n",
      " - 20s - loss: 0.0807 - acc: 0.9760 - val_loss: 0.0651 - val_acc: 0.9842\n",
      "Epoch 7/50\n",
      " - 20s - loss: 0.0685 - acc: 0.9789 - val_loss: 0.0142 - val_acc: 0.9954\n",
      "Epoch 8/50\n",
      " - 20s - loss: 0.0537 - acc: 0.9851 - val_loss: 0.0134 - val_acc: 0.9966\n",
      "Epoch 9/50\n",
      " - 21s - loss: 0.0643 - acc: 0.9829 - val_loss: 0.0095 - val_acc: 0.9970\n",
      "Epoch 10/50\n",
      " - 21s - loss: 0.0665 - acc: 0.9819 - val_loss: 0.0069 - val_acc: 0.9980\n",
      "Epoch 11/50\n",
      " - 20s - loss: 0.0106 - acc: 0.9967 - val_loss: 0.0019 - val_acc: 0.9996\n",
      "Epoch 12/50\n",
      " - 20s - loss: 0.0057 - acc: 0.9980 - val_loss: 0.0015 - val_acc: 0.9996\n",
      "Epoch 13/50\n",
      " - 20s - loss: 0.0043 - acc: 0.9984 - val_loss: 8.1159e-04 - val_acc: 1.0000\n",
      "Epoch 14/50\n",
      " - 21s - loss: 0.0035 - acc: 0.9991 - val_loss: 8.8740e-04 - val_acc: 0.9997\n",
      "Epoch 15/50\n",
      " - 21s - loss: 0.0033 - acc: 0.9989 - val_loss: 5.9341e-04 - val_acc: 0.9999\n",
      "Epoch 16/50\n",
      " - 20s - loss: 0.0036 - acc: 0.9988 - val_loss: 4.2178e-04 - val_acc: 1.0000\n",
      "Epoch 17/50\n",
      " - 20s - loss: 0.0025 - acc: 0.9992 - val_loss: 3.4386e-04 - val_acc: 0.9999\n",
      "Epoch 18/50\n",
      " - 21s - loss: 0.0025 - acc: 0.9991 - val_loss: 2.7291e-04 - val_acc: 1.0000\n",
      "Epoch 19/50\n",
      " - 21s - loss: 0.0027 - acc: 0.9991 - val_loss: 3.0343e-04 - val_acc: 1.0000\n",
      "Epoch 20/50\n",
      " - 21s - loss: 0.0025 - acc: 0.9992 - val_loss: 2.3075e-04 - val_acc: 1.0000\n",
      "Epoch 21/50\n",
      " - 21s - loss: 0.0015 - acc: 0.9996 - val_loss: 2.2939e-04 - val_acc: 1.0000\n",
      "Epoch 22/50\n",
      " - 21s - loss: 0.0024 - acc: 0.9992 - val_loss: 2.2809e-04 - val_acc: 1.0000\n",
      "Epoch 23/50\n",
      " - 19s - loss: 0.0023 - acc: 0.9991 - val_loss: 2.4419e-04 - val_acc: 1.0000\n",
      "Epoch 24/50\n",
      " - 18s - loss: 0.0017 - acc: 0.9994 - val_loss: 2.2206e-04 - val_acc: 1.0000\n",
      "Epoch 25/50\n",
      " - 19s - loss: 0.0023 - acc: 0.9993 - val_loss: 2.2369e-04 - val_acc: 1.0000\n",
      "Epoch 26/50\n",
      " - 20s - loss: 0.0017 - acc: 0.9993 - val_loss: 2.0967e-04 - val_acc: 1.0000\n",
      "Epoch 27/50\n",
      " - 19s - loss: 0.0017 - acc: 0.9994 - val_loss: 1.9752e-04 - val_acc: 1.0000\n",
      "Epoch 28/50\n",
      " - 20s - loss: 0.0019 - acc: 0.9995 - val_loss: 2.0810e-04 - val_acc: 1.0000\n",
      "Epoch 29/50\n",
      " - 20s - loss: 0.0020 - acc: 0.9994 - val_loss: 2.0712e-04 - val_acc: 1.0000\n",
      "Epoch 30/50\n",
      " - 19s - loss: 0.0017 - acc: 0.9996 - val_loss: 1.9740e-04 - val_acc: 1.0000\n",
      "Epoch 31/50\n",
      " - 20s - loss: 0.0018 - acc: 0.9994 - val_loss: 1.9510e-04 - val_acc: 1.0000\n",
      "Epoch 32/50\n",
      " - 20s - loss: 0.0020 - acc: 0.9995 - val_loss: 1.9478e-04 - val_acc: 1.0000\n",
      "Epoch 33/50\n",
      " - 21s - loss: 0.0018 - acc: 0.9995 - val_loss: 1.9493e-04 - val_acc: 1.0000\n",
      "Epoch 34/50\n",
      " - 21s - loss: 0.0019 - acc: 0.9995 - val_loss: 1.9594e-04 - val_acc: 1.0000\n",
      "Epoch 35/50\n",
      " - 21s - loss: 0.0024 - acc: 0.9992 - val_loss: 1.9677e-04 - val_acc: 1.0000\n",
      "Epoch 36/50\n",
      " - 21s - loss: 0.0021 - acc: 0.9994 - val_loss: 2.0105e-04 - val_acc: 1.0000\n",
      "Epoch 37/50\n",
      " - 21s - loss: 0.0019 - acc: 0.9994 - val_loss: 1.9922e-04 - val_acc: 1.0000\n",
      "Epoch 38/50\n",
      " - 20s - loss: 0.0021 - acc: 0.9994 - val_loss: 1.9802e-04 - val_acc: 1.0000\n",
      "Epoch 39/50\n",
      " - 21s - loss: 0.0025 - acc: 0.9994 - val_loss: 1.9590e-04 - val_acc: 1.0000\n",
      "Epoch 40/50\n",
      " - 21s - loss: 0.0022 - acc: 0.9991 - val_loss: 1.9686e-04 - val_acc: 1.0000\n",
      "Epoch 41/50\n",
      " - 21s - loss: 0.0019 - acc: 0.9995 - val_loss: 1.9678e-04 - val_acc: 1.0000\n",
      "Epoch 42/50\n",
      " - 21s - loss: 0.0023 - acc: 0.9994 - val_loss: 1.9672e-04 - val_acc: 1.0000\n",
      "Epoch 43/50\n",
      " - 21s - loss: 0.0021 - acc: 0.9993 - val_loss: 1.9674e-04 - val_acc: 1.0000\n",
      "Epoch 44/50\n",
      " - 21s - loss: 0.0016 - acc: 0.9995 - val_loss: 1.9678e-04 - val_acc: 1.0000\n",
      "Epoch 45/50\n",
      " - 21s - loss: 0.0015 - acc: 0.9995 - val_loss: 1.9686e-04 - val_acc: 1.0000\n",
      "Epoch 46/50\n",
      " - 21s - loss: 0.0021 - acc: 0.9993 - val_loss: 1.9682e-04 - val_acc: 1.0000\n",
      "Epoch 47/50\n",
      " - 21s - loss: 0.0020 - acc: 0.9994 - val_loss: 1.9678e-04 - val_acc: 1.0000\n",
      "Epoch 48/50\n",
      " - 21s - loss: 0.0017 - acc: 0.9995 - val_loss: 1.9700e-04 - val_acc: 1.0000\n",
      "Epoch 49/50\n",
      " - 21s - loss: 0.0019 - acc: 0.9994 - val_loss: 1.9707e-04 - val_acc: 1.0000\n",
      "Epoch 50/50\n",
      " - 20s - loss: 0.0022 - acc: 0.9994 - val_loss: 1.9701e-04 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "def lr_schedule(epoch):\n",
    "    return lr * (0.1 ** int(epoch / 10))\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "do_train_model=model.fit(X, Y,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2,verbose=2,\n",
    "          #np.resize(img, (-1, <image shape>)\n",
    "          callbacks=[LearningRateScheduler(lr_schedule),ModelCheckpoint(path+str(current_time)+'_'+str(epochs)+'.h5', save_best_only=True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "# model = load_model('/home/atif/machine_learning_stuff/model_file_keras/general_2_sep_ep_30_epoch.h5')\n",
    "model = load_model('/home/atif/machine_learning_stuff/model_file_keras/2019-09-09 14:08:34.208492_50.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check total accuracy of the model using all test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename:  denkmit_edelstahk_reiniger (1).jpg \t classId:  5\n",
      "filename:  denkmit_edelstahk_reiniger (2).jpg \t classId:  5\n",
      "filename:  denkmit_edelstahk_reiniger (3).jpg \t classId:  5\n",
      "filename:  denkmit_edelstahk_reiniger (4).jpg \t classId:  5\n",
      "filename:  denkmit_edelstahk_reiniger (5).jpg \t classId:  5\n",
      "filename:  denkmit_edelstahk_reiniger (6).jpg \t classId:  5\n",
      "filename:  denkmit_edelstahk_reiniger (7).jpg \t classId:  5\n",
      "filename:  denkmit_Entkalker (1).jpg \t classId:  7\n",
      "filename:  denkmit_Entkalker (2).jpg \t classId:  7\n",
      "filename:  denkmit_Entkalker (3).jpg \t classId:  7\n",
      "filename:  denkmit_Entkalker (4).jpg \t classId:  7\n",
      "filename:  denkmit_Entkalker (5).jpg \t classId:  7\n",
      "filename:  denkmit_Entkalker (6).jpg \t classId:  7\n",
      "filename:  denkmit_geschirrreiniger_REVOLUTION (1).jpg \t classId:  10\n",
      "filename:  denkmit_geschirrreiniger_REVOLUTION (2).jpg \t classId:  10\n",
      "filename:  denkmit_geschirrreiniger_REVOLUTION (3).jpg \t classId:  10\n",
      "filename:  denkmit_geschirrreiniger_REVOLUTION (4).jpg \t classId:  10\n",
      "filename:  denkmit_geschirrreiniger_REVOLUTION (5).jpg \t classId:  10\n",
      "filename:  denkmit_geschirrreiniger_REVOLUTION (6).jpg \t classId:  10\n",
      "filename:  Denkmit_geschirr_reiniger_classic (1).jpg \t classId:  9\n",
      "filename:  Denkmit_geschirr_reiniger_classic (3).jpg \t classId:  9\n",
      "filename:  Denkmit_geschirr_reiniger_classic (4).jpg \t classId:  9\n",
      "filename:  Denkmit_geschirr_reiniger_classic (5).jpg \t classId:  9\n",
      "filename:  Denkmit_geschirr_reiniger_classic (6).jpg \t classId:  9\n",
      "filename:  denkmit_geschirr_reiniger_multipower (1).jpg \t classId:  8\n",
      "filename:  denkmit_geschirr_reiniger_multipower (2).jpg \t classId:  8\n",
      "filename:  denkmit_geschirr_reiniger_multipower (3).jpg \t classId:  8\n",
      "filename:  denkmit_geschirr_reiniger_multipower (4).jpg \t classId:  8\n",
      "filename:  denkmit_geschirr_reiniger_multipower (5).jpg \t classId:  8\n",
      "filename:  denkmit_geschirr_reiniger_multipower (6).jpg \t classId:  8\n",
      "filename:  denkmit_geschirr_reiniger_NATURE (1).jpg \t classId:  11\n",
      "filename:  denkmit_geschirr_reiniger_NATURE (2).jpg \t classId:  11\n",
      "filename:  denkmit_geschirr_reiniger_NATURE (3).jpg \t classId:  11\n",
      "filename:  denkmit_geschirr_reiniger_NATURE (4).jpg \t classId:  11\n",
      "filename:  denkmit_geschirr_reiniger_NATURE (5).jpg \t classId:  11\n",
      "filename:  calgonit_finish_speizalsalz (3).jpg \t classId:  3\n",
      "filename:  Denkmit_geschirr_reiniger_classic (2).jpg \t classId:  9\n",
      "filename:  denkmit_hygiene_Allzweck_reiniger (1).jpg \t classId:  12\n",
      "filename:  denkmit_spezalsalz (4).jpg \t classId:  14\n",
      "filename:  calgonit_finish_speizalsalz (4).jpg \t classId:  3\n",
      "filename:  calgonit_finish_speizalsalz (5).jpg \t classId:  3\n",
      "filename:  calgonit_finish_speizalsalz (6).jpg \t classId:  3\n",
      "filename:  calgonit_maschine_pfleger (1).jpg \t classId:  2\n",
      "filename:  calgonit_maschine_pfleger (2).jpg \t classId:  2\n",
      "filename:  calgonit_maschine_pfleger (3).jpg \t classId:  2\n",
      "filename:  calgonit_maschine_pfleger (4).jpg \t classId:  2\n",
      "filename:  calgonit_finish_classic (1).jpg \t classId:  0\n",
      "filename:  calgonit_finish_classic (2).jpg \t classId:  0\n",
      "filename:  calgonit_finish_classic (3).jpg \t classId:  0\n",
      "filename:  calgonit_finish_classic (4).jpg \t classId:  0\n",
      "filename:  calgonit_finish_classic (5).jpg \t classId:  0\n",
      "filename:  calgonit_finish_klarspueler (1).jpg \t classId:  1\n",
      "filename:  calgonit_finish_klarspueler (2).jpg \t classId:  1\n",
      "filename:  calgonit_finish_klarspueler (3).jpg \t classId:  1\n",
      "filename:  calgonit_finish_klarspueler (4).jpg \t classId:  1\n",
      "filename:  calgonit_finish_klarspueler (5).jpg \t classId:  1\n",
      "filename:  calgonit_finish_klarspueler (6).jpg \t classId:  1\n",
      "filename:  calgonit_finish_speizalsalz (1).jpg \t classId:  3\n",
      "filename:  calgonit_finish_speizalsalz (2).jpg \t classId:  3\n",
      "filename:  denkmit_spezalsalz (5).jpg \t classId:  14\n",
      "filename:  denkmit_spezalsalz (6).jpg \t classId:  14\n",
      "filename:  denkmit_spezalsalz (7).jpg \t classId:  14\n",
      "filename:  denkmit_spezalsalz (8).jpg \t classId:  14\n",
      "filename:  denkmit_spezalsalz (9).jpg \t classId:  14\n",
      "filename:  somat (1).jpg \t classId:  15\n",
      "filename:  somat (2).jpg \t classId:  15\n",
      "filename:  somat_3.jpg \t classId:  15\n",
      "filename:  somat_4.jpg \t classId:  15\n",
      "filename:  somat_5.jpg \t classId:  15\n",
      "filename:  somat_6.jpg \t classId:  15\n",
      "filename:  somat_7.jpg \t classId:  15\n",
      "filename:  somat_8.jpg \t classId:  15\n",
      "filename:  denkmit_hygiene_Allzweck_reiniger (2).jpg \t classId:  12\n",
      "filename:  denkmit_hygiene_Allzweck_reiniger (3).jpg \t classId:  12\n",
      "filename:  denkmit_hygiene_Allzweck_reiniger (4).jpg \t classId:  12\n",
      "filename:  denkmit_hygiene_Allzweck_reiniger (5).jpg \t classId:  12\n",
      "filename:  denkmit_mascine_pfleger (1).jpg \t classId:  13\n",
      "filename:  denkmit_mascine_pfleger (2).jpg \t classId:  13\n",
      "filename:  denkmit_mascine_pfleger (3).jpg \t classId:  13\n",
      "filename:  denkmit_mascine_pfleger (4).jpg \t classId:  13\n",
      "filename:  denkmit_mascine_pfleger (5).jpg \t classId:  13\n",
      "filename:  denkmit_mascine_pfleger (6).jpg \t classId:  13\n",
      "filename:  denkmit_spezalsalz (1).jpg \t classId:  14\n",
      "filename:  denkmit_spezalsalz (2).jpg \t classId:  14\n",
      "filename:  denkmit_spezalsalz (3).jpg \t classId:  14\n",
      "filename:  2_SM_CalgonitFinishVorratspack_14_1_90_60_lit_cropped.jpg \t classId:  4\n",
      "filename:  3_SM_CalgonitFinishVorratspack_14_2_90_60_lit_cropped.jpg \t classId:  4\n",
      "filename:  34_SM_DenkMitEdelstahlReinigerSpray_20_33_90_60_lit_cropped.jpg \t classId:  6\n",
      "filename:  35_SM_DenkMitEdelstahlReinigerSpray_20_34_90_60_lit_cropped.jpg \t classId:  6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "test = pd.read_csv('/home/atif/machine_learning_stuff/ml_image/test_image_keras_IAI.csv',sep=';')\n",
    "# test_image_path =  '/home/atif/machine_learning_stuff/ml_image/test_image_crop/'\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "i = 0\n",
    "for file_name, class_id  in zip(list(test['Filename']), list(test['ClassId'])):\n",
    "    print('filename: ',file_name,'\\t classId: ',class_id)\n",
    "    #print('classId: ',class_id)\n",
    "    img_path = os.path.join('/home/atif/machine_learning_stuff/ml_image/test_image_26_aug/',file_name)\n",
    "#     img_path = glob.glob(os.path.join(test_image_path, '*/*.jpg'))\n",
    "    X_test.append(preprocess_img(io.imread(img_path)))\n",
    "    y_test.append(class_id)\n",
    "    \n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/atif/machine_learning_stuff/ml_image/test_image_26_aug/35_SM_DenkMitEdelstahlReinigerSpray_20_34_90_60_lit_cropped.jpg\n"
     ]
    }
   ],
   "source": [
    "print(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5,  5,  5,  5,  5,  5,  5,  7,  7,  7,  7,  7,  7, 10, 10, 10, 10,\n",
       "       10, 10,  9,  9,  9,  9,  9,  8,  8,  8,  8,  8,  8, 11, 11, 11, 11,\n",
       "       11,  3,  9, 12, 14,  3,  3,  3,  2,  2,  2,  2,  0,  0,  0,  0,  0,\n",
       "        1,  1,  1,  1,  1,  1,  3,  3, 14, 14, 14, 14, 14, 15, 15, 15, 15,\n",
       "       15, 15, 15, 15, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 14, 14, 14,\n",
       "        4,  4,  6,  6])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# finding accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy = 0.7303370786516854\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_test)\n",
    "acc = np.sum(y_pred==y_test)/np.size(y_pred)\n",
    "print(\"Test accuracy = {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check true vs true/false result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count =0\n",
    "right_count=0\n",
    "wrong_count=0\n",
    "for i,j in enumerate(y_test):\n",
    "    count +=1\n",
    "    if j == y_pred[i]:\n",
    "        right_count+=1\n",
    "#         print(count,'-'*5,j,'-'*5,y_pred[i])\n",
    "        \n",
    "    else:\n",
    "#         pass\n",
    "        wrong_count+=1\n",
    "        print(count,'Â°'*40,j,'-'*5,y_pred[i])\n",
    "print('total: ',count)\n",
    "print('right_count: ',right_count)\n",
    "print('wrong_count',wrong_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# do accuracy calculationfrom scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy = (right_count/y_pred.shape[0])*100\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# confusion matrix calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "results = confusion_matrix(y_test, y_pred)\n",
    "print(results)\n",
    "print(type(results))\n",
    "print(results.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# confusion matrix visualization with seaborn heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_cm = pd.DataFrame(results, range(16),\n",
    "                  range(16))\n",
    "plt.figure(figsize = (10,7))\n",
    "plt.tight_layout()\n",
    "sn.set(font_scale=1.4)#for label size\n",
    "\n",
    "ax = sn.heatmap(df_cm, annot=True,annot_kws={\"size\": 14},xticklabels=True, yticklabels=True)# font size\n",
    "ax.set(xlabel='predicted_class', ylabel='true_class')\n",
    "ax.set_ylim(16)\n",
    "figure = ax.get_figure()    \n",
    "# figure.savefig('2_sep_ax_conf.png', dpi=400)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# confusion matrix visualization with matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "plt.imshow(cm, cmap=plt.cm.Accent)\n",
    "plt.xlabel(\"Predicted labels\")\n",
    "plt.ylabel(\"True labels\")\n",
    "plt.xticks([], [])\n",
    "# plt.xticks(y_pred)\n",
    "plt.yticks([], [])\n",
    "# plt.xticks(y_test)\n",
    "plt.title('Confusion matrix ')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check class image by image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "test_image_path = r'/home/atif/machine_learning_stuff/ml_image/test_image_26_aug/'\n",
    "\n",
    "my_name = ['SM_CalgonitFinish_2','SM_CalgonitFinishKlarspueler_5','SM_CalgonitFinishMaschinenpfleger_8','SM_CalgonitFinishSpezialSalz_11',\n",
    "           'SM_CalgonitFinishVorratspack_14','SM_DenkMitEdelstahlreiniger_17','SM_DenkMitEdelstahlReinigerSpray_20','SM_DenkMitEntkalker_23',\n",
    "           'SM_DenkMitGeschirrReiniger_26','SM_DenkMitGeschirrReinigerClassic_29','SM_DenkMitGeschirrReinigerEvo_32','SM_DenkMitGeschirrReinigerNature_35',\n",
    "           'SM_DenkMitHygieneAllzweckreiniger_38','SM_DenkMitMaschinenpfleger_41','SM_DenkMitSpezialsalz_44','SM_SomatClassic_53']\n",
    "\n",
    "img_path = glob.glob(test_image_path+ '/*.jpg')\n",
    "for image in img_path:\n",
    "    X_test=[]\n",
    "    X_test.append(preprocess_img(io.imread(image)))\n",
    "    X_test = np.array(X_test)\n",
    "#     plt.imshow(X_test)\n",
    "    X_test = X_test.reshape(len(X_test),3,IMG_SIZE,IMG_SIZE)\n",
    "    \n",
    "    print('image name is: ',image)\n",
    "    predicted_class = model.predict_classes(X_test)\n",
    "    print(\"predicted class: \",predicted_class)\n",
    "#     print('type-of predicted calss: ', type(predicted_class))\n",
    "    print('class name is: ',my_name[predicted_class[0]])\n",
    "    \n",
    "#     probability = model.predict_proba(X_test)\n",
    "#     print(\"probability: \",probability)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training with data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    rescale=1/255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_augmentation = cnn_model()\n",
    "# let's train the model using SGD + momentum (how original).\n",
    "lr = 0.01\n",
    "sgd = SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_augmentation.compile(loss='categorical_crossentropy',\n",
    "          optimizer=sgd,\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    return lr*(0.1**int(epoch/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "46080/46080 [==============================] - 1080s 23ms/step - loss: 2.7734 - acc: 0.0617 - val_loss: 2.7742 - val_acc: 0.0625\n",
      "Epoch 2/50\n",
      "46080/46080 [==============================] - 873s 19ms/step - loss: 2.7734 - acc: 0.0618 - val_loss: 2.7738 - val_acc: 0.0602\n",
      "Epoch 3/50\n",
      "24612/46080 [===============>..............] - ETA: 8:19 - loss: 2.7734 - acc: 0.0615"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-cf0536f70514>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                             callbacks=[LearningRateScheduler(lr_schedule),\n\u001b[0;32m----> 8\u001b[0;31m                                        ModelCheckpoint(path+str(current_time)+'_AUGMENTATION_'+str(epochs)+'.h5',save_best_only=True)]\n\u001b[0m\u001b[1;32m      9\u001b[0m                            )\n",
      "\u001b[0;32m~/tf_gpu/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_gpu/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1225\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1227\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1229\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_gpu/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_gpu/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2145\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2146\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2147\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_gpu/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1837\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1838\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1839\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1840\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_gpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2353\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2354\u001b[0m         \u001b[0mfetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2355\u001b[0;31m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m   2357\u001b[0m                               **self.session_kwargs)\n",
      "\u001b[0;32m~/tf_gpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0mcandidate_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_initialized'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m                     \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nb_epoch = 50\n",
    "batch_size = 32\n",
    "model_augmentation.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),\n",
    "                            steps_per_epoch=X_train.shape[0],\n",
    "                            epochs=nb_epoch,\n",
    "                            validation_data=(X_val, Y_val),\n",
    "                            callbacks=[LearningRateScheduler(lr_schedule),\n",
    "                                       ModelCheckpoint(path+str(current_time)+'_AUGMENTATION_'+str(epochs)+'.h5',save_best_only=True)]\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.1.0'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
