{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook code for image preprocessing, raining and testing(image by image and overall accuracy) of UE4 image will be developed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import io, color, exposure, transform\n",
    "from skimage.color import rgb2gray\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split  #it came from update scikit learn. https://stackoverflow.com/questions/40704484/importerror-no-module-named-model-selection\n",
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "import keras\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D,Conv1D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_first')\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "from matplotlib.pylab import rcParams\n",
    "\n",
    "#import keras\n",
    "\n",
    "NUM_CLASSES = 16 # change it with respect to the desired class\n",
    "IMG_SIZE = 48 # change it if it desired\n",
    "IMG_depth = 3 # for RGB 3, for B&W it will be 1\n",
    "from keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5py.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_img(img):\n",
    "    # Histogram normalization in y\n",
    "    hsv = color.rgb2hsv(img)\n",
    "    hsv[:,:,2] = exposure.equalize_hist(hsv[:,:,2])\n",
    "    img = color.hsv2rgb(hsv)\n",
    "\n",
    "    # central scrop\n",
    "    min_side = min(img.shape[:-1])\n",
    "    centre = img.shape[0]//2, img.shape[1]//2\n",
    "    img = img[centre[0]-min_side//2:centre[0]+min_side//2,centre[1]-min_side//2:centre[1]+min_side//2,:]\n",
    "#    img = rgb2gray(img)\n",
    "\n",
    "    # rescale to standard size\n",
    "    img = transform.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "    # roll color axis to axis 0\n",
    "    img = np.rollaxis(img,-1) # this lin is doing the channel fisrt operation\n",
    "\n",
    "    return img\n",
    "\n",
    "def get_class(img_path):\n",
    "    return int(img_path.split('/')[-2])\n",
    "#     return str(img_path.split('/')[-2]) # returning the folder name. If use -1 that means image name. consider the img_path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1200/57600\n",
      "Processed 2400/57600\n",
      "Processed 3600/57600\n",
      "Processed 4800/57600\n",
      "Processed 6000/57600\n",
      "Processed 7200/57600\n",
      "Processed 8400/57600\n",
      "Processed 9600/57600\n",
      "Processed 10800/57600\n",
      "Processed 12000/57600\n",
      "Processed 13200/57600\n",
      "Processed 14400/57600\n",
      "Processed 15600/57600\n",
      "Processed 16800/57600\n",
      "Processed 18000/57600\n",
      "Processed 19200/57600\n",
      "Processed 20400/57600\n",
      "Processed 21600/57600\n",
      "Processed 22800/57600\n",
      "Processed 24000/57600\n",
      "Processed 25200/57600\n",
      "Processed 26400/57600\n",
      "Processed 27600/57600\n",
      "Processed 28800/57600\n",
      "Processed 30000/57600\n",
      "Processed 31200/57600\n",
      "Processed 32400/57600\n",
      "Processed 33600/57600\n",
      "Processed 34800/57600\n",
      "Processed 36000/57600\n",
      "Processed 37200/57600\n",
      "Processed 38400/57600\n",
      "Processed 39600/57600\n",
      "Processed 40800/57600\n",
      "Processed 42000/57600\n",
      "Processed 43200/57600\n",
      "Processed 44400/57600\n",
      "Processed 45600/57600\n",
      "Processed 46800/57600\n",
      "Processed 48000/57600\n",
      "Processed 49200/57600\n",
      "Processed 50400/57600\n",
      "Processed 51600/57600\n",
      "Processed 52800/57600\n",
      "Processed 54000/57600\n",
      "Processed 55200/57600\n",
      "Processed 56400/57600\n",
      "Processed 57600/57600\n"
     ]
    }
   ],
   "source": [
    "imgs = []\n",
    "labels = []\n",
    "root_dir = '/home/atif/machine_learning_stuff/ml_image/train_image_AI/'\n",
    "#path='/home/atif/training_by_several_learning_process/flower_photos/00000/'\n",
    "\n",
    "#all_img_paths = glob.glob(path+ '5547758_eea9edfd54_n_000.jpg')\n",
    "\n",
    "all_img_paths = glob.glob(os.path.join(root_dir, '*/*.png')) #I have done the training with .png format image. If another type of image will come \n",
    "                                                                                    #them .png will be changed by that extension\n",
    "np.random.shuffle(all_img_paths)\n",
    "for img_path in all_img_paths:\n",
    "    try:\n",
    "        img = preprocess_img(io.imread(img_path))\n",
    "        label = get_class(img_path)\n",
    "        imgs.append(img)\n",
    "        labels.append(label)\n",
    "\n",
    "        if len(imgs)%1200 == 0: print(\"Processed {}/{}\".format(len(imgs), len(all_img_paths)))\n",
    "            #print(\"get it 2\")\n",
    "    except (IOError, OSError):\n",
    "        print('missed', img_path)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (57600, 3, 48, 48)  type:  <class 'numpy.ndarray'>\n",
      "Y shape:  (57600, 16)  type:  <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "X = np.array(imgs, dtype='float32') #Keeping the image as an array\n",
    "X = X.reshape(len(imgs),IMG_depth,IMG_SIZE,IMG_SIZE) # write (IMG_SIZE,IMG_SIZE,1 if you want channel last; 1= grayscale;3=RGB)\n",
    "# Y = np.eye(NUM_CLASSES, dtype='uint8')[labels]\n",
    "Y = keras.utils.to_categorical(labels, NUM_CLASSES)\n",
    "\n",
    "print('X shape: ', X.shape,' type: ',type(X))\n",
    "print('Y shape: ', Y.shape,' type: ',type(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/atif/tf_gpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/atif/tf_gpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2885: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/atif/tf_gpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1349: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "def cnn_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                     input_shape=(3, IMG_SIZE, IMG_SIZE),\n",
    "                     activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3), padding='same',\n",
    "                     input_shape=(3, IMG_SIZE, IMG_SIZE),\n",
    "                     activation='relu'))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same',\n",
    "                     activation='relu'))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same',\n",
    "                     activation='relu'))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "model = cnn_model()\n",
    "\n",
    "lr = 0.01\n",
    "sgd = SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "          optimizer=sgd,\n",
    "          metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 48, 48)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 46, 46)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 23, 23)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64, 23, 23)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 128, 23, 23)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 256, 21, 21)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 256, 10, 10)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256, 10, 10)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 256, 10, 10)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 256, 8, 8)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 256, 4, 4)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256, 4, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 512, 4, 4)         1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 512, 2, 2)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 512, 1, 1)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512, 1, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                16400     \n",
      "=================================================================\n",
      "Total params: 5,650,256\n",
      "Trainable params: 5,650,256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/atif/machine_learning_stuff/model_file_keras/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current time: 2019-09-12 19:40:27.274695\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "current_time = datetime.datetime.now()\n",
    "print(\"current time:\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Train on 46080 samples, validate on 11520 samples\n",
      "Epoch 1/50\n",
      " - 40s - loss: 1.9878 - acc: 0.3249 - val_loss: 0.3881 - val_acc: 0.8839\n",
      "Epoch 2/50\n",
      " - 40s - loss: 0.2487 - acc: 0.9184 - val_loss: 0.0516 - val_acc: 0.9815\n",
      "Epoch 3/50\n",
      " - 40s - loss: 0.0873 - acc: 0.9725 - val_loss: 0.0368 - val_acc: 0.9873\n",
      "Epoch 4/50\n",
      " - 40s - loss: 0.0468 - acc: 0.9857 - val_loss: 0.0146 - val_acc: 0.9951\n",
      "Epoch 5/50\n",
      " - 40s - loss: 0.0382 - acc: 0.9890 - val_loss: 0.0034 - val_acc: 0.9990\n",
      "Epoch 6/50\n",
      " - 40s - loss: 0.0333 - acc: 0.9903 - val_loss: 0.0059 - val_acc: 0.9983\n",
      "Epoch 7/50\n",
      " - 40s - loss: 0.0164 - acc: 0.9949 - val_loss: 0.0046 - val_acc: 0.9984\n",
      "Epoch 8/50\n",
      " - 40s - loss: 0.0194 - acc: 0.9943 - val_loss: 0.0070 - val_acc: 0.9980\n",
      "Epoch 9/50\n",
      " - 40s - loss: 0.0216 - acc: 0.9942 - val_loss: 0.0055 - val_acc: 0.9985\n",
      "Epoch 10/50\n",
      " - 40s - loss: 0.0120 - acc: 0.9966 - val_loss: 9.1329e-04 - val_acc: 0.9998\n",
      "Epoch 11/50\n",
      " - 40s - loss: 0.0010 - acc: 0.9998 - val_loss: 5.7527e-04 - val_acc: 0.9999\n",
      "Epoch 12/50\n",
      " - 40s - loss: 7.1827e-04 - acc: 0.9998 - val_loss: 4.5630e-04 - val_acc: 0.9999\n",
      "Epoch 13/50\n",
      " - 40s - loss: 4.5748e-04 - acc: 0.9999 - val_loss: 5.4779e-04 - val_acc: 0.9999\n",
      "Epoch 14/50\n",
      " - 40s - loss: 3.4716e-04 - acc: 0.9999 - val_loss: 5.9212e-04 - val_acc: 0.9999\n",
      "Epoch 15/50\n",
      " - 40s - loss: 4.1329e-04 - acc: 0.9999 - val_loss: 6.0150e-04 - val_acc: 0.9999\n",
      "Epoch 16/50\n",
      " - 40s - loss: 2.4129e-04 - acc: 1.0000 - val_loss: 6.0630e-04 - val_acc: 0.9999\n",
      "Epoch 17/50\n",
      " - 40s - loss: 2.5652e-04 - acc: 1.0000 - val_loss: 6.3098e-04 - val_acc: 0.9999\n",
      "Epoch 18/50\n",
      " - 40s - loss: 1.8039e-04 - acc: 1.0000 - val_loss: 5.7924e-04 - val_acc: 0.9999\n",
      "Epoch 19/50\n",
      " - 40s - loss: 2.8364e-04 - acc: 0.9999 - val_loss: 6.1639e-04 - val_acc: 0.9999\n",
      "Epoch 20/50\n",
      " - 40s - loss: 2.9616e-04 - acc: 0.9999 - val_loss: 5.9764e-04 - val_acc: 0.9999\n",
      "Epoch 21/50\n",
      " - 40s - loss: 1.5418e-04 - acc: 1.0000 - val_loss: 5.9720e-04 - val_acc: 0.9999\n",
      "Epoch 22/50\n",
      " - 40s - loss: 2.6463e-04 - acc: 0.9999 - val_loss: 5.9790e-04 - val_acc: 0.9999\n",
      "Epoch 23/50\n",
      " - 40s - loss: 1.5088e-04 - acc: 1.0000 - val_loss: 5.9921e-04 - val_acc: 0.9999\n",
      "Epoch 24/50\n",
      " - 40s - loss: 1.2913e-04 - acc: 1.0000 - val_loss: 6.0133e-04 - val_acc: 0.9999\n",
      "Epoch 25/50\n",
      " - 40s - loss: 1.1390e-04 - acc: 1.0000 - val_loss: 6.0285e-04 - val_acc: 0.9999\n",
      "Epoch 26/50\n",
      " - 40s - loss: 1.8890e-04 - acc: 0.9999 - val_loss: 6.0376e-04 - val_acc: 0.9999\n",
      "Epoch 27/50\n",
      " - 40s - loss: 2.2600e-04 - acc: 0.9999 - val_loss: 6.0181e-04 - val_acc: 0.9999\n",
      "Epoch 28/50\n",
      " - 40s - loss: 1.4809e-04 - acc: 1.0000 - val_loss: 6.0463e-04 - val_acc: 0.9999\n",
      "Epoch 29/50\n",
      " - 40s - loss: 1.4755e-04 - acc: 1.0000 - val_loss: 6.0647e-04 - val_acc: 0.9999\n",
      "Epoch 30/50\n",
      " - 40s - loss: 1.5562e-04 - acc: 1.0000 - val_loss: 6.0819e-04 - val_acc: 0.9999\n",
      "Epoch 31/50\n",
      " - 40s - loss: 1.6343e-04 - acc: 1.0000 - val_loss: 6.0926e-04 - val_acc: 0.9999\n",
      "Epoch 32/50\n",
      " - 39s - loss: 1.2920e-04 - acc: 1.0000 - val_loss: 6.0889e-04 - val_acc: 0.9999\n",
      "Epoch 33/50\n",
      " - 40s - loss: 2.0525e-04 - acc: 0.9999 - val_loss: 6.0932e-04 - val_acc: 0.9999\n",
      "Epoch 34/50\n",
      " - 40s - loss: 2.0725e-04 - acc: 1.0000 - val_loss: 6.0875e-04 - val_acc: 0.9999\n",
      "Epoch 35/50\n",
      " - 40s - loss: 2.4830e-04 - acc: 0.9999 - val_loss: 6.0818e-04 - val_acc: 0.9999\n",
      "Epoch 36/50\n",
      " - 40s - loss: 1.6567e-04 - acc: 1.0000 - val_loss: 6.0838e-04 - val_acc: 0.9999\n",
      "Epoch 37/50\n",
      " - 40s - loss: 1.5685e-04 - acc: 1.0000 - val_loss: 6.0833e-04 - val_acc: 0.9999\n",
      "Epoch 38/50\n",
      " - 40s - loss: 1.5082e-04 - acc: 1.0000 - val_loss: 6.0877e-04 - val_acc: 0.9999\n",
      "Epoch 39/50\n",
      " - 40s - loss: 2.4150e-04 - acc: 0.9999 - val_loss: 6.0997e-04 - val_acc: 0.9999\n",
      "Epoch 40/50\n",
      " - 40s - loss: 1.5081e-04 - acc: 1.0000 - val_loss: 6.0989e-04 - val_acc: 0.9999\n",
      "Epoch 41/50\n",
      " - 39s - loss: 1.8038e-04 - acc: 1.0000 - val_loss: 6.0988e-04 - val_acc: 0.9999\n",
      "Epoch 42/50\n",
      " - 40s - loss: 1.7846e-04 - acc: 1.0000 - val_loss: 6.0994e-04 - val_acc: 0.9999\n",
      "Epoch 43/50\n",
      " - 40s - loss: 2.5169e-04 - acc: 0.9999 - val_loss: 6.0993e-04 - val_acc: 0.9999\n",
      "Epoch 44/50\n",
      " - 39s - loss: 1.1086e-04 - acc: 1.0000 - val_loss: 6.0993e-04 - val_acc: 0.9999\n",
      "Epoch 45/50\n",
      " - 40s - loss: 1.2648e-04 - acc: 1.0000 - val_loss: 6.0995e-04 - val_acc: 0.9999\n",
      "Epoch 46/50\n",
      " - 40s - loss: 1.1040e-04 - acc: 1.0000 - val_loss: 6.0995e-04 - val_acc: 0.9999\n",
      "Epoch 47/50\n",
      " - 39s - loss: 2.6213e-04 - acc: 1.0000 - val_loss: 6.0998e-04 - val_acc: 0.9999\n",
      "Epoch 48/50\n",
      " - 40s - loss: 1.2587e-04 - acc: 1.0000 - val_loss: 6.0998e-04 - val_acc: 0.9999\n",
      "Epoch 49/50\n",
      " - 40s - loss: 2.0899e-04 - acc: 0.9999 - val_loss: 6.0993e-04 - val_acc: 0.9999\n",
      "Epoch 50/50\n",
      " - 40s - loss: 1.5045e-04 - acc: 1.0000 - val_loss: 6.0995e-04 - val_acc: 0.9999\n"
     ]
    }
   ],
   "source": [
    "def lr_schedule(epoch):\n",
    "    return lr * (0.1 ** int(epoch / 10))\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "do_train_model=model.fit(X, Y,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2,verbose=2,\n",
    "          #np.resize(img, (-1, <image shape>)\n",
    "          callbacks=[LearningRateScheduler(lr_schedule),ModelCheckpoint(path+str(current_time)+'_new_model_'+str(epochs)+'.h5', save_best_only=True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "# model = load_model('/home/atif/machine_learning_stuff/model_file_keras/general_2_sep_ep_30_epoch.h5')\n",
    "model = load_model('/home/atif/machine_learning_stuff/model_file_keras/2019-09-12 19:40:27.274695_new_model_50.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check total accuracy of the model using all test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename:  denkmit_edelstahk_reiniger (1).jpg \t classId:  5\n",
      "filename:  denkmit_edelstahk_reiniger (2).jpg \t classId:  5\n",
      "filename:  denkmit_edelstahk_reiniger (3).jpg \t classId:  5\n",
      "filename:  denkmit_edelstahk_reiniger (4).jpg \t classId:  5\n",
      "filename:  denkmit_edelstahk_reiniger (5).jpg \t classId:  5\n",
      "filename:  denkmit_edelstahk_reiniger (6).jpg \t classId:  5\n",
      "filename:  denkmit_edelstahk_reiniger (7).jpg \t classId:  5\n",
      "filename:  denkmit_Entkalker (1).jpg \t classId:  7\n",
      "filename:  denkmit_Entkalker (2).jpg \t classId:  7\n",
      "filename:  denkmit_Entkalker (3).jpg \t classId:  7\n",
      "filename:  denkmit_Entkalker (4).jpg \t classId:  7\n",
      "filename:  denkmit_Entkalker (5).jpg \t classId:  7\n",
      "filename:  denkmit_Entkalker (6).jpg \t classId:  7\n",
      "filename:  denkmit_geschirrreiniger_REVOLUTION (1).jpg \t classId:  10\n",
      "filename:  denkmit_geschirrreiniger_REVOLUTION (2).jpg \t classId:  10\n",
      "filename:  denkmit_geschirrreiniger_REVOLUTION (3).jpg \t classId:  10\n",
      "filename:  denkmit_geschirrreiniger_REVOLUTION (4).jpg \t classId:  10\n",
      "filename:  denkmit_geschirrreiniger_REVOLUTION (5).jpg \t classId:  10\n",
      "filename:  denkmit_geschirrreiniger_REVOLUTION (6).jpg \t classId:  10\n",
      "filename:  Denkmit_geschirr_reiniger_classic (1).jpg \t classId:  9\n",
      "filename:  Denkmit_geschirr_reiniger_classic (3).jpg \t classId:  9\n",
      "filename:  Denkmit_geschirr_reiniger_classic (4).jpg \t classId:  9\n",
      "filename:  Denkmit_geschirr_reiniger_classic (5).jpg \t classId:  9\n",
      "filename:  Denkmit_geschirr_reiniger_classic (6).jpg \t classId:  9\n",
      "filename:  denkmit_geschirr_reiniger_multipower (1).jpg \t classId:  8\n",
      "filename:  denkmit_geschirr_reiniger_multipower (2).jpg \t classId:  8\n",
      "filename:  denkmit_geschirr_reiniger_multipower (3).jpg \t classId:  8\n",
      "filename:  denkmit_geschirr_reiniger_multipower (4).jpg \t classId:  8\n",
      "filename:  denkmit_geschirr_reiniger_multipower (5).jpg \t classId:  8\n",
      "filename:  denkmit_geschirr_reiniger_multipower (6).jpg \t classId:  8\n",
      "filename:  denkmit_geschirr_reiniger_NATURE (1).jpg \t classId:  11\n",
      "filename:  denkmit_geschirr_reiniger_NATURE (2).jpg \t classId:  11\n",
      "filename:  denkmit_geschirr_reiniger_NATURE (3).jpg \t classId:  11\n",
      "filename:  denkmit_geschirr_reiniger_NATURE (4).jpg \t classId:  11\n",
      "filename:  denkmit_geschirr_reiniger_NATURE (5).jpg \t classId:  11\n",
      "filename:  calgonit_finish_speizalsalz (3).jpg \t classId:  3\n",
      "filename:  Denkmit_geschirr_reiniger_classic (2).jpg \t classId:  9\n",
      "filename:  denkmit_hygiene_Allzweck_reiniger (1).jpg \t classId:  12\n",
      "filename:  denkmit_spezalsalz (4).jpg \t classId:  14\n",
      "filename:  calgonit_finish_speizalsalz (4).jpg \t classId:  3\n",
      "filename:  calgonit_finish_speizalsalz (5).jpg \t classId:  3\n",
      "filename:  calgonit_finish_speizalsalz (6).jpg \t classId:  3\n",
      "filename:  calgonit_maschine_pfleger (1).jpg \t classId:  2\n",
      "filename:  calgonit_maschine_pfleger (2).jpg \t classId:  2\n",
      "filename:  calgonit_maschine_pfleger (3).jpg \t classId:  2\n",
      "filename:  calgonit_maschine_pfleger (4).jpg \t classId:  2\n",
      "filename:  calgonit_finish_classic (1).jpg \t classId:  0\n",
      "filename:  calgonit_finish_classic (2).jpg \t classId:  0\n",
      "filename:  calgonit_finish_classic (3).jpg \t classId:  0\n",
      "filename:  calgonit_finish_classic (4).jpg \t classId:  0\n",
      "filename:  calgonit_finish_classic (5).jpg \t classId:  0\n",
      "filename:  calgonit_finish_klarspueler (1).jpg \t classId:  1\n",
      "filename:  calgonit_finish_klarspueler (2).jpg \t classId:  1\n",
      "filename:  calgonit_finish_klarspueler (3).jpg \t classId:  1\n",
      "filename:  calgonit_finish_klarspueler (4).jpg \t classId:  1\n",
      "filename:  calgonit_finish_klarspueler (5).jpg \t classId:  1\n",
      "filename:  calgonit_finish_klarspueler (6).jpg \t classId:  1\n",
      "filename:  calgonit_finish_speizalsalz (1).jpg \t classId:  3\n",
      "filename:  calgonit_finish_speizalsalz (2).jpg \t classId:  3\n",
      "filename:  denkmit_spezalsalz (5).jpg \t classId:  14\n",
      "filename:  denkmit_spezalsalz (6).jpg \t classId:  14\n",
      "filename:  denkmit_spezalsalz (7).jpg \t classId:  14\n",
      "filename:  denkmit_spezalsalz (8).jpg \t classId:  14\n",
      "filename:  denkmit_spezalsalz (9).jpg \t classId:  14\n",
      "filename:  somat (1).jpg \t classId:  15\n",
      "filename:  somat (2).jpg \t classId:  15\n",
      "filename:  somat_3.jpg \t classId:  15\n",
      "filename:  somat_4.jpg \t classId:  15\n",
      "filename:  somat_5.jpg \t classId:  15\n",
      "filename:  somat_6.jpg \t classId:  15\n",
      "filename:  somat_7.jpg \t classId:  15\n",
      "filename:  somat_8.jpg \t classId:  15\n",
      "filename:  denkmit_hygiene_Allzweck_reiniger (2).jpg \t classId:  12\n",
      "filename:  denkmit_hygiene_Allzweck_reiniger (3).jpg \t classId:  12\n",
      "filename:  denkmit_hygiene_Allzweck_reiniger (4).jpg \t classId:  12\n",
      "filename:  denkmit_hygiene_Allzweck_reiniger (5).jpg \t classId:  12\n",
      "filename:  denkmit_mascine_pfleger (1).jpg \t classId:  13\n",
      "filename:  denkmit_mascine_pfleger (2).jpg \t classId:  13\n",
      "filename:  denkmit_mascine_pfleger (3).jpg \t classId:  13\n",
      "filename:  denkmit_mascine_pfleger (4).jpg \t classId:  13\n",
      "filename:  denkmit_mascine_pfleger (5).jpg \t classId:  13\n",
      "filename:  denkmit_mascine_pfleger (6).jpg \t classId:  13\n",
      "filename:  denkmit_spezalsalz (1).jpg \t classId:  14\n",
      "filename:  denkmit_spezalsalz (2).jpg \t classId:  14\n",
      "filename:  denkmit_spezalsalz (3).jpg \t classId:  14\n",
      "filename:  2_SM_CalgonitFinishVorratspack_14_1_90_60_lit_cropped.jpg \t classId:  4\n",
      "filename:  3_SM_CalgonitFinishVorratspack_14_2_90_60_lit_cropped.jpg \t classId:  4\n",
      "filename:  34_SM_DenkMitEdelstahlReinigerSpray_20_33_90_60_lit_cropped.jpg \t classId:  6\n",
      "filename:  35_SM_DenkMitEdelstahlReinigerSpray_20_34_90_60_lit_cropped.jpg \t classId:  6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "test = pd.read_csv('/home/atif/machine_learning_stuff/ml_image/test_image_keras_IAI.csv',sep=';')\n",
    "# test_image_path =  '/home/atif/machine_learning_stuff/ml_image/test_image_crop/'\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "i = 0\n",
    "for file_name, class_id  in zip(list(test['Filename']), list(test['ClassId'])):\n",
    "    print('filename: ',file_name,'\\t classId: ',class_id)\n",
    "    #print('classId: ',class_id)\n",
    "    img_path = os.path.join('/home/atif/machine_learning_stuff/ml_image/test_image_26_aug/',file_name)\n",
    "#     img_path = glob.glob(os.path.join(test_image_path, '*/*.jpg'))\n",
    "    X_test.append(preprocess_img(io.imread(img_path)))\n",
    "    y_test.append(class_id)\n",
    "    \n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/atif/machine_learning_stuff/ml_image/test_image_26_aug/35_SM_DenkMitEdelstahlReinigerSpray_20_34_90_60_lit_cropped.jpg\n"
     ]
    }
   ],
   "source": [
    "print(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5,  5,  5,  5,  5,  5,  5,  7,  7,  7,  7,  7,  7, 10, 10, 10, 10,\n",
       "       10, 10,  9,  9,  9,  9,  9,  8,  8,  8,  8,  8,  8, 11, 11, 11, 11,\n",
       "       11,  3,  9, 12, 14,  3,  3,  3,  2,  2,  2,  2,  0,  0,  0,  0,  0,\n",
       "        1,  1,  1,  1,  1,  1,  3,  3, 14, 14, 14, 14, 14, 15, 15, 15, 15,\n",
       "       15, 15, 15, 15, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 14, 14, 14,\n",
       "        4,  4,  6,  6])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# finding accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy = 0.8202247191011236\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_test)\n",
    "acc = np.sum(y_pred==y_test)/np.size(y_pred)\n",
    "print(\"Test accuracy = {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check true vs true/false result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count =0\n",
    "right_count=0\n",
    "wrong_count=0\n",
    "for i,j in enumerate(y_test):\n",
    "    count +=1\n",
    "    if j == y_pred[i]:\n",
    "        right_count+=1\n",
    "#         print(count,'-'*5,j,'-'*5,y_pred[i])\n",
    "        \n",
    "    else:\n",
    "#         pass\n",
    "        wrong_count+=1\n",
    "        print(count,'°'*40,j,'-'*5,y_pred[i])\n",
    "print('total: ',count)\n",
    "print('right_count: ',right_count)\n",
    "print('wrong_count',wrong_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# do accuracy calculationfrom scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy = (right_count/y_pred.shape[0])*100\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# confusion matrix calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "results = confusion_matrix(y_test, y_pred)\n",
    "print(results)\n",
    "print(type(results))\n",
    "print(results.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# confusion matrix visualization with seaborn heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_cm = pd.DataFrame(results, range(16),\n",
    "                  range(16))\n",
    "plt.figure(figsize = (10,7))\n",
    "plt.tight_layout()\n",
    "sn.set(font_scale=1.4)#for label size\n",
    "\n",
    "ax = sn.heatmap(df_cm, annot=True,annot_kws={\"size\": 14},xticklabels=True, yticklabels=True)# font size\n",
    "ax.set(xlabel='predicted_class', ylabel='true_class')\n",
    "ax.set_ylim(16)\n",
    "figure = ax.get_figure()    \n",
    "# figure.savefig('2_sep_ax_conf.png', dpi=400)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# confusion matrix visualization with matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "plt.imshow(cm, cmap=plt.cm.Accent)\n",
    "plt.xlabel(\"Predicted labels\")\n",
    "plt.ylabel(\"True labels\")\n",
    "plt.xticks([], [])\n",
    "# plt.xticks(y_pred)\n",
    "plt.yticks([], [])\n",
    "# plt.xticks(y_test)\n",
    "plt.title('Confusion matrix ')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check class image by image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "test_image_path = r'/home/atif/machine_learning_stuff/ml_image/test_image_26_aug/'\n",
    "\n",
    "my_name = ['SM_CalgonitFinish_2','SM_CalgonitFinishKlarspueler_5','SM_CalgonitFinishMaschinenpfleger_8','SM_CalgonitFinishSpezialSalz_11',\n",
    "           'SM_CalgonitFinishVorratspack_14','SM_DenkMitEdelstahlreiniger_17','SM_DenkMitEdelstahlReinigerSpray_20','SM_DenkMitEntkalker_23',\n",
    "           'SM_DenkMitGeschirrReiniger_26','SM_DenkMitGeschirrReinigerClassic_29','SM_DenkMitGeschirrReinigerEvo_32','SM_DenkMitGeschirrReinigerNature_35',\n",
    "           'SM_DenkMitHygieneAllzweckreiniger_38','SM_DenkMitMaschinenpfleger_41','SM_DenkMitSpezialsalz_44','SM_SomatClassic_53']\n",
    "\n",
    "img_path = glob.glob(test_image_path+ '/*.jpg')\n",
    "for image in img_path:\n",
    "    X_test=[]\n",
    "    X_test.append(preprocess_img(io.imread(image)))\n",
    "    X_test = np.array(X_test)\n",
    "#     plt.imshow(X_test)\n",
    "    X_test = X_test.reshape(len(X_test),3,IMG_SIZE,IMG_SIZE)\n",
    "    \n",
    "    print('image name is: ',image)\n",
    "    predicted_class = model.predict_classes(X_test)\n",
    "    print(\"predicted class: \",predicted_class)\n",
    "#     print('type-of predicted calss: ', type(predicted_class))\n",
    "    print('class name is: ',my_name[predicted_class[0]])\n",
    "    \n",
    "#     probability = model.predict_proba(X_test)\n",
    "#     print(\"probability: \",probability)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training with data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    rescale=1/255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_augmentation = cnn_model()\n",
    "# let's train the model using SGD + momentum (how original).\n",
    "lr = 0.01\n",
    "sgd = SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_augmentation.compile(loss='categorical_crossentropy',\n",
    "          optimizer=sgd,\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    return lr*(0.1**int(epoch/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epoch = 50\n",
    "batch_size = 32\n",
    "model_augmentation.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),\n",
    "                            steps_per_epoch=X_train.shape[0],\n",
    "                            epochs=nb_epoch,\n",
    "                            validation_data=(X_val, Y_val),\n",
    "                            callbacks=[LearningRateScheduler(lr_schedule),\n",
    "                                       ModelCheckpoint(path+str(current_time)+'_AUGMENTATION_'+str(epochs)+'.h5',save_best_only=True)]\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.1.0'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
