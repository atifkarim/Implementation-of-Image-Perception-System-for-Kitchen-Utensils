{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook code for image preprocessing, raining and testing(image by image and overall accuracy) of UE4 image will be developed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/atif/iai_ml_venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/atif/iai_ml_venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/atif/iai_ml_venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/atif/iai_ml_venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/atif/iai_ml_venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/atif/iai_ml_venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/atif/iai_ml_venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/atif/iai_ml_venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/atif/iai_ml_venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/atif/iai_ml_venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/atif/iai_ml_venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/atif/iai_ml_venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from skimage import io, color, exposure, transform\n",
    "from skimage.color import rgb2gray\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split  #it came from update scikit learn. https://stackoverflow.com/questions/40704484/importerror-no-module-named-model-selection\n",
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "import keras\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D,Conv1D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_first')\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "from matplotlib.pylab import rcParams\n",
    "\n",
    "#import keras\n",
    "\n",
    "NUM_CLASSES = 16 # change it with respect to the desired class\n",
    "IMG_SIZE = 48 # change it if it desired\n",
    "IMG_depth = 3 # for RGB 3, for B&W it will be 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_img(img):\n",
    "    # Histogram normalization in y\n",
    "    hsv = color.rgb2hsv(img)\n",
    "    hsv[:,:,2] = exposure.equalize_hist(hsv[:,:,2])\n",
    "    img = color.hsv2rgb(hsv)\n",
    "\n",
    "    # central scrop\n",
    "    min_side = min(img.shape[:-1])\n",
    "    centre = img.shape[0]//2, img.shape[1]//2\n",
    "    img = img[centre[0]-min_side//2:centre[0]+min_side//2,centre[1]-min_side//2:centre[1]+min_side//2,:]\n",
    "#    img = rgb2gray(img)\n",
    "\n",
    "    # rescale to standard size\n",
    "    img = transform.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "    # roll color axis to axis 0\n",
    "    img = np.rollaxis(img,-1)\n",
    "\n",
    "    return img\n",
    "\n",
    "def get_class(img_path):\n",
    "    return int(img_path.split('/')[-2])\n",
    "#     return str(img_path.split('/')[-2]) # returning the folder name. If use -1 that means image name. consider the img_path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1200/7200\n",
      "Processed 2400/7200\n",
      "Processed 3600/7200\n",
      "Processed 4800/7200\n",
      "Processed 6000/7200\n",
      "Processed 7200/7200\n"
     ]
    }
   ],
   "source": [
    "imgs = []\n",
    "labels = []\n",
    "root_dir = '/home/atif/machine_learning_stuff/ml_image/copy_image/'\n",
    "#path='/home/atif/training_by_several_learning_process/flower_photos/00000/'\n",
    "\n",
    "#all_img_paths = glob.glob(path+ '5547758_eea9edfd54_n_000.jpg')\n",
    "\n",
    "all_img_paths = glob.glob(os.path.join(root_dir, '*/*.png')) #I have done the training with .png format image. If another type of image will come \n",
    "                                                                                    #them .png will be changed by that extension\n",
    "np.random.shuffle(all_img_paths)\n",
    "for img_path in all_img_paths:\n",
    "    try:\n",
    "        img = preprocess_img(io.imread(img_path))\n",
    "        label = get_class(img_path)\n",
    "        imgs.append(img)\n",
    "        labels.append(label)\n",
    "\n",
    "        if len(imgs)%1200 == 0: print(\"Processed {}/{}\".format(len(imgs), len(all_img_paths)))\n",
    "            #print(\"get it 2\")\n",
    "    except (IOError, OSError):\n",
    "        print('missed', img_path)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (7200, 3, 48, 48)  type:  <class 'numpy.ndarray'>\n",
      "Y shape:  (7200, 2)  type:  <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "X = np.array(imgs, dtype='float32') #Keeping the image as an array\n",
    "X = X.reshape(len(imgs),IMG_depth,IMG_SIZE,IMG_SIZE) # write (IMG_SIZE,IMG_SIZE,1 if you want channel last; 1= grayscale;3=RGB)\n",
    "# Y = np.eye(NUM_CLASSES, dtype='uint8')[labels]\n",
    "Y = keras.utils.to_categorical(labels, NUM_CLASSES)\n",
    "\n",
    "print('X shape: ', X.shape,' type: ',type(X))\n",
    "print('Y shape: ', Y.shape,' type: ',type(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                     input_shape=(3, IMG_SIZE, IMG_SIZE),\n",
    "                     activation='relu'))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same',\n",
    "                     activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same',\n",
    "                     activation='relu'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "model = cnn_model()\n",
    "\n",
    "lr = 0.01\n",
    "sgd = SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "          optimizer=sgd,\n",
    "          metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 48, 48)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 46, 46)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 23, 23)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 23, 23)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 64, 23, 23)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 64, 21, 21)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 64, 10, 10)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64, 10, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 128, 10, 10)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 128, 8, 8)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 128, 4, 4)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128, 4, 4)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 1,337,122\n",
      "Trainable params: 1,337,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/atif/machine_learning_stuff/model_file_keras/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0819 23:48:05.314949 140606987949888 deprecation.py:323] From /home/atif/iai_ml_venv/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0819 23:48:05.529354 140606987949888 variables.py:2445] Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n",
      "W0819 23:48:05.530908 140606987949888 deprecation.py:506] From /home/atif/iai_ml_venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:680: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5760 samples, validate on 1440 samples\n",
      "Epoch 1/1\n",
      " - 26s - loss: 0.2793 - acc: 0.8710 - val_loss: 0.0164 - val_acc: 0.9944\n"
     ]
    }
   ],
   "source": [
    "def lr_schedule(epoch):\n",
    "    return lr * (0.1 ** int(epoch / 10))\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 1\n",
    "do_train_model=model.fit(X, Y,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2,verbose=2,\n",
    "          #np.resize(img, (-1, <image shape>)\n",
    "          callbacks=[LearningRateScheduler(lr_schedule),ModelCheckpoint(path+'19_aug_ep_1_label_string.h5', save_best_only=True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('/home/atif/machine_learning_stuff/model_file_keras/model_augmentation_1_epoch_27_aug.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check total accuracy of the model using all test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename:  denkmit_edelstahk_reiniger (1).jpg \t classId:  5\n",
      "filename:  denkmit_edelstahk_reiniger (2).jpg \t classId:  5\n",
      "filename:  denkmit_edelstahk_reiniger (3).jpg \t classId:  5\n",
      "filename:  denkmit_edelstahk_reiniger (4).jpg \t classId:  5\n",
      "filename:  denkmit_edelstahk_reiniger (5).jpg \t classId:  5\n",
      "filename:  denkmit_edelstahk_reiniger (6).jpg \t classId:  5\n",
      "filename:  denkmit_edelstahk_reiniger (7).jpg \t classId:  5\n",
      "filename:  denkmit_Entkalker (1).jpg \t classId:  7\n",
      "filename:  denkmit_Entkalker (2).jpg \t classId:  7\n",
      "filename:  denkmit_Entkalker (3).jpg \t classId:  7\n",
      "filename:  denkmit_Entkalker (4).jpg \t classId:  7\n",
      "filename:  denkmit_Entkalker (5).jpg \t classId:  7\n",
      "filename:  denkmit_Entkalker (6).jpg \t classId:  7\n",
      "filename:  denkmit_geschirrreiniger_REVOLUTION (1).jpg \t classId:  10\n",
      "filename:  denkmit_geschirrreiniger_REVOLUTION (2).jpg \t classId:  10\n",
      "filename:  denkmit_geschirrreiniger_REVOLUTION (3).jpg \t classId:  10\n",
      "filename:  denkmit_geschirrreiniger_REVOLUTION (4).jpg \t classId:  10\n",
      "filename:  denkmit_geschirrreiniger_REVOLUTION (5).jpg \t classId:  10\n",
      "filename:  denkmit_geschirrreiniger_REVOLUTION (6).jpg \t classId:  10\n",
      "filename:  Denkmit_geschirr_reiniger_classic (1).jpg \t classId:  9\n",
      "filename:  Denkmit_geschirr_reiniger_classic (3).jpg \t classId:  9\n",
      "filename:  Denkmit_geschirr_reiniger_classic (4).jpg \t classId:  9\n",
      "filename:  Denkmit_geschirr_reiniger_classic (5).jpg \t classId:  9\n",
      "filename:  Denkmit_geschirr_reiniger_classic (6).jpg \t classId:  9\n",
      "filename:  denkmit_geschirr_reiniger_multipower (1).jpg \t classId:  8\n",
      "filename:  denkmit_geschirr_reiniger_multipower (2).jpg \t classId:  8\n",
      "filename:  denkmit_geschirr_reiniger_multipower (3).jpg \t classId:  8\n",
      "filename:  denkmit_geschirr_reiniger_multipower (4).jpg \t classId:  8\n",
      "filename:  denkmit_geschirr_reiniger_multipower (5).jpg \t classId:  8\n",
      "filename:  denkmit_geschirr_reiniger_multipower (6).jpg \t classId:  8\n",
      "filename:  denkmit_geschirr_reiniger_NATURE (1).jpg \t classId:  11\n",
      "filename:  denkmit_geschirr_reiniger_NATURE (2).jpg \t classId:  11\n",
      "filename:  denkmit_geschirr_reiniger_NATURE (3).jpg \t classId:  11\n",
      "filename:  denkmit_geschirr_reiniger_NATURE (4).jpg \t classId:  11\n",
      "filename:  denkmit_geschirr_reiniger_NATURE (5).jpg \t classId:  11\n",
      "filename:  calgonit_finish_speizalsalz (3).jpg \t classId:  3\n",
      "filename:  Denkmit_geschirr_reiniger_classic (2).jpg \t classId:  9\n",
      "filename:  denkmit_hygiene_Allzweck_reiniger (1).jpg \t classId:  12\n",
      "filename:  denkmit_spezalsalz (4).jpg \t classId:  14\n",
      "filename:  calgonit_finish_speizalsalz (4).jpg \t classId:  3\n",
      "filename:  calgonit_finish_speizalsalz (5).jpg \t classId:  3\n",
      "filename:  calgonit_finish_speizalsalz (6).jpg \t classId:  3\n",
      "filename:  calgonit_maschine_pfleger (1).jpg \t classId:  2\n",
      "filename:  calgonit_maschine_pfleger (2).jpg \t classId:  2\n",
      "filename:  calgonit_maschine_pfleger (3).jpg \t classId:  2\n",
      "filename:  calgonit_maschine_pfleger (4).jpg \t classId:  2\n",
      "filename:  calgonit_finish_classic (1).jpg \t classId:  0\n",
      "filename:  calgonit_finish_classic (2).jpg \t classId:  0\n",
      "filename:  calgonit_finish_classic (3).jpg \t classId:  0\n",
      "filename:  calgonit_finish_classic (4).jpg \t classId:  0\n",
      "filename:  calgonit_finish_classic (5).jpg \t classId:  0\n",
      "filename:  calgonit_finish_klarspueler (1).jpg \t classId:  1\n",
      "filename:  calgonit_finish_klarspueler (2).jpg \t classId:  1\n",
      "filename:  calgonit_finish_klarspueler (3).jpg \t classId:  1\n",
      "filename:  calgonit_finish_klarspueler (4).jpg \t classId:  1\n",
      "filename:  calgonit_finish_klarspueler (5).jpg \t classId:  1\n",
      "filename:  calgonit_finish_klarspueler (6).jpg \t classId:  1\n",
      "filename:  calgonit_finish_speizalsalz (1).jpg \t classId:  3\n",
      "filename:  calgonit_finish_speizalsalz (2).jpg \t classId:  3\n",
      "filename:  denkmit_spezalsalz (5).jpg \t classId:  14\n",
      "filename:  denkmit_spezalsalz (6).jpg \t classId:  14\n",
      "filename:  denkmit_spezalsalz (7).jpg \t classId:  14\n",
      "filename:  denkmit_spezalsalz (8).jpg \t classId:  14\n",
      "filename:  denkmit_spezalsalz (9).jpg \t classId:  14\n",
      "filename:  somat (1).jpg \t classId:  15\n",
      "filename:  somat (2).jpg \t classId:  15\n",
      "filename:  somat_3.jpg \t classId:  15\n",
      "filename:  somat_4.jpg \t classId:  15\n",
      "filename:  somat_5.jpg \t classId:  15\n",
      "filename:  somat_6.jpg \t classId:  15\n",
      "filename:  somat_7.jpg \t classId:  15\n",
      "filename:  somat_8.jpg \t classId:  15\n",
      "filename:  denkmit_hygiene_Allzweck_reiniger (2).jpg \t classId:  12\n",
      "filename:  denkmit_hygiene_Allzweck_reiniger (3).jpg \t classId:  12\n",
      "filename:  denkmit_hygiene_Allzweck_reiniger (4).jpg \t classId:  12\n",
      "filename:  denkmit_hygiene_Allzweck_reiniger (5).jpg \t classId:  12\n",
      "filename:  denkmit_mascine_pfleger (1).jpg \t classId:  13\n",
      "filename:  denkmit_mascine_pfleger (2).jpg \t classId:  13\n",
      "filename:  denkmit_mascine_pfleger (3).jpg \t classId:  13\n",
      "filename:  denkmit_mascine_pfleger (4).jpg \t classId:  13\n",
      "filename:  denkmit_mascine_pfleger (5).jpg \t classId:  13\n",
      "filename:  denkmit_mascine_pfleger (6).jpg \t classId:  13\n",
      "filename:  denkmit_spezalsalz (1).jpg \t classId:  14\n",
      "filename:  denkmit_spezalsalz (2).jpg \t classId:  14\n",
      "filename:  denkmit_spezalsalz (3).jpg \t classId:  14\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "test = pd.read_csv('/home/atif/machine_learning_stuff/ml_image/test_image_keras_IAI.csv',sep=';')\n",
    "# test_image_path =  '/home/atif/machine_learning_stuff/ml_image/test_image_crop/'\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "i = 0\n",
    "for file_name, class_id  in zip(list(test['Filename']), list(test['ClassId'])):\n",
    "    print('filename: ',file_name,'\\t classId: ',class_id)\n",
    "    #print('classId: ',class_id)\n",
    "    img_path = os.path.join('/home/atif/machine_learning_stuff/ml_image/test_image_26_aug/',file_name)\n",
    "#     img_path = glob.glob(os.path.join(test_image_path, '*/*.jpg'))\n",
    "    X_test.append(preprocess_img(io.imread(img_path)))\n",
    "    y_test.append(class_id)\n",
    "    \n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/atif/machine_learning_stuff/ml_image/test_image_26_aug/denkmit_spezalsalz (3).jpg\n"
     ]
    }
   ],
   "source": [
    "print(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5,  5,  5,  5,  5,  5,  5,  7,  7,  7,  7,  7,  7, 10, 10, 10, 10,\n",
       "       10, 10,  9,  9,  9,  9,  9,  8,  8,  8,  8,  8,  8, 11, 11, 11, 11,\n",
       "       11,  3,  9, 12, 14,  3,  3,  3,  2,  2,  2,  2,  0,  0,  0,  0,  0,\n",
       "        1,  1,  1,  1,  1,  1,  3,  3, 14, 14, 14, 14, 14, 15, 15, 15, 15,\n",
       "       15, 15, 15, 15, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 14, 14, 14])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy = 0.12941176470588237\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_test)\n",
    "acc = np.sum(y_pred==y_test)/np.size(y_pred)\n",
    "print(\"Test accuracy = {}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check class image by image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "test_image_path = r'/home/atif/machine_learning_stuff/ml_image/test_image_26_aug/'\n",
    "\n",
    "my_name = ['SM_CalgonitFinish_2','SM_CalgonitFinishKlarspueler_5','SM_CalgonitFinishMaschinenpfleger_8','SM_CalgonitFinishSpezialSalz_11',\n",
    "           'SM_CalgonitFinishVorratspack_14','SM_DenkMitEdelstahlreiniger_17','SM_DenkMitEdelstahlReinigerSpray_20','SM_DenkMitEntkalker_23',\n",
    "           'SM_DenkMitGeschirrReiniger_26','SM_DenkMitGeschirrReinigerClassic_29','SM_DenkMitGeschirrReinigerEvo_32','SM_DenkMitGeschirrReinigerNature_35',\n",
    "           'SM_DenkMitHygieneAllzweckreiniger_38','SM_DenkMitMaschinenpfleger_41','SM_DenkMitSpezialsalz_44','SM_SomatClassic_53']\n",
    "\n",
    "img_path = glob.glob(test_image_path+ '/*.jpg')\n",
    "for image in img_path:\n",
    "    X_test=[]\n",
    "    X_test.append(preprocess_img(io.imread(image)))\n",
    "    X_test = np.array(X_test)\n",
    "#     plt.imshow(X_test)\n",
    "    X_test = X_test.reshape(len(X_test),3,IMG_SIZE,IMG_SIZE)\n",
    "    \n",
    "    print('image name is: ',image)\n",
    "    predicted_class = model.predict_classes(X_test)\n",
    "    print(\"predicted class: \",predicted_class)\n",
    "#     print('type-of predicted calss: ', type(predicted_class))\n",
    "    print('class name is: ',my_name[predicted_class[0]])\n",
    "    \n",
    "#     probability = model.predict_proba(X_test)\n",
    "#     print(\"probability: \",probability)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training with data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "datagen = ImageDataGenerator(featurewise_center=False, \n",
    "                            featurewise_std_normalization=False, \n",
    "                            width_shift_range=0.1,\n",
    "                            height_shift_range=0.1,\n",
    "                            zoom_range=0.2,\n",
    "                            shear_range=0.1,\n",
    "                            rotation_range=10.,)\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_augmentation = cnn_model()\n",
    "# let's train the model using SGD + momentum (how original).\n",
    "lr = 0.01\n",
    "sgd = SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_augmentation.compile(loss='categorical_crossentropy',\n",
    "          optimizer=sgd,\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    return lr*(0.1**int(epoch/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "5760/5760 [==============================] - 841s 146ms/step - loss: 0.0426 - acc: 0.9840 - val_loss: 3.2677e-05 - val_acc: 1.0000\n",
      "Epoch 2/30\n",
      "5760/5760 [==============================] - 870s 151ms/step - loss: 0.0021 - acc: 0.9993 - val_loss: 7.7081e-06 - val_acc: 1.0000\n",
      "Epoch 3/30\n",
      "5760/5760 [==============================] - 871s 151ms/step - loss: 0.0019 - acc: 0.9995 - val_loss: 1.8673e-06 - val_acc: 1.0000\n",
      "Epoch 4/30\n",
      "5760/5760 [==============================] - 881s 153ms/step - loss: 3.9565e-04 - acc: 0.9999 - val_loss: 1.6942e-07 - val_acc: 1.0000\n",
      "Epoch 5/30\n",
      "5760/5760 [==============================] - 920s 160ms/step - loss: 0.0011 - acc: 0.9997 - val_loss: 5.2300e-06 - val_acc: 1.0000\n",
      "Epoch 6/30\n",
      "5760/5760 [==============================] - 844s 147ms/step - loss: 1.4314e-04 - acc: 1.0000 - val_loss: 4.1631e-07 - val_acc: 1.0000\n",
      "Epoch 7/30\n",
      "5760/5760 [==============================] - 845s 147ms/step - loss: 5.7142e-05 - acc: 1.0000 - val_loss: 1.3962e-07 - val_acc: 1.0000\n",
      "Epoch 8/30\n",
      "2853/5760 [=============>................] - ETA: 7:04 - loss: 2.1517e-05 - acc: 1.0000"
     ]
    }
   ],
   "source": [
    "nb_epoch = 30\n",
    "batch_size = 32\n",
    "model_augmentation.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),\n",
    "                            steps_per_epoch=X_train.shape[0],\n",
    "                            epochs=nb_epoch,\n",
    "                            validation_data=(X_val, Y_val),\n",
    "                            callbacks=[LearningRateScheduler(lr_schedule),\n",
    "                                       ModelCheckpoint(path+'model_augmentation_30_epoch_27_aug.h5',save_best_only=True)]\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
