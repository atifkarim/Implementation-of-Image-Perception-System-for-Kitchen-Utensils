{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from skimage import io, color, exposure, transform\n",
    "from skimage.color import rgb2gray\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split  #it came from update scikit learn. https://stackoverflow.com/questions/40704484/importerror-no-module-named-model-selection\n",
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D,Conv1D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_first')\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "#%matplotlib inline\n",
    "\n",
    "#import keras\n",
    "\n",
    "NUM_CLASSES = 5\n",
    "IMG_SIZE = 48\n",
    "IMG_depth = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_img(img):\n",
    "    # Histogram normalization in y\n",
    "    hsv = color.rgb2hsv(img)\n",
    "    hsv[:,:,2] = exposure.equalize_hist(hsv[:,:,2])\n",
    "    img = color.hsv2rgb(hsv)\n",
    "\n",
    "    # central scrop\n",
    "    min_side = min(img.shape[:-1])\n",
    "    centre = img.shape[0]//2, img.shape[1]//2\n",
    "    img = img[centre[0]-min_side//2:centre[0]+min_side//2,centre[1]-min_side//2:centre[1]+min_side//2,:]\n",
    "#    img = rgb2gray(img)\n",
    "\n",
    "    # rescale to standard size\n",
    "    img = transform.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "    # roll color axis to axis 0\n",
    "    img = np.rollaxis(img,-1)\n",
    "\n",
    "    return img\n",
    "\n",
    "def get_class(img_path):\n",
    "    return int(img_path.split('/')[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atif/anaconda3/envs/venv/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/home/atif/anaconda3/envs/venv/lib/python3.6/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "/home/atif/anaconda3/envs/venv/lib/python3.6/site-packages/skimage/color/colorconv.py:283: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  out[idx, 0] = 4. + (arr[idx, 0] - arr[idx, 1]) / delta[idx]\n",
      "/home/atif/anaconda3/envs/venv/lib/python3.6/site-packages/skimage/color/colorconv.py:275: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  out[idx, 0] = (arr[idx, 1] - arr[idx, 2]) / delta[idx]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1000/5400\n",
      "Processed 2000/5400\n",
      "Processed 3000/5400\n",
      "Processed 4000/5400\n",
      "Processed 5000/5400\n"
     ]
    }
   ],
   "source": [
    "imgs = []\n",
    "labels = []\n",
    "root_dir = '/media/atif/0820209220208930/unreal_cv_documentation/ignore_from_git/train_image_AI/'\n",
    "#path='/home/atif/training_by_several_learning_process/flower_photos/00000/'\n",
    "\n",
    "#all_img_paths = glob.glob(path+ '5547758_eea9edfd54_n_000.jpg')\n",
    "\n",
    "all_img_paths = glob.glob(os.path.join(root_dir, '*/*.png')) #I have done the training with .ppm format image. If another type of image will come \n",
    "                                                                                    #them .ppm will be changed by that extension\n",
    "np.random.shuffle(all_img_paths)\n",
    "for img_path in all_img_paths:\n",
    "    try:\n",
    "        img = preprocess_img(io.imread(img_path))\n",
    "        label = get_class(img_path)\n",
    "        imgs.append(img)\n",
    "        labels.append(label)\n",
    "\n",
    "        if len(imgs)%1000 == 0: print(\"Processed {}/{}\".format(len(imgs), len(all_img_paths)))\n",
    "            #print(\"get it 2\")\n",
    "    except (IOError, OSError):\n",
    "        print('missed', img_path)\n",
    "        pass\n",
    "\n",
    "X = np.array(imgs, dtype='float32') #Keeping the image as an array\n",
    "Y = np.eye(NUM_CLASSES, dtype='uint8')[labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5400, 3, 48, 48)\n",
      "4\n",
      "(3, 48, 48)\n",
      "(5400, 3, 48, 48)\n",
      "(5400, 5)\n"
     ]
    }
   ],
   "source": [
    "X = X.reshape(len(imgs),IMG_depth,IMG_SIZE,IMG_SIZE) # write (IMG_SIZE,IMG_SIZE,1 if you want channel last; 1= grayscale;3=RGB)\n",
    "# plt.imshow(X[0],cmap=\"gray\")\n",
    "print(X.shape)\n",
    "print(X.ndim)\n",
    "print(X[0].shape)\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                     input_shape=(3, IMG_SIZE, IMG_SIZE),\n",
    "                     activation='relu'))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same',\n",
    "                     activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same',\n",
    "                     activation='relu'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "model = cnn_model()\n",
    "\n",
    "lr = 0.01\n",
    "sgd = SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "          optimizer=sgd,\n",
    "          metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 48, 48)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 46, 46)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 23, 23)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 23, 23)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 64, 23, 23)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 64, 21, 21)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 64, 10, 10)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64, 10, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 128, 10, 10)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 128, 8, 8)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 128, 4, 4)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128, 4, 4)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 1,338,661\n",
      "Trainable params: 1,338,661\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4320 samples, validate on 1080 samples\n",
      "Epoch 1/50\n",
      "4320/4320 [==============================] - 149s 34ms/step - loss: 1.5412 - acc: 0.2933 - val_loss: 1.2160 - val_acc: 0.5269\n",
      "Epoch 2/50\n",
      "4320/4320 [==============================] - 184s 43ms/step - loss: 0.7465 - acc: 0.7299 - val_loss: 0.1564 - val_acc: 0.9620\n",
      "Epoch 3/50\n",
      "4320/4320 [==============================] - 207s 48ms/step - loss: 0.2080 - acc: 0.9294 - val_loss: 0.0398 - val_acc: 0.9870\n",
      "Epoch 4/50\n",
      "4320/4320 [==============================] - 183s 42ms/step - loss: 0.0723 - acc: 0.9759 - val_loss: 0.0227 - val_acc: 0.9954\n",
      "Epoch 5/50\n",
      "4320/4320 [==============================] - 220s 51ms/step - loss: 0.0524 - acc: 0.9843 - val_loss: 0.0117 - val_acc: 0.9944\n",
      "Epoch 6/50\n",
      "4320/4320 [==============================] - 193s 45ms/step - loss: 0.0291 - acc: 0.9912 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 7/50\n",
      "4320/4320 [==============================] - 198s 46ms/step - loss: 0.0316 - acc: 0.9910 - val_loss: 0.0023 - val_acc: 0.9991\n",
      "Epoch 8/50\n",
      "4320/4320 [==============================] - 194s 45ms/step - loss: 0.0110 - acc: 0.9956 - val_loss: 4.1673e-05 - val_acc: 1.0000\n",
      "Epoch 9/50\n",
      "4320/4320 [==============================] - 179s 41ms/step - loss: 0.0271 - acc: 0.9931 - val_loss: 0.0126 - val_acc: 0.9963\n",
      "Epoch 10/50\n",
      "4320/4320 [==============================] - 133s 31ms/step - loss: 0.0272 - acc: 0.9919 - val_loss: 0.0060 - val_acc: 0.9981\n",
      "Epoch 11/50\n",
      "4320/4320 [==============================] - 129s 30ms/step - loss: 0.0087 - acc: 0.9977 - val_loss: 5.1637e-04 - val_acc: 1.0000\n",
      "Epoch 12/50\n",
      "4320/4320 [==============================] - 128s 30ms/step - loss: 0.0030 - acc: 0.9993 - val_loss: 4.2375e-04 - val_acc: 1.0000\n",
      "Epoch 13/50\n",
      "4320/4320 [==============================] - 128s 30ms/step - loss: 0.0029 - acc: 0.9991 - val_loss: 2.9189e-04 - val_acc: 1.0000\n",
      "Epoch 14/50\n",
      "4320/4320 [==============================] - 128s 30ms/step - loss: 0.0019 - acc: 0.9993 - val_loss: 1.5270e-04 - val_acc: 1.0000\n",
      "Epoch 15/50\n",
      "4320/4320 [==============================] - 127s 29ms/step - loss: 0.0018 - acc: 0.9993 - val_loss: 8.9002e-05 - val_acc: 1.0000\n",
      "Epoch 16/50\n",
      "4320/4320 [==============================] - 128s 30ms/step - loss: 0.0014 - acc: 0.9993 - val_loss: 6.9990e-05 - val_acc: 1.0000\n",
      "Epoch 17/50\n",
      "4320/4320 [==============================] - 127s 29ms/step - loss: 8.1878e-04 - acc: 1.0000 - val_loss: 1.3489e-04 - val_acc: 1.0000\n",
      "Epoch 18/50\n",
      "4320/4320 [==============================] - 128s 30ms/step - loss: 0.0011 - acc: 0.9998 - val_loss: 8.5364e-05 - val_acc: 1.0000\n",
      "Epoch 19/50\n",
      "4320/4320 [==============================] - 127s 30ms/step - loss: 5.2604e-04 - acc: 1.0000 - val_loss: 8.6834e-05 - val_acc: 1.0000\n",
      "Epoch 20/50\n",
      "4320/4320 [==============================] - 128s 30ms/step - loss: 0.0021 - acc: 0.9995 - val_loss: 5.7980e-05 - val_acc: 1.0000\n",
      "Epoch 21/50\n",
      "4320/4320 [==============================] - 127s 30ms/step - loss: 9.8549e-04 - acc: 0.9995 - val_loss: 5.7559e-05 - val_acc: 1.0000\n",
      "Epoch 22/50\n",
      "4320/4320 [==============================] - 128s 30ms/step - loss: 8.8018e-04 - acc: 1.0000 - val_loss: 5.4100e-05 - val_acc: 1.0000\n",
      "Epoch 23/50\n",
      "4320/4320 [==============================] - 128s 30ms/step - loss: 9.6128e-04 - acc: 0.9998 - val_loss: 5.5016e-05 - val_acc: 1.0000\n",
      "Epoch 24/50\n",
      "4320/4320 [==============================] - 127s 29ms/step - loss: 0.0019 - acc: 0.9991 - val_loss: 6.5545e-05 - val_acc: 1.0000\n",
      "Epoch 25/50\n",
      "4320/4320 [==============================] - 128s 30ms/step - loss: 8.1138e-04 - acc: 1.0000 - val_loss: 6.4024e-05 - val_acc: 1.0000\n",
      "Epoch 26/50\n",
      "4320/4320 [==============================] - 129s 30ms/step - loss: 0.0010 - acc: 0.9995 - val_loss: 6.4839e-05 - val_acc: 1.0000\n",
      "Epoch 27/50\n",
      "4320/4320 [==============================] - 128s 30ms/step - loss: 0.0030 - acc: 0.9995 - val_loss: 6.3474e-05 - val_acc: 1.0000\n",
      "Epoch 28/50\n",
      "4320/4320 [==============================] - 128s 30ms/step - loss: 0.0038 - acc: 0.9991 - val_loss: 6.3346e-05 - val_acc: 1.0000\n",
      "Epoch 29/50\n",
      "4320/4320 [==============================] - 128s 30ms/step - loss: 0.0011 - acc: 0.9998 - val_loss: 5.4156e-05 - val_acc: 1.0000\n",
      "Epoch 30/50\n",
      "4320/4320 [==============================] - 128s 30ms/step - loss: 0.0020 - acc: 0.9993 - val_loss: 6.8983e-05 - val_acc: 1.0000\n",
      "Epoch 31/50\n",
      "4320/4320 [==============================] - 128s 30ms/step - loss: 9.7079e-04 - acc: 1.0000 - val_loss: 6.9168e-05 - val_acc: 1.0000\n",
      "Epoch 32/50\n",
      "4320/4320 [==============================] - 128s 30ms/step - loss: 0.0020 - acc: 0.9995 - val_loss: 6.9057e-05 - val_acc: 1.0000\n",
      "Epoch 33/50\n",
      "4320/4320 [==============================] - 128s 30ms/step - loss: 8.4859e-04 - acc: 1.0000 - val_loss: 6.8289e-05 - val_acc: 1.0000\n",
      "Epoch 34/50\n",
      "4320/4320 [==============================] - 128s 30ms/step - loss: 7.3716e-04 - acc: 1.0000 - val_loss: 6.8549e-05 - val_acc: 1.0000\n",
      "Epoch 35/50\n",
      "4320/4320 [==============================] - 128s 30ms/step - loss: 7.4976e-04 - acc: 0.9998 - val_loss: 6.8397e-05 - val_acc: 1.0000\n",
      "Epoch 36/50\n",
      "4320/4320 [==============================] - 128s 30ms/step - loss: 9.9662e-04 - acc: 0.9998 - val_loss: 6.8506e-05 - val_acc: 1.0000\n",
      "Epoch 37/50\n",
      "4320/4320 [==============================] - 128s 30ms/step - loss: 9.2271e-04 - acc: 0.9998 - val_loss: 6.8755e-05 - val_acc: 1.0000\n",
      "Epoch 38/50\n",
      "4320/4320 [==============================] - 128s 30ms/step - loss: 4.1308e-04 - acc: 1.0000 - val_loss: 6.8630e-05 - val_acc: 1.0000\n",
      "Epoch 39/50\n",
      "4320/4320 [==============================] - 128s 30ms/step - loss: 0.0017 - acc: 0.9993 - val_loss: 6.8747e-05 - val_acc: 1.0000\n",
      "Epoch 40/50\n",
      "4320/4320 [==============================] - 128s 30ms/step - loss: 9.0814e-04 - acc: 1.0000 - val_loss: 6.8551e-05 - val_acc: 1.0000\n",
      "Epoch 41/50\n",
      "4320/4320 [==============================] - 128s 30ms/step - loss: 4.7368e-04 - acc: 1.0000 - val_loss: 6.8412e-05 - val_acc: 1.0000\n",
      "Epoch 42/50\n",
      "4320/4320 [==============================] - 128s 30ms/step - loss: 9.0933e-04 - acc: 0.9998 - val_loss: 6.8447e-05 - val_acc: 1.0000\n",
      "Epoch 43/50\n",
      "4320/4320 [==============================] - 128s 30ms/step - loss: 0.0012 - acc: 0.9995 - val_loss: 6.8513e-05 - val_acc: 1.0000\n",
      "Epoch 44/50\n",
      "4320/4320 [==============================] - 128s 30ms/step - loss: 0.0011 - acc: 0.9998 - val_loss: 6.8454e-05 - val_acc: 1.0000\n",
      "Epoch 45/50\n",
      "4320/4320 [==============================] - 128s 30ms/step - loss: 9.9259e-04 - acc: 0.9998 - val_loss: 6.8387e-05 - val_acc: 1.0000\n",
      "Epoch 46/50\n",
      "4320/4320 [==============================] - 127s 30ms/step - loss: 0.0014 - acc: 0.9995 - val_loss: 6.8376e-05 - val_acc: 1.0000\n",
      "Epoch 47/50\n",
      "4320/4320 [==============================] - 127s 29ms/step - loss: 9.1658e-04 - acc: 0.9995 - val_loss: 6.8315e-05 - val_acc: 1.0000\n",
      "Epoch 48/50\n",
      "4320/4320 [==============================] - 127s 29ms/step - loss: 8.4295e-04 - acc: 1.0000 - val_loss: 6.8326e-05 - val_acc: 1.0000\n",
      "Epoch 49/50\n",
      "4320/4320 [==============================] - 127s 30ms/step - loss: 0.0010 - acc: 0.9998 - val_loss: 6.8398e-05 - val_acc: 1.0000\n",
      "Epoch 50/50\n",
      "4320/4320 [==============================] - 163s 38ms/step - loss: 0.0015 - acc: 0.9995 - val_loss: 6.8474e-05 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f68a1c0c2e8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lr_schedule(epoch):\n",
    "    return lr * (0.1 ** int(epoch / 10))\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "model.fit(X, Y,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2,\n",
    "          #np.resize(img, (-1, <image shape>)\n",
    "          callbacks=[LearningRateScheduler(lr_schedule),ModelCheckpoint('/media/atif/0820209220208930/unreal_cv_documentation/ignore_from_git/trained_file_AI/trained_UE4_first.h5', save_best_only=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atif/anaconda3/envs/venv/lib/python3.6/site-packages/skimage/color/colorconv.py:283: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  out[idx, 0] = 4. + (arr[idx, 0] - arr[idx, 1]) / delta[idx]\n",
      "/home/atif/anaconda3/envs/venv/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/home/atif/anaconda3/envs/venv/lib/python3.6/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " /media/atif/0820209220208930/unreal_cv_documentation/ignore_from_git/test_image_AI/calgonit_finish_1035.png\n",
      "predicted class:  [4]\n",
      "probability:  [[5.0177057e-10 1.0891918e-07 1.1687316e-13 1.2897646e-14 9.9999988e-01]]\n",
      "\n",
      " /media/atif/0820209220208930/unreal_cv_documentation/ignore_from_git/test_image_AI/calgonit_finish_24.png\n",
      "predicted class:  [4]\n",
      "probability:  [[3.1424308e-15 1.0334130e-16 2.2029010e-24 4.2919256e-19 1.0000000e+00]]\n",
      "\n",
      " /media/atif/0820209220208930/unreal_cv_documentation/ignore_from_git/test_image_AI/calgonit_finish_435.png\n",
      "predicted class:  [4]\n",
      "probability:  [[8.3640532e-07 2.5469612e-07 4.1909775e-08 3.0858408e-07 9.9999857e-01]]\n",
      "\n",
      " /media/atif/0820209220208930/unreal_cv_documentation/ignore_from_git/test_image_AI/calgonit_finish_824.png\n",
      "predicted class:  [4]\n",
      "probability:  [[2.7730483e-08 1.1543107e-06 1.0534397e-09 3.1265267e-07 9.9999845e-01]]\n",
      "\n",
      " /media/atif/0820209220208930/unreal_cv_documentation/ignore_from_git/test_image_AI/calgonit_finish_974.png\n",
      "predicted class:  [4]\n",
      "probability:  [[4.6088249e-07 3.2352163e-09 2.3988253e-10 2.9763393e-11 9.9999952e-01]]\n",
      "\n",
      " /media/atif/0820209220208930/unreal_cv_documentation/ignore_from_git/test_image_AI/chair_1034.png\n",
      "predicted class:  [0]\n",
      "probability:  [[1.0000000e+00 3.8742352e-13 5.7135923e-14 2.4194719e-14 9.1844560e-18]]\n",
      "\n",
      " /media/atif/0820209220208930/unreal_cv_documentation/ignore_from_git/test_image_AI/chair_105.png\n",
      "predicted class:  [0]\n",
      "probability:  [[1.0000000e+00 3.3266599e-12 2.7822232e-08 1.8163380e-12 2.7262977e-12]]\n",
      "\n",
      " /media/atif/0820209220208930/unreal_cv_documentation/ignore_from_git/test_image_AI/chair_22.png\n",
      "predicted class:  [0]\n",
      "probability:  [[1.0000000e+00 7.7961084e-12 1.4147568e-16 7.4786905e-16 1.1952255e-12]]\n",
      "\n",
      " /media/atif/0820209220208930/unreal_cv_documentation/ignore_from_git/test_image_AI/chair_485.png\n",
      "predicted class:  [0]\n",
      "probability:  [[1.0000000e+00 1.6284754e-15 2.0020189e-16 3.0539948e-09 3.1675187e-11]]\n",
      "\n",
      " /media/atif/0820209220208930/unreal_cv_documentation/ignore_from_git/test_image_AI/chair_904.png\n",
      "predicted class:  [0]\n",
      "probability:  [[1.0000000e+00 1.6925262e-15 1.5933259e-16 1.3326584e-12 2.1720046e-14]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atif/anaconda3/envs/venv/lib/python3.6/site-packages/skimage/color/colorconv.py:275: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  out[idx, 0] = (arr[idx, 1] - arr[idx, 2]) / delta[idx]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " /media/atif/0820209220208930/unreal_cv_documentation/ignore_from_git/test_image_AI/rock_44.png\n",
      "predicted class:  [1]\n",
      "probability:  [[2.1815778e-05 9.9990058e-01 4.1056985e-08 7.1170070e-05 6.4108613e-06]]\n",
      "\n",
      " /media/atif/0820209220208930/unreal_cv_documentation/ignore_from_git/test_image_AI/rock_875.png\n",
      "predicted class:  [1]\n",
      "probability:  [[1.0950030e-08 1.0000000e+00 1.1585048e-09 3.7393374e-08 2.9445759e-09]]\n",
      "\n",
      " /media/atif/0820209220208930/unreal_cv_documentation/ignore_from_git/test_image_AI/somat_1004.png\n",
      "predicted class:  [3]\n",
      "probability:  [[3.0130477e-13 1.6989387e-09 3.7450887e-09 1.0000000e+00 1.5859566e-18]]\n",
      "\n",
      " /media/atif/0820209220208930/unreal_cv_documentation/ignore_from_git/test_image_AI/somat_34.png\n",
      "predicted class:  [3]\n",
      "probability:  [[3.663658e-11 5.127386e-11 9.343606e-10 1.000000e+00 2.028886e-08]]\n",
      "\n",
      " /media/atif/0820209220208930/unreal_cv_documentation/ignore_from_git/test_image_AI/somat_374.png\n",
      "predicted class:  [3]\n",
      "probability:  [[2.4770513e-10 9.1767366e-10 3.4991489e-11 1.0000000e+00 7.7192636e-10]]\n",
      "\n",
      " /media/atif/0820209220208930/unreal_cv_documentation/ignore_from_git/test_image_AI/somat_553.png\n",
      "predicted class:  [3]\n",
      "probability:  [[1.0075657e-07 1.2770819e-09 7.8696110e-07 9.9999917e-01 1.6626490e-12]]\n",
      "\n",
      " /media/atif/0820209220208930/unreal_cv_documentation/ignore_from_git/test_image_AI/somat_74.png\n",
      "predicted class:  [3]\n",
      "probability:  [[1.0007757e-06 1.4909112e-04 6.4680105e-05 9.9452025e-01 5.2650142e-03]]\n",
      "\n",
      " /media/atif/0820209220208930/unreal_cv_documentation/ignore_from_git/test_image_AI/table_1044.png\n",
      "predicted class:  [2]\n",
      "probability:  [[3.43165157e-19 1.22115365e-20 1.00000000e+00 4.28298914e-22\n",
      "  1.57831503e-34]]\n",
      "\n",
      " /media/atif/0820209220208930/unreal_cv_documentation/ignore_from_git/test_image_AI/table_555.png\n",
      "predicted class:  [2]\n",
      "probability:  [[1.0585591e-28 4.5893789e-26 1.0000000e+00 2.0132402e-22 1.5604969e-36]]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('/media/atif/0820209220208930/unreal_cv_documentation/ignore_from_git/trained_file_AI/trained_UE4_first.h5')\n",
    "#for gray scale\n",
    "def preprocess_img(img):\n",
    "#     Histogram normalization in y\n",
    "    hsv = color.rgb2hsv(img)\n",
    "    hsv[:,:,2] = exposure.equalize_hist(hsv[:,:,2])\n",
    "    img = color.hsv2rgb(hsv)\n",
    "\n",
    "    # central scrop\n",
    "    min_side = min(img.shape[:-1])\n",
    "    centre = img.shape[0]//2, img.shape[1]//2\n",
    "    img = img[centre[0]-min_side//2:centre[0]+min_side//2,\n",
    "              centre[1]-min_side//2:centre[1]+min_side//2,\n",
    "              :]\n",
    "#     img = rgb2gray(img)\n",
    "\n",
    "    # rescale to standard size\n",
    "    img = transform.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "    # roll color axis to axis 0\n",
    "    img = np.rollaxis(img,-1)\n",
    "\n",
    "    return img\n",
    "\n",
    "import glob\n",
    "\n",
    "path = r'/media/atif/0820209220208930/unreal_cv_documentation/ignore_from_git/test_image_AI/'\n",
    "\n",
    "img_path = glob.glob(path+ '/*.png')\n",
    "for image in img_path:\n",
    "    X_test=[]\n",
    "    X_test.append(preprocess_img(io.imread(image)))\n",
    "    X_test = np.array(X_test)\n",
    "#     plt.imshow(X_test)\n",
    "    X_test = X_test.reshape(len(X_test),3,IMG_SIZE,IMG_SIZE)\n",
    "    \n",
    "    print(\"\\n\",image)\n",
    "    predicted_class = model.predict_classes(X_test)\n",
    "    print(\"predicted class: \",predicted_class)\n",
    "    \n",
    "    probability = model.predict_proba(X_test)\n",
    "    print(\"probability: \",probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
