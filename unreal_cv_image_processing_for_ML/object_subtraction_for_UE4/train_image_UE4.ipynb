{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from skimage import io, color, exposure, transform\n",
    "from skimage.color import rgb2gray\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split  #it came from update scikit learn. https://stackoverflow.com/questions/40704484/importerror-no-module-named-model-selection\n",
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D,Conv1D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_first')\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "#%matplotlib inline\n",
    "\n",
    "#import keras\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "IMG_SIZE = 48\n",
    "IMG_depth = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_img(img):\n",
    "    # Histogram normalization in y\n",
    "    hsv = color.rgb2hsv(img)\n",
    "    hsv[:,:,2] = exposure.equalize_hist(hsv[:,:,2])\n",
    "    img = color.hsv2rgb(hsv)\n",
    "\n",
    "    # central scrop\n",
    "    min_side = min(img.shape[:-1])\n",
    "    centre = img.shape[0]//2, img.shape[1]//2\n",
    "    img = img[centre[0]-min_side//2:centre[0]+min_side//2,centre[1]-min_side//2:centre[1]+min_side//2,:]\n",
    "#    img = rgb2gray(img)\n",
    "\n",
    "    # rescale to standard size\n",
    "    img = transform.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "    # roll color axis to axis 0\n",
    "    img = np.rollaxis(img,-1)\n",
    "\n",
    "    return img\n",
    "\n",
    "def get_class(img_path):\n",
    "    return int(img_path.split('/')[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atif/anaconda3/envs/venv/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/home/atif/anaconda3/envs/venv/lib/python3.6/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "/home/atif/anaconda3/envs/venv/lib/python3.6/site-packages/skimage/color/colorconv.py:283: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  out[idx, 0] = 4. + (arr[idx, 0] - arr[idx, 1]) / delta[idx]\n",
      "/home/atif/anaconda3/envs/venv/lib/python3.6/site-packages/skimage/color/colorconv.py:275: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  out[idx, 0] = (arr[idx, 1] - arr[idx, 2]) / delta[idx]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1000/2160\n",
      "Processed 2000/2160\n"
     ]
    }
   ],
   "source": [
    "imgs = []\n",
    "labels = []\n",
    "root_dir = '/media/atif/0820209220208930/unreal_cv_documentation/ignore_from_git/keras_graph_AI/train/'\n",
    "#path='/home/atif/training_by_several_learning_process/flower_photos/00000/'\n",
    "\n",
    "#all_img_paths = glob.glob(path+ '5547758_eea9edfd54_n_000.jpg')\n",
    "\n",
    "all_img_paths = glob.glob(os.path.join(root_dir, '*/*.png')) #I have done the training with .ppm format image. If another type of image will come \n",
    "                                                                                    #them .ppm will be changed by that extension\n",
    "np.random.shuffle(all_img_paths)\n",
    "for img_path in all_img_paths:\n",
    "    try:\n",
    "        img = preprocess_img(io.imread(img_path))\n",
    "        label = get_class(img_path)\n",
    "        imgs.append(img)\n",
    "        labels.append(label)\n",
    "\n",
    "        if len(imgs)%1000 == 0: print(\"Processed {}/{}\".format(len(imgs), len(all_img_paths)))\n",
    "            #print(\"get it 2\")\n",
    "    except (IOError, OSError):\n",
    "        print('missed', img_path)\n",
    "        pass\n",
    "\n",
    "X = np.array(imgs, dtype='float32') #Keeping the image as an array\n",
    "Y = np.eye(NUM_CLASSES, dtype='uint8')[labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_imgs=[]\n",
    "# root_test_dir = r'/media/atif/0820209220208930/unreal_cv_documentation/ignore_from_git/keras_graph_AI/test/'\n",
    "# # test_image_dir = glob.glob(os.path.join(root_test_dir, '*/*.png'))\n",
    "# test_image_dir=glob.glob(root_test_dir+ '/*.png')\n",
    "\n",
    "# np.random.shuffle(test_image_dir)\n",
    "# for test_img_path in test_image_dir:\n",
    "#     try:\n",
    "#         img = preprocess_img(io.imread(test_img_path))\n",
    "# #         label = get_class(img_path)\n",
    "#         test_imgs.append(img)\n",
    "# #         labels.append(label)\n",
    "\n",
    "#         if len(test_imgs)%1000 == 0: print(\"Processed {}/{}\".format(len(test_imgs), len(test_image_dir)))\n",
    "#             #print(\"get it 2\")\n",
    "#     except (IOError, OSError):\n",
    "#         print('missed', test_img_path)\n",
    "#         pass\n",
    "\n",
    "# Z = np.array(test_imgs, dtype='float32') #Keeping the image as an array\n",
    "# print(len(Z))\n",
    "# print(Z.shape)\n",
    "# # Z1=Z.reshape(48,48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2160, 3, 48, 48)\n",
      "4\n",
      "(3, 48, 48)\n",
      "(2160, 3, 48, 48)\n",
      "(2160, 2)\n"
     ]
    }
   ],
   "source": [
    "X = X.reshape(len(imgs),IMG_depth,IMG_SIZE,IMG_SIZE) # write (IMG_SIZE,IMG_SIZE,1 if you want channel last; 1= grayscale;3=RGB)\n",
    "# plt.imshow(X[0],cmap=\"gray\")\n",
    "print(X.shape)\n",
    "print(X.ndim)\n",
    "print(X[0].shape)\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                     input_shape=(3, IMG_SIZE, IMG_SIZE),\n",
    "                     activation='relu'))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same',\n",
    "                     activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same',\n",
    "                     activation='relu'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "model = cnn_model()\n",
    "\n",
    "lr = 0.01\n",
    "sgd = SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "          optimizer=sgd,\n",
    "          metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 48, 48)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 46, 46)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 23, 23)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 23, 23)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 64, 23, 23)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 64, 21, 21)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 64, 10, 10)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64, 10, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 128, 10, 10)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 128, 8, 8)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 128, 4, 4)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128, 4, 4)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 1,337,122\n",
      "Trainable params: 1,337,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1728 samples, validate on 432 samples\n",
      "Epoch 1/2\n",
      "1728/1728 [==============================] - 54s 31ms/step - loss: 0.6749 - acc: 0.5990 - val_loss: 0.6781 - val_acc: 0.5370\n",
      "Epoch 2/2\n",
      "1696/1728 [============================>.] - ETA: 0s - loss: 0.4627 - acc: 0.7978"
     ]
    }
   ],
   "source": [
    "def lr_schedule(epoch):\n",
    "    return lr * (0.1 ** int(epoch / 10))\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 2\n",
    "do_train_model=model.fit(X, Y,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2,\n",
    "          #np.resize(img, (-1, <image shape>)\n",
    "          callbacks=[LearningRateScheduler(lr_schedule),ModelCheckpoint('/media/atif/0820209220208930/unreal_cv_documentation/ignore_from_git/keras_graph_AI/do_train_model.h5', save_best_only=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = model.fit(X, Y, validation_split=0.33, epochs=1, batch_size=32, verbose=0)\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atif/anaconda3/envs/venv/lib/python3.6/site-packages/skimage/color/colorconv.py:283: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  out[idx, 0] = 4. + (arr[idx, 0] - arr[idx, 1]) / delta[idx]\n",
      "/home/atif/anaconda3/envs/venv/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/home/atif/anaconda3/envs/venv/lib/python3.6/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " /media/atif/0820209220208930/unreal_cv_documentation/ignore_from_git/test_image_AI/calgonit_finish_1035.png\n",
      "predicted class:  [4]\n",
      "probability:  [[5.0177057e-10 1.0891918e-07 1.1687316e-13 1.2897646e-14 9.9999988e-01]]\n",
      "\n",
      " /media/atif/0820209220208930/unreal_cv_documentation/ignore_from_git/test_image_AI/calgonit_finish_24.png\n",
      "predicted class:  [4]\n",
      "probability:  [[3.1424308e-15 1.0334130e-16 2.2029010e-24 4.2919256e-19 1.0000000e+00]]\n",
      "\n",
      " /media/atif/0820209220208930/unreal_cv_documentation/ignore_from_git/test_image_AI/calgonit_finish_435.png\n",
      "predicted class:  [4]\n",
      "probability:  [[8.3640532e-07 2.5469612e-07 4.1909775e-08 3.0858408e-07 9.9999857e-01]]\n",
      "\n",
      " /media/atif/0820209220208930/unreal_cv_documentation/ignore_from_git/test_image_AI/calgonit_finish_824.png\n",
      "predicted class:  [4]\n",
      "probability:  [[2.7730483e-08 1.1543107e-06 1.0534397e-09 3.1265267e-07 9.9999845e-01]]\n",
      "\n",
      " /media/atif/0820209220208930/unreal_cv_documentation/ignore_from_git/test_image_AI/calgonit_finish_974.png\n",
      "predicted class:  [4]\n",
      "probability:  [[4.6088249e-07 3.2352163e-09 2.3988253e-10 2.9763393e-11 9.9999952e-01]]\n",
      "\n",
      " /media/atif/0820209220208930/unreal_cv_documentation/ignore_from_git/test_image_AI/chair_1034.png\n",
      "predicted class:  [0]\n",
      "probability:  [[1.0000000e+00 3.8742352e-13 5.7135923e-14 2.4194719e-14 9.1844560e-18]]\n",
      "\n",
      " /media/atif/0820209220208930/unreal_cv_documentation/ignore_from_git/test_image_AI/chair_105.png\n",
      "predicted class:  [0]\n",
      "probability:  [[1.0000000e+00 3.3266599e-12 2.7822232e-08 1.8163380e-12 2.7262977e-12]]\n",
      "\n",
      " /media/atif/0820209220208930/unreal_cv_documentation/ignore_from_git/test_image_AI/chair_22.png\n",
      "predicted class:  [0]\n",
      "probability:  [[1.0000000e+00 7.7961084e-12 1.4147568e-16 7.4786905e-16 1.1952255e-12]]\n",
      "\n",
      " /media/atif/0820209220208930/unreal_cv_documentation/ignore_from_git/test_image_AI/chair_485.png\n",
      "predicted class:  [0]\n",
      "probability:  [[1.0000000e+00 1.6284754e-15 2.0020189e-16 3.0539948e-09 3.1675187e-11]]\n",
      "\n",
      " /media/atif/0820209220208930/unreal_cv_documentation/ignore_from_git/test_image_AI/chair_904.png\n",
      "predicted class:  [0]\n",
      "probability:  [[1.0000000e+00 1.6925262e-15 1.5933259e-16 1.3326584e-12 2.1720046e-14]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atif/anaconda3/envs/venv/lib/python3.6/site-packages/skimage/color/colorconv.py:275: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  out[idx, 0] = (arr[idx, 1] - arr[idx, 2]) / delta[idx]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " /media/atif/0820209220208930/unreal_cv_documentation/ignore_from_git/test_image_AI/rock_44.png\n",
      "predicted class:  [1]\n",
      "probability:  [[2.1815778e-05 9.9990058e-01 4.1056985e-08 7.1170070e-05 6.4108613e-06]]\n",
      "\n",
      " /media/atif/0820209220208930/unreal_cv_documentation/ignore_from_git/test_image_AI/rock_875.png\n",
      "predicted class:  [1]\n",
      "probability:  [[1.0950030e-08 1.0000000e+00 1.1585048e-09 3.7393374e-08 2.9445759e-09]]\n",
      "\n",
      " /media/atif/0820209220208930/unreal_cv_documentation/ignore_from_git/test_image_AI/somat_1004.png\n",
      "predicted class:  [3]\n",
      "probability:  [[3.0130477e-13 1.6989387e-09 3.7450887e-09 1.0000000e+00 1.5859566e-18]]\n",
      "\n",
      " /media/atif/0820209220208930/unreal_cv_documentation/ignore_from_git/test_image_AI/somat_34.png\n",
      "predicted class:  [3]\n",
      "probability:  [[3.663658e-11 5.127386e-11 9.343606e-10 1.000000e+00 2.028886e-08]]\n",
      "\n",
      " /media/atif/0820209220208930/unreal_cv_documentation/ignore_from_git/test_image_AI/somat_374.png\n",
      "predicted class:  [3]\n",
      "probability:  [[2.4770513e-10 9.1767366e-10 3.4991489e-11 1.0000000e+00 7.7192636e-10]]\n",
      "\n",
      " /media/atif/0820209220208930/unreal_cv_documentation/ignore_from_git/test_image_AI/somat_553.png\n",
      "predicted class:  [3]\n",
      "probability:  [[1.0075657e-07 1.2770819e-09 7.8696110e-07 9.9999917e-01 1.6626490e-12]]\n",
      "\n",
      " /media/atif/0820209220208930/unreal_cv_documentation/ignore_from_git/test_image_AI/somat_74.png\n",
      "predicted class:  [3]\n",
      "probability:  [[1.0007757e-06 1.4909112e-04 6.4680105e-05 9.9452025e-01 5.2650142e-03]]\n",
      "\n",
      " /media/atif/0820209220208930/unreal_cv_documentation/ignore_from_git/test_image_AI/table_1044.png\n",
      "predicted class:  [2]\n",
      "probability:  [[3.43165157e-19 1.22115365e-20 1.00000000e+00 4.28298914e-22\n",
      "  1.57831503e-34]]\n",
      "\n",
      " /media/atif/0820209220208930/unreal_cv_documentation/ignore_from_git/test_image_AI/table_555.png\n",
      "predicted class:  [2]\n",
      "probability:  [[1.0585591e-28 4.5893789e-26 1.0000000e+00 2.0132402e-22 1.5604969e-36]]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('/media/atif/0820209220208930/unreal_cv_documentation/ignore_from_git/trained_file_AI/trained_UE4_first.h5')\n",
    "#for gray scale\n",
    "def preprocess_img(img):\n",
    "#     Histogram normalization in y\n",
    "    hsv = color.rgb2hsv(img)\n",
    "    hsv[:,:,2] = exposure.equalize_hist(hsv[:,:,2])\n",
    "    img = color.hsv2rgb(hsv)\n",
    "\n",
    "    # central scrop\n",
    "    min_side = min(img.shape[:-1])\n",
    "    centre = img.shape[0]//2, img.shape[1]//2\n",
    "    img = img[centre[0]-min_side//2:centre[0]+min_side//2,\n",
    "              centre[1]-min_side//2:centre[1]+min_side//2,\n",
    "              :]\n",
    "#     img = rgb2gray(img)\n",
    "\n",
    "    # rescale to standard size\n",
    "    img = transform.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "    # roll color axis to axis 0\n",
    "    img = np.rollaxis(img,-1)\n",
    "\n",
    "    return img\n",
    "\n",
    "import glob\n",
    "\n",
    "path = r'/media/atif/0820209220208930/unreal_cv_documentation/ignore_from_git/test_image_AI/'\n",
    "\n",
    "img_path = glob.glob(path+ '/*.png')\n",
    "for image in img_path:\n",
    "    X_test=[]\n",
    "    X_test.append(preprocess_img(io.imread(image)))\n",
    "    X_test = np.array(X_test)\n",
    "#     plt.imshow(X_test)\n",
    "    X_test = X_test.reshape(len(X_test),3,IMG_SIZE,IMG_SIZE)\n",
    "    \n",
    "    print(\"\\n\",image)\n",
    "    predicted_class = model.predict_classes(X_test)\n",
    "    print(\"predicted class: \",predicted_class)\n",
    "    \n",
    "    probability = model.predict_proba(X_test)\n",
    "    print(\"probability: \",probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
