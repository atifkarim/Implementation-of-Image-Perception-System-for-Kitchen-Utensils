{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/atif/iai_ml_venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/atif/iai_ml_venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/atif/iai_ml_venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/atif/iai_ml_venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/atif/iai_ml_venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/atif/iai_ml_venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/atif/iai_ml_venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/atif/iai_ml_venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/atif/iai_ml_venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/atif/iai_ml_venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/atif/iai_ml_venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/atif/iai_ml_venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from skimage import io, color, exposure, transform\n",
    "from skimage.color import rgb2gray\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split  #it came from update scikit learn. https://stackoverflow.com/questions/40704484/importerror-no-module-named-model-selection\n",
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D,Conv1D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_first')\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "\n",
    "#import keras\n",
    "\n",
    "NUM_CLASSES = 16\n",
    "IMG_SIZE = 48\n",
    "IMG_depth = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_img(img):\n",
    "    # Histogram normalization in y\n",
    "    hsv = color.rgb2hsv(img)\n",
    "    hsv[:,:,2] = exposure.equalize_hist(hsv[:,:,2])\n",
    "    img = color.hsv2rgb(hsv)\n",
    "\n",
    "    # central scrop\n",
    "    min_side = min(img.shape[:-1])\n",
    "    centre = img.shape[0]//2, img.shape[1]//2\n",
    "    img = img[centre[0]-min_side//2:centre[0]+min_side//2,centre[1]-min_side//2:centre[1]+min_side//2,:]\n",
    "#    img = rgb2gray(img)\n",
    "\n",
    "    # rescale to standard size\n",
    "    img = transform.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "    # roll color axis to axis 0\n",
    "    img = np.rollaxis(img,-1)\n",
    "\n",
    "    return img\n",
    "\n",
    "def get_class(img_path):\n",
    "    return int(img_path.split('/')[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1200/57600\n",
      "Processed 2400/57600\n",
      "Processed 3600/57600\n",
      "Processed 4800/57600\n",
      "Processed 6000/57600\n",
      "Processed 7200/57600\n",
      "Processed 8400/57600\n",
      "Processed 9600/57600\n",
      "Processed 10800/57600\n",
      "Processed 12000/57600\n",
      "Processed 13200/57600\n",
      "Processed 14400/57600\n",
      "Processed 15600/57600\n",
      "Processed 16800/57600\n",
      "Processed 18000/57600\n",
      "Processed 19200/57600\n",
      "Processed 20400/57600\n",
      "Processed 21600/57600\n",
      "Processed 22800/57600\n",
      "Processed 24000/57600\n",
      "Processed 25200/57600\n",
      "Processed 26400/57600\n",
      "Processed 27600/57600\n",
      "Processed 28800/57600\n",
      "Processed 30000/57600\n",
      "Processed 31200/57600\n",
      "Processed 32400/57600\n",
      "Processed 33600/57600\n",
      "Processed 34800/57600\n",
      "Processed 36000/57600\n",
      "Processed 37200/57600\n",
      "Processed 38400/57600\n",
      "Processed 39600/57600\n",
      "Processed 40800/57600\n",
      "Processed 42000/57600\n",
      "Processed 43200/57600\n",
      "Processed 44400/57600\n",
      "Processed 45600/57600\n",
      "Processed 46800/57600\n",
      "Processed 48000/57600\n",
      "Processed 49200/57600\n",
      "Processed 50400/57600\n",
      "Processed 51600/57600\n",
      "Processed 52800/57600\n",
      "Processed 54000/57600\n",
      "Processed 55200/57600\n",
      "Processed 56400/57600\n",
      "Processed 57600/57600\n"
     ]
    }
   ],
   "source": [
    "imgs = []\n",
    "labels = []\n",
    "root_dir = '/home/atif/machine_learning_stuff/ml_image/train_image_AI/'\n",
    "#path='/home/atif/training_by_several_learning_process/flower_photos/00000/'\n",
    "\n",
    "#all_img_paths = glob.glob(path+ '5547758_eea9edfd54_n_000.jpg')\n",
    "\n",
    "all_img_paths = glob.glob(os.path.join(root_dir, '*/*.png')) #I have done the training with .ppm format image. If another type of image will come \n",
    "                                                                                    #them .ppm will be changed by that extension\n",
    "np.random.shuffle(all_img_paths)\n",
    "for img_path in all_img_paths:\n",
    "    try:\n",
    "        img = preprocess_img(io.imread(img_path))\n",
    "        label = get_class(img_path)\n",
    "        imgs.append(img)\n",
    "        labels.append(label)\n",
    "\n",
    "        if len(imgs)%1200 == 0: print(\"Processed {}/{}\".format(len(imgs), len(all_img_paths)))\n",
    "            #print(\"get it 2\")\n",
    "    except (IOError, OSError):\n",
    "        print('missed', img_path)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(imgs, dtype='float32') #Keeping the image as an array\n",
    "Y = np.eye(NUM_CLASSES, dtype='uint8')[labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_imgs=[]\n",
    "# root_test_dir = r'/media/atif/0820209220208930/unreal_cv_documentation/ignore_from_git/keras_graph_AI/test/'\n",
    "# # test_image_dir = glob.glob(os.path.join(root_test_dir, '*/*.png'))\n",
    "# test_image_dir=glob.glob(root_test_dir+ '/*.png')\n",
    "\n",
    "# np.random.shuffle(test_image_dir)\n",
    "# for test_img_path in test_image_dir:\n",
    "#     try:\n",
    "#         img = preprocess_img(io.imread(test_img_path))\n",
    "# #         label = get_class(img_path)\n",
    "#         test_imgs.append(img)\n",
    "# #         labels.append(label)\n",
    "\n",
    "#         if len(test_imgs)%1000 == 0: print(\"Processed {}/{}\".format(len(test_imgs), len(test_image_dir)))\n",
    "#             #print(\"get it 2\")\n",
    "#     except (IOError, OSError):\n",
    "#         print('missed', test_img_path)\n",
    "#         pass\n",
    "\n",
    "# Z = np.array(test_imgs, dtype='float32') #Keeping the image as an array\n",
    "# # Z_label = np.eye(NUM_CLASSES, dtype='uint8')[labels]\n",
    "# print(len(Z))\n",
    "# print(Z.shape)\n",
    "# # plt.show(1,3,0:,0:)\n",
    "# # print(Z.ndim)\n",
    "# # print(Z[0].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57600, 3, 48, 48)\n",
      "4\n",
      "(3, 48, 48)\n",
      "(57600, 3, 48, 48)\n",
      "(57600, 16)\n"
     ]
    }
   ],
   "source": [
    "X = X.reshape(len(imgs),IMG_depth,IMG_SIZE,IMG_SIZE) # write (IMG_SIZE,IMG_SIZE,1 if you want channel last; 1= grayscale;3=RGB)\n",
    "# plt.imshow(X[0],cmap=\"gray\")\n",
    "print(X.shape)\n",
    "print(X.ndim)\n",
    "print(X[0].shape)\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0808 22:49:10.012565 139772371695424 deprecation_wrapper.py:119] From /home/atif/iai_ml_venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:64: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0808 22:49:10.025485 139772371695424 deprecation_wrapper.py:119] From /home/atif/iai_ml_venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:497: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0808 22:49:10.027616 139772371695424 deprecation_wrapper.py:119] From /home/atif/iai_ml_venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3636: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0808 22:49:10.035887 139772371695424 deprecation_wrapper.py:119] From /home/atif/iai_ml_venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:159: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0808 22:49:10.036290 139772371695424 deprecation_wrapper.py:119] From /home/atif/iai_ml_venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:164: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0808 22:49:10.094630 139772371695424 deprecation_wrapper.py:119] From /home/atif/iai_ml_venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3464: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0808 22:49:10.105459 139772371695424 deprecation.py:506] From /home/atif/iai_ml_venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3019: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0808 22:49:10.193051 139772371695424 deprecation.py:506] From /home/atif/iai_ml_venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "W0808 22:49:10.234534 139772371695424 deprecation_wrapper.py:119] From /home/atif/iai_ml_venv/lib/python3.6/site-packages/keras/optimizers.py:711: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0808 22:49:10.236521 139772371695424 deprecation.py:506] From /home/atif/iai_ml_venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2885: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "def cnn_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                     input_shape=(3, IMG_SIZE, IMG_SIZE),\n",
    "                     activation='relu'))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same',\n",
    "                     activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same',\n",
    "                     activation='relu'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "model = cnn_model()\n",
    "\n",
    "lr = 0.01\n",
    "sgd = SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "          optimizer=sgd,\n",
    "          metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 48, 48)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 46, 46)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 23, 23)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 23, 23)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 64, 23, 23)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 64, 21, 21)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 64, 10, 10)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64, 10, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 128, 10, 10)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 128, 8, 8)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 128, 4, 4)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128, 4, 4)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 1,344,304\n",
      "Trainable params: 1,344,304\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/atif/machine_learning_stuff/model_file_keras/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0808 22:49:10.330253 139772371695424 deprecation.py:323] From /home/atif/iai_ml_venv/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0808 22:49:10.606750 139772371695424 variables.py:2445] Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n",
      "W0808 22:49:10.608206 139772371695424 deprecation.py:506] From /home/atif/iai_ml_venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:680: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 46080 samples, validate on 11520 samples\n",
      "Epoch 1/3\n",
      " - 207s - loss: 1.1118 - acc: 0.6290 - val_loss: 0.1412 - val_acc: 0.9549\n",
      "Epoch 2/3\n"
     ]
    }
   ],
   "source": [
    "def lr_schedule(epoch):\n",
    "    return lr * (0.1 ** int(epoch / 10))\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 3\n",
    "do_train_model=model.fit(X, Y,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2,verbose=2,\n",
    "          #np.resize(img, (-1, <image shape>)\n",
    "          callbacks=[LearningRateScheduler(lr_schedule),ModelCheckpoint(path+'07_aug_ep_3.h5', save_best_only=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(X, Y, validation_split=0.33, epochs=1, batch_size=32, verbose=0)\n",
    "# list all data in history\n",
    "print(do_train_model.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(do_train_model.history['acc'])\n",
    "plt.plot(do_train_model.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_accuracy', 'validation_accuracy'], loc='upper left')\n",
    "plt.rcParams['figure.figsize'] =(20,10)\n",
    "plt.savefig(path+'epoch_vs_accuracy.jpg')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(do_train_model.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(do_train_model.history['loss'])\n",
    "plt.plot(do_train_model.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_loss', 'validation_loss'], loc='upper left')\n",
    "plt.savefig(path+'epoch_vs_loss.jpg')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image name is:  /home/atif/machine_learning_stuff/ml_image/test_image_crop/crop_clgo_finish_klarspueler.jpg\n",
      "predicted class:  [1]\n",
      "class name is:  SM_CalgonitFinishKlarspueler_5\n",
      "probability:  [[2.7340452e-09 9.9999988e-01 1.2844298e-07 3.4400390e-08 4.4906785e-09\n",
      "  2.9537511e-16 7.6701406e-10 2.5724523e-09 3.7113938e-14 3.9326677e-11\n",
      "  1.8616154e-15 3.5040252e-14 4.2083198e-18 2.3733964e-16 2.0021346e-11\n",
      "  3.3514354e-11]]\n",
      "\n",
      "\n",
      "image name is:  /home/atif/machine_learning_stuff/ml_image/test_image_crop/DenkMitEntkalker.jpg\n",
      "predicted class:  [15]\n",
      "class name is:  SM_SomatClassic_53\n",
      "probability:  [[1.15807036e-13 1.12055829e-12 9.24432948e-13 7.67269000e-07\n",
      "  1.11174805e-10 5.58040010e-14 2.07815102e-11 1.04912258e-04\n",
      "  4.72139024e-16 1.82505709e-03 1.58136498e-16 1.77574111e-05\n",
      "  1.78138970e-18 2.68715032e-17 3.70488334e-10 9.98051405e-01]]\n",
      "\n",
      "\n",
      "image name is:  /home/atif/machine_learning_stuff/ml_image/test_image_crop/DenkMitGeschirrReinigerClassic.jpg\n",
      "predicted class:  [9]\n",
      "class name is:  SM_DenkMitGeschirrReinigerClassic_29\n",
      "probability:  [[4.14747636e-13 4.90123393e-12 1.01448634e-10 5.95730683e-08\n",
      "  4.20712715e-10 4.66608314e-11 8.54881721e-10 2.52453873e-07\n",
      "  7.05141570e-11 9.99304414e-01 1.92768371e-11 3.99500277e-04\n",
      "  1.49511059e-13 2.24044177e-12 3.88989925e-08 2.95777310e-04]]\n",
      "\n",
      "\n",
      "image name is:  /home/atif/machine_learning_stuff/ml_image/test_image_crop/CalgonitFinishKlarspueler.jpg\n",
      "predicted class:  [3]\n",
      "class name is:  SM_CalgonitFinishSpezialSalz_11\n",
      "probability:  [[4.8387444e-10 1.0649726e-10 1.2967440e-13 9.9998879e-01 7.4213569e-12\n",
      "  6.2019024e-15 7.8986340e-13 8.3103068e-06 5.8079104e-14 7.0123757e-10\n",
      "  9.3088082e-15 4.4593821e-12 9.2564621e-17 5.0868712e-16 2.8935435e-06\n",
      "  4.2554404e-08]]\n",
      "\n",
      "\n",
      "image name is:  /home/atif/machine_learning_stuff/ml_image/test_image_crop/crop_CalgonitFinishKlarspuler.jpg\n",
      "predicted class:  [1]\n",
      "class name is:  SM_CalgonitFinishKlarspueler_5\n",
      "probability:  [[1.5489293e-13 1.0000000e+00 2.1865740e-10 1.9311642e-15 9.3241946e-15\n",
      "  4.7214099e-25 2.8298010e-16 4.1274930e-17 4.1036504e-22 1.9901683e-11\n",
      "  2.5464585e-23 6.4030513e-20 2.2214651e-25 2.2532569e-25 1.1109644e-15\n",
      "  1.9917336e-14]]\n",
      "\n",
      "\n",
      "image name is:  /home/atif/machine_learning_stuff/ml_image/test_image_crop/EdelstahlReiniger.jpg\n",
      "predicted class:  [15]\n",
      "class name is:  SM_SomatClassic_53\n",
      "probability:  [[8.7398720e-24 1.7143335e-15 1.9917693e-20 1.6922809e-15 5.4498492e-21\n",
      "  5.5161698e-22 5.4219657e-11 5.4764190e-14 2.1833705e-20 1.3963456e-15\n",
      "  8.5290986e-27 1.9957922e-13 1.0110490e-26 1.8903985e-22 9.3864409e-21\n",
      "  1.0000000e+00]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('/home/atif/machine_learning_stuff/model_file_keras/08_aug_ep_100.h5')\n",
    "#for gray scale\n",
    "def preprocess_img(img):\n",
    "#     Histogram normalization in y\n",
    "    hsv = color.rgb2hsv(img)\n",
    "    hsv[:,:,2] = exposure.equalize_hist(hsv[:,:,2])\n",
    "    img = color.hsv2rgb(hsv)\n",
    "\n",
    "    # central scrop\n",
    "    min_side = min(img.shape[:-1])\n",
    "    centre = img.shape[0]//2, img.shape[1]//2\n",
    "    img = img[centre[0]-min_side//2:centre[0]+min_side//2,\n",
    "              centre[1]-min_side//2:centre[1]+min_side//2,\n",
    "              :]\n",
    "#     img = rgb2gray(img)\n",
    "\n",
    "    # rescale to standard size\n",
    "    img = transform.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "    # roll color axis to axis 0\n",
    "    img = np.rollaxis(img,-1)\n",
    "\n",
    "    return img\n",
    "\n",
    "import glob\n",
    "\n",
    "path = r'/home/atif/machine_learning_stuff/ml_image/test_image_crop/'\n",
    "\n",
    "my_name = ['SM_CalgonitFinish_2','SM_CalgonitFinishKlarspueler_5','SM_CalgonitFinishMaschinenpfleger_8','SM_CalgonitFinishSpezialSalz_11',\n",
    "           'SM_CalgonitFinishVorratspack_14','SM_DenkMitEdelstahlreiniger_17','SM_DenkMitEdelstahlReinigerSpray_20','SM_DenkMitEntkalker_23',\n",
    "           'SM_DenkMitGeschirrReiniger_26','SM_DenkMitGeschirrReinigerClassic_29','SM_DenkMitGeschirrReinigerEvo_32','SM_DenkMitGeschirrReinigerNature_35',\n",
    "           'SM_DenkMitHygieneAllzweckreiniger_38','SM_DenkMitMaschinenpfleger_41','SM_DenkMitSpezialsalz_44','SM_SomatClassic_53']\n",
    "\n",
    "img_path = glob.glob(path+ '/*.jpg')\n",
    "for image in img_path:\n",
    "    X_test=[]\n",
    "    X_test.append(preprocess_img(io.imread(image)))\n",
    "    X_test = np.array(X_test)\n",
    "#     plt.imshow(X_test)\n",
    "    X_test = X_test.reshape(len(X_test),3,IMG_SIZE,IMG_SIZE)\n",
    "    \n",
    "    print('image name is: ',image)\n",
    "    predicted_class = model.predict_classes(X_test)\n",
    "    print(\"predicted class: \",predicted_class)\n",
    "#     print('type-of predicted calss: ', type(predicted_class))\n",
    "    print('class name is: ',my_name[predicted_class[0]])\n",
    "    \n",
    "    probability = model.predict_proba(X_test)\n",
    "    print(\"probability: \",probability)\n",
    "    print('\\n')\n",
    "    \n",
    "#     evaluate=model.evaluate(X_test)\n",
    "#     print(\"\\nEvaluation\",evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 7613574926921769401, name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 6670460804252057397\n",
       " physical_device_desc: \"device: XLA_CPU device\"]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
