{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import cv2\n",
    "# from matplotlib import pyplot as plt\n",
    "# img = cv2.imread('F:/save_image_ai/object_subtraction_for_UE4/1_mask.png')\n",
    "# mask = np.zeros(img.shape[:2],np.uint8)\n",
    "# bgdModel = np.zeros((1,65),np.float64)\n",
    "# fgdModel = np.zeros((1,65),np.float64)\n",
    "# rect = (50,50,450,290)\n",
    "# cv2.grabCut(img,mask,rect,bgdModel,fgdModel,5,cv2.GC_INIT_WITH_RECT)\n",
    "# mask2 = np.where((mask==2)|(mask==0),0,1).astype('uint8')\n",
    "# img = img*mask2[:,:,np.newaxis]\n",
    "# plt.imshow(img)\n",
    "# # plt.colorbar(),plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame = cv2.imread(\"F:/save_image_ai/object_subtraction_for_UE4/1_mask.png\")\n",
    "# lower_black = np.array([0,0,0], dtype = \"uint16\")q\n",
    "# upper_black = np.array([70,70,70], dtype = \"uint16\")\n",
    "# light_white = (0, 0, 200)\n",
    "# dark_white = (145, 60, 255)\n",
    "# # black_mask = cv2.inRange(frame, lower_black, upper_black)\n",
    "# black_mask = cv2.inRange(frame, light_white,dark_white)\n",
    "# frame[np.where((frame == [0]).all(axis = 2))] = [0]     # it works\n",
    "# black_mask[np.where((black_mask == [0]).all(axis = 1))] = [255]\n",
    "# cv2.imshow('Test', frame)\n",
    "# # cv2.imshow('Test2', raw)\n",
    "# if cv2.waitKey() == ord('q'):\n",
    "#     cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "\n",
    "# frame = cv2.imread(\"F:/save_image_ai/object_subtraction_for_UE4/1_mask.png\")\n",
    "# hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# cv2.imshow('hsv',hsv)\n",
    "# if cv2.waitKey() == ord('q'):\n",
    "#     cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  %matplotlib inline\n",
    "# import cv2\n",
    "# import numpy\n",
    "# import matplotlib as plt\n",
    "\n",
    "# frame = cv2.imread('F:/save_image_ai/object_subtraction_for_UE4/1_rgb.png')\n",
    "# if frame is None:\n",
    "#     print('Error loading image')\n",
    "#     exit()\n",
    "\n",
    "# hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# hsv_channels = cv2.split(hsv)\n",
    "\n",
    "# rows = frame.shape[0]\n",
    "# cols = frame.shape[1]\n",
    "\n",
    "# for i in range(0, rows):\n",
    "#     for j in range(0, cols):\n",
    "#         h = hsv_channels[0][i][j]\n",
    "\n",
    "#         if h > 90 and h < 255:\n",
    "#             hsv_channels[2][i][j] = 255\n",
    "#         else:\n",
    "#             hsv_channels[2][i][j] = 0\n",
    "\n",
    "# cv2.imshow(\"original\",frame)\n",
    "# cv2.imshow(\"show0\", hsv_channels[0])\n",
    "# cv2.imshow(\"show1\", hsv_channels[1])\n",
    "# cv2.imshow(\"show2\", hsv_channels[2])\n",
    "# # cv2.imwrite('F:/save_image_ai/object_subtraction_for_UE4/t_1_1.png',hsv_channels[1])\n",
    "# # x1=250\n",
    "# # y1=200\n",
    "# # x2=400\n",
    "# # y2=150\n",
    "# # cv2.rectangle(hsv_channels[1], (x1, y1), (x2, y2), (0,255,0), 2)\n",
    "# # cv2.imwrite(\"F:/save_image_ai/object_subtraction_for_UE4/t_1_rec.png\",hsv_channels[1])\n",
    "# # cv2.imshow('rec',hsv_channels[1])\n",
    "\n",
    "# if cv2.waitKey() == ord('q'):\n",
    "#     cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #without for loop\n",
    "\n",
    "# %matplotlib inline\n",
    "# import cv2\n",
    "# import numpy\n",
    "# import matplotlib as plt\n",
    "\n",
    "# rgb_image=cv2.imread('/media/atif/0820209220208930/unreal_cv_documentation/unreal_cv_image_processing_for_ML/object_subtraction_for_UE4/1_rgb.png')\n",
    "# cv2.imshow('rgb_image',rgb_image)\n",
    "# frame = cv2.imread('/media/atif/0820209220208930/unreal_cv_documentation/unreal_cv_image_processing_for_ML/object_subtraction_for_UE4/1_mask.png') #load masked image\n",
    "# if frame is None:\n",
    "#     print('Error loading image')\n",
    "#     exit()\n",
    "\n",
    "# hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV) #convert to hsv\n",
    "\n",
    "# hsv_channels = cv2.split(hsv) #split the hsv color\n",
    "\n",
    "# rows = frame.shape[0]\n",
    "# cols = frame.shape[1]\n",
    "\n",
    "# cv2.imshow(\"mask\",frame)\n",
    "# cv2.imshow(\"show0\", hsv_channels[0])\n",
    "# cv2.imshow(\"show1\", hsv_channels[1])\n",
    "# # cv2.imshow(\"show2\", hsv_channels[2])\n",
    "# _,thresh=cv2.threshold(hsv_channels[1],140,255,cv2.THRESH_BINARY_INV) #thresholding done for detecting contour\n",
    "# cv2.imshow('thresh',thresh)\n",
    "# _, contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "# cv2.drawContours(frame,contours,-1,(0,255,0),2)\n",
    "# cv2.imshow('contour',frame)\n",
    "\n",
    "# # cv2.imwrite('/media/atif/0820209220208930/unreal_cv_documentation/unreal_cv_image_processing_for_ML/object_subtraction_for_UE4/draw_rec.png',hsv_channels[1])\n",
    "# x1=202\n",
    "# y1=115\n",
    "# x2=412\n",
    "# y2=274\n",
    "# cv2.rectangle(hsv_channels[1], (x1, y1), (x2, y2), (0,255,0), 2)\n",
    "# cv2.rectangle(rgb_image, (x1, y1), (x2, y2), (0,255,0), 2)\n",
    "# # cv2.imwrite(\"/media/atif/0820209220208930/unreal_cv_documentation/unreal_cv_image_processing_for_ML/object_subtraction_for_UE4/draw_rec.png\",hsv_channels[1])\n",
    "# cv2.imshow('rec',hsv_channels[1])\n",
    "# cv2.imshow('rec_rgb',rgb_image)\n",
    "\n",
    "# if cv2.waitKey() == ord('q'): #press q to close the output image window\n",
    "#     cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "\n",
    "# rgb_img = cv2.imread('F:/save_image_ai/object_subtraction_for_UE4/1_mask.png')\n",
    "# gray_img=cv2.cvtColor(rgb_img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# _,thresh=cv2.threshold(gray_img,225,255,cv2.THRESH_BINARY_INV)\n",
    "# cv2.imshow('thresh',thresh)\n",
    "\n",
    "# if cv2.waitKey() == ord('q'):\n",
    "#     cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "rgb=cv2.imread('F:/unreal_cv_documentation/my_dir/SM_Couch_5/1_SM_Couch_5_0_90_lit.png')\n",
    "im = cv2.imread('F:/unreal_cv_documentation/my_dir/SM_Couch_5/1_SM_Couch_5_0_90_object_mask.png')\n",
    "# imgray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "hsv = cv2.cvtColor(im, cv2.COLOR_BGR2HSV) #convert to hsv\n",
    "\n",
    "hsv_channels = cv2.split(hsv) #split the hsv color\n",
    "\n",
    "# rows = im.shape[0]\n",
    "# cols = im.shape[1]\n",
    "\n",
    "# cv2.imshow(\"hsv_channels[1]\",hsv_channels[1])  #displaying hsv image. also work for hsv_channels[0]\n",
    "\n",
    "_,thresh=cv2.threshold(hsv_channels[1],140,255,cv2.THRESH_BINARY_INV) #do thresholding\n",
    "# cv2.imshow('thresholded_image',thresh) #display thresholded image\n",
    "\n",
    "im2, contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) #apply contour function on thresholded image\n",
    "# cnt = contours[4]\n",
    "#You will find contour from thresholded or canny edged image clearly. After then you can apply the detected contour on other image. Ths has done later.\n",
    "\n",
    "# cv2.drawContours(im, contours, 0, (0,255,0), 3) #draw contour on masked image\n",
    "# cv2.imshow('contoured_image_on_mask',im) #displaying contour on masked image\n",
    "\n",
    "# cv2.drawContours(hsv_channels[1], contours, 0, (0,255,0), 3) #draw contour on hsv image\n",
    "# cv2.imshow('contoured_image_hsv',hsv_channels[1]) # Displaying contour on hsv image\n",
    "\n",
    "cnt_table = contours[0] #if you change this numeric value then you will find something interesting like it will change the position of contour\n",
    "cnt_chair =contours[0]\n",
    "# M = cv2.moments(cnt)\n",
    "# print( M )\n",
    "\n",
    "# k = cv2.isContourConvex(cnt_table)\n",
    "# print(k)\n",
    "\n",
    "x,y,w,h = cv2.boundingRect(cnt_chair) #this related to bound the contour on a box. It actually takes information from contour\n",
    "# x_t,y_t,w_t,h_t = cv2.boundingRect(cnt_table)\n",
    "\n",
    "print(' here the val: ',x,\" \",y,\" \",x+w,\" \",y+h)\n",
    "\n",
    "# cv2.rectangle(hsv_channels[1],(x,y),(x+w,y+h),(0,255,0),2) #draw this box on hsv image.\n",
    "# cv2.imshow('rec_hsv[1]',hsv_channels[1])\n",
    "\n",
    "# cv2.rectangle(thresh,(x,y),(x+w,y+h),(0,255,0),2) #draw this on thresholded image. result not good\n",
    "# cv2.imshow('rec_thresh',thresh)\n",
    "\n",
    "mask_rec_chair=cv2.rectangle(im,(x,y),(x+w,y+h),(255,255,255),1) #draw this box on masked image\n",
    "cv2.imshow('rec_mask',mask_rec_chair)\n",
    "\n",
    "# mask_rec_table=cv2.rectangle(im,(x_t,y_t),(x_t+w_t,y_t+h_t),(255,255,255),1) #draw this box on masked image\n",
    "# cv2.imshow('rec_mask_table',mask_rec_table)\n",
    "\n",
    "# mask_rec_1=cv2.rectangle(im,(x_t,y_t),(x_t+w_t,y_t+h_t),(255,255,255),1) #draw this box on masked image\n",
    "# cv2.imshow('rec_mask_1',mask_rec_1)\n",
    "\n",
    "rgb_rec_chair=cv2.rectangle(rgb,(x,y),(x+w,y+h),(255,255,255),1) #draw this box on rgb image\n",
    "cv2.imshow('rec_rgb_chair',rgb_rec_chair)\n",
    "# rgb_rec_table=cv2.rectangle(rgb,(x_t,y_t),(x_t+w_t,y_t+h_t),(255,255,255),1) #draw this box on rgb image\n",
    "# cv2.imshow('rec_rgb_table',rgb_rec_table)\n",
    "\n",
    "crop_img_chair = rgb_rec_chair[y:y+h, x:x+w] #to crop the applied bounded box\n",
    "cv2.imshow(\"cropped_chair\", crop_img_chair) #displaying cropped image\n",
    "# cv2.imwrite(\"/media/atif/0820209220208930/unreal_cv_documentation/unreal_cv_image_processing_for_ML/object_subtraction_for_UE4/single_image_testing/crop_rgb_chair_1.png\",crop_img_chair) #save the cropped image\n",
    "\n",
    "# crop_img_table = rgb_rec_table[y_t:y_t+h_t, x_t:x_t+w_t] #to crop the applied bounded box\n",
    "# cv2.imshow(\"cropped_table\", crop_img_table) #displaying cropped image\n",
    "# cv2.imwrite(\"/media/atif/0820209220208930/unreal_cv_documentation/unreal_cv_image_processing_for_ML/object_subtraction_for_UE4/single_image_testing/crop_rgb_table_1.png\",crop_img_table)\n",
    "\n",
    "\n",
    "if cv2.waitKey() == ord('q'): #press q to close the output image window\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# crop the interested object from RGB as well as mask image and store the cropped image in a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# path_mask = '/media/atif/0820209220208930/unreal_cv_documentation/unreal_cv_image_processing_for_ML/object_subtraction_for_UE4/single_image_testing/m'\n",
    "# path_rgb = '/media/atif/0820209220208930/unreal_cv_documentation/unreal_cv_image_processing_for_ML/object_subtraction_for_UE4/single_image_testing/r'\n",
    "\n",
    "path_mask = '/media/atif/0820209220208930/save_image_ai/object_subtraction_for_UE4/image_AI/mask_calgonit'\n",
    "path_rgb = '/media/atif/0820209220208930/save_image_ai/object_subtraction_for_UE4/image_AI/rgb_calgonit'\n",
    "\n",
    "\n",
    "# img_path_mask = sorted(glob.glob(path_mask+ '/*.png'))\n",
    "# img_path_rgb = sorted(glob.glob(path_rgb+ '/*.png'))\n",
    "for a,b,image_mask in os.walk(path_mask):\n",
    "    for s in image_mask:\n",
    "        n=s.split(\".\")\n",
    "#         print(n[0])\n",
    "        mask = path_mask+'/'+s\n",
    "        image_mask2=cv2.imread(mask)\n",
    "        hsv = cv2.cvtColor(image_mask2, cv2.COLOR_BGR2HSV)\n",
    "        hsv_channels = cv2.split(hsv)\n",
    "\n",
    "        _,thresh=cv2.threshold(hsv_channels[1],140,255,cv2.THRESH_BINARY_INV)\n",
    "        im2, contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cv2.drawContours(image_mask2, contours, 0, (0,255,0), 3)\n",
    "        cnt = contours[0]\n",
    "#         cnt_table = contours[0]\n",
    "        x,y,w,h = cv2.boundingRect(cnt)\n",
    "#         x_t,y_t,w_t,h_t = cv2.boundingRect(cnt_table)\n",
    "        \n",
    "        for c,d,image_rgb in os.walk(path_rgb):\n",
    "            for t in image_rgb:\n",
    "                m=t.split('.')\n",
    "                if int(n[0])== int(m[0]):\n",
    "                    rgb = path_rgb+'/'+t\n",
    "                    image_rgb2=cv2.imread(rgb)\n",
    "                    image_rgb_rec=cv2.rectangle(image_rgb2,(x,y),(x+w,y+h),(255,255,255),1)\n",
    "#                     rgb_rec_table=cv2.rectangle(image_rgb2,(x_t,y_t),(x_t+w_t,y_t+h_t),(255,255,255),1)\n",
    "                    crop_img = image_rgb_rec[y:y+h, x:x+w]\n",
    "#                     crop_img_table = rgb_rec_table[y_t:y_t+h_t, x_t:x_t+w_t]\n",
    "#                     cv2.imwrite(\"/media/atif/0820209220208930/unreal_cv_documentation/ignore_from_git/YOLO_learning/BBox-Label-Tool/Images/cropped_image/jpg/0051/\"+'calgonit_'+str(t),crop_img)\n",
    "                    cv2.imwrite(\"/media/atif/0820209220208930/unreal_cv_documentation/ignore_from_git/YOLO_learning/BBox-Label-Tool/Images/cropped_image/jpg/test/\"+str(t),crop_img)\n",
    "#                     cv2.imwrite(\"/media/atif/0820209220208930/unreal_cv_documentation/unreal_cv_image_processing_for_ML/object_subtraction_for_UE4/test_crop_multi_object/\"+str(t),crop_img_table)\n",
    "#                     cv2.imwrite(\"/media/atif/0820209220208930/unreal_cv_documentation/unreal_cv_image_processing_for_ML/object_subtraction_for_UE4/single_image_testing/test_table_chair/\"+'table_'+str(t),crop_img_table)\n",
    "                else:\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following cell will do the labelling/annotation on RGB image. It will detect the x,y,x+w,y+h coordinate from the RGB image and store the data in a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "my_class=[1,2,3,4,5]\n",
    "# print(my_class[-1])\n",
    "aaa=my_class[-1]\n",
    "print(type(aaa))\n",
    "print(aaa)\n",
    "bi=str(aaa)\n",
    "print(bi)\n",
    "print(type(bi))\n",
    "# path_mask = '/media/atif/0820209220208930/unreal_cv_documentation/unreal_cv_image_processing_for_ML/object_subtraction_for_UE4/single_image_testing/m'\n",
    "# path_rgb = '/media/atif/0820209220208930/unreal_cv_documentation/unreal_cv_image_processing_for_ML/object_subtraction_for_UE4/single_image_testing/r'\n",
    "\n",
    "#path_mask = '/media/atif/0820209220208930/save_image_ai/object_subtraction_for_UE4/image_AI/mask_calgonit'\n",
    "#path_rgb = '/media/atif/0820209220208930/save_image_ai/object_subtraction_for_UE4/image_AI/rgb_calgonit'\n",
    "\n",
    "path_mask='F:/save_image_ai/object_subtraction_for_UE4/image_AI/mask_calgonit'\n",
    "path_rgb='F:/save_image_ai/object_subtraction_for_UE4/image_AI/rgb_calgonit'\n",
    "\n",
    "# img_path_mask = sorted(glob.glob(path_mask+ '/*.png'))\n",
    "# img_path_rgb = sorted(glob.glob(path_rgb+ '/*.png'))\n",
    "for a,b,image_mask in os.walk(path_mask):\n",
    "    for s in image_mask:\n",
    "#         print('s: ',s)\n",
    "        n=s.split(\".\")\n",
    "#         print('i am n: ',n[0])\n",
    "        mask = path_mask+'/'+s\n",
    "#         print('mask: ',mask)\n",
    "        image_mask2=cv2.imread(mask)\n",
    "        hsv = cv2.cvtColor(image_mask2, cv2.COLOR_BGR2HSV)\n",
    "        hsv_channels = cv2.split(hsv)\n",
    "\n",
    "        _,thresh=cv2.threshold(hsv_channels[1],140,255,cv2.THRESH_BINARY_INV)\n",
    "        im2, contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cv2.drawContours(image_mask2, contours, 0, (0,255,0), 3)\n",
    "        cnt = contours[0]\n",
    "#         cnt_table = contours[0]\n",
    "        x,y,w,h = cv2.boundingRect(cnt)\n",
    "#         print('here the val: ',x,\" \",y,\" \",x+w,\" \",y+h)\n",
    "        \n",
    "        for c,d,image_rgb in os.walk(path_rgb):\n",
    "            for t in image_rgb:\n",
    "                m=t.split('.')\n",
    "                if int(n[0])== int(m[0]):\n",
    "                    rgb = path_rgb+'/'+t\n",
    "                    image_rgb2=cv2.imread(rgb)\n",
    "                    image_rgb_rec=cv2.rectangle(image_rgb2,(x,y),(x+w,y+h),(255,255,255),1)\n",
    "#                     crop_img = image_rgb_rec[y:y+h, x:x+w]\n",
    "#                     print(num,' ',m[0])\n",
    "#                     print(m[0],' here the val: ',x,\" \",y,\" \",x+w,\" \",y+h)\n",
    "#                     f = open(\"/media/atif/0820209220208930/unreal_cv_documentation/ignore_from_git/YOLO_learning/YOLO-Annotation-Tool/Labels/005/\"+'calgonit_'+str(m[0])+'.txt', 'w')\n",
    "                    f = open(\"E:/005/\"+'calgonit_'+str(m[0])+'.txt', 'w')\n",
    "#                     f.write('005'+\"\\n\")\n",
    "                    f.write('00'+bi+\"\\n\")\n",
    "                    f.write(str(x)+' ')\n",
    "                    f.write(str(y)+' ')\n",
    "                    f.write(str(x+w)+' ')\n",
    "                    f.write(str(y+h)+' ')\n",
    "                    f.close()\n",
    "                else:\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try to solve 'list index out of range' and 'no contour in the image' problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BGR to GRAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "objet_list=['Chair_15','SM_CalgonitFinish_2','SM_SomatClassic_2','SM_CalgonitFinishKlarspueler_2','SM_CalgonitFinishMaschinenpfleger_5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here length of contours:  1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "#SM_Couch_5\n",
    "# Chair_15\n",
    "# objet_list=['Chair_15','SM_CalgonitFinish_2','SM_SomatClassic_2','SM_CalgonitFinishKlarspueler_2','SM_CalgonitFinishMaschinenpfleger_5']\n",
    "# n=-2\n",
    "# print(objet_list[n])\n",
    "# rgb=cv2.imread('F:/unreal_cv_documentation/my_dir/'+objet_list[n]+'/2_'+objet_list[n]+'_0_85_lit.png')\n",
    "# mask = cv2.imread('F:/unreal_cv_documentation/my_dir/'+objet_list[n]+'/2_'+objet_list[n]+'_0_85_object_mask.png')\n",
    "\n",
    "rgb = cv2.imread('F:/unreal_cv_documentation/my_dir/SM_SomatClassic_2/1_SM_SomatClassic_2_0_90_lit.png')\n",
    "mask = cv2.imread('F:/unreal_cv_documentation/my_dir/SM_SomatClassic_2/1_SM_SomatClassic_2_0_90_object_mask.png')\n",
    "\n",
    "# cv2.imshow('mask_window',mask)\n",
    "\n",
    "# mask_copy=mask.copy()\n",
    "\n",
    "imgray=cv2.cvtColor(mask,cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('gray',imgray)\n",
    "# imgray = cv2.medianBlur(mask,5)\n",
    "# cv2.imshow('median',imgray)\n",
    "\n",
    "# canny = cv2.Canny(imgray, 130, 255, 1)\n",
    "# kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "# thresh = cv2.dilate(canny, kernel, iterations=1)\n",
    "\n",
    "# cv2.imshow('canny',canny)\n",
    "# cv2.imshow('dilate',thresh)\n",
    "\n",
    "# imgray = cv2.Canny(mask,100,200)\n",
    "# cv2.imshow('canny',edges)\n",
    "\n",
    "ret,thresh = cv2.threshold(imgray,127,255,1)\n",
    "# ret,thresh = cv2.threshold(imgray,127,255,cv2.THRESH_BINARY_INV)\n",
    "# thresh = cv2.adaptiveThreshold(imgray,255,cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY,11,2)\n",
    "# thresh = cv2.adaptiveThreshold(imgray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n",
    "\n",
    "#otsu thresholding\n",
    "# ret2,thresh = cv2.threshold(imgray,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "# blur = cv2.GaussianBlur(imgray,(5,5),0)\n",
    "# ret3,thresh = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "# kernel = cv2.getStructuringElement(cv2.MORPH_CROSS,(3,3))\n",
    "# dilated = cv2.dilate(thresh,kernel,iterations = 13)\n",
    "\n",
    "cv2.imshow('thresh',thresh)\n",
    "\n",
    "image, contours, hierarchy =  cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "# cv2.drawContours(mask,contours,-1,(255,255,255))\n",
    "cv2.imshow('contour_frame_on_mask',image)\n",
    "# print(thresh)\n",
    "if len(contours)>0:\n",
    "    print('here length of contours: ',len(contours))\n",
    "    cnt=contours[0]\n",
    "    x,y,w,h = cv2.boundingRect(cnt)\n",
    "\n",
    "    draw_contour_mask=cv2.rectangle(mask,(x,y),(x+w,y+h),(0,0,0),1) #draw this box on masked image\n",
    "    cv2.imshow('rec_mask',draw_contour_mask)\n",
    "\n",
    "    draw_contour_rgb=cv2.rectangle(rgb,(x,y),(x+w,y+h),(255,255,255),1) #draw this box on rgb image\n",
    "    # cv2.imshow('rec_rgb_chair',draw_contour_rgb)\n",
    "\n",
    "    crop_rgb = draw_contour_rgb[y:y+h, x:x+w] #to crop the applied bounded box\n",
    "    cv2.imshow(\"cropped_chair\", crop_rgb)\n",
    "\n",
    "\n",
    "    if cv2.waitKey() == ord('q'): #press q to close the output image window\n",
    "        cv2.destroyAllWindows()\n",
    "else:\n",
    "    print('Now length of contours: ',len(contours))\n",
    "    pass\n",
    "\n",
    "if cv2.waitKey() == ord('q'): #press q to close the output image window\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BGR to HSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SM_CalgonitFinishKlarspueler_2\n",
      "here length of contour:  1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# objet_list=['Chair_15','SM_CalgonitFinish_2','SM_SomatClassic_2','SM_CalgonitFinishKlarspueler_2']\n",
    "n=-2\n",
    "print(objet_list[n])\n",
    "rgb_1=cv2.imread('F:/unreal_cv_documentation/my_dir/'+objet_list[n]+'/2_'+objet_list[n]+'_0_85_lit.png')\n",
    "mask_1 = cv2.imread('F:/unreal_cv_documentation/my_dir/'+objet_list[n]+'/2_'+objet_list[n]+'_0_85_object_mask.png')\n",
    "\n",
    "# cv2.imshow('mask_frame',mask_1)\n",
    "\n",
    "hsv = cv2.cvtColor(mask_1, cv2.COLOR_BGR2HSV)\n",
    "hsv_channels = cv2.split(hsv)\n",
    "\n",
    "_,thresh=cv2.threshold(hsv_channels[1],127,255,cv2.THRESH_BINARY_INV)\n",
    "# thresh = cv2.adaptiveThreshold(hsv_channels[2],127,cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY,11,2)\n",
    "# thresh = cv2.adaptiveThreshold(hsv_channels[2],255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n",
    "\n",
    "im2, contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cv2.drawContours(mask_1, contours, -1, (0,255,0), 8)\n",
    "cv2.imshow('mask here',mask_1)\n",
    "cv2.imshow('hsv_channel[1]',hsv_channels[1])\n",
    "\n",
    "if len(contours)>0:\n",
    "    print('here length of contour: ',len(contours))\n",
    "    cnt=contours[0]\n",
    "    x,y,w,h = cv2.boundingRect(cnt)\n",
    "\n",
    "    draw_contour_mask_hsv=cv2.rectangle(mask_1,(x,y),(x+w,y+h),(255,255,255),1) #draw this box on masked image\n",
    "#     cv2.imshow('rec_mask',draw_contour_mask_hsv)\n",
    "\n",
    "    draw_contour_rgb_hsv=cv2.rectangle(rgb_1,(x,y),(x+w,y+h),(255,255,255),1) #draw this box on rgb image\n",
    "    # cv2.imshow('rec_rgb_chair',draw_contour_rgb_hsv)\n",
    "\n",
    "    crop_rgb_hsv = draw_contour_rgb_hsv[y:y+h, x:x+w] #to crop the applied bounded box\n",
    "    cv2.imshow(\"cropped_chair\", crop_rgb_hsv) \n",
    "\n",
    "    # cv2.imshow('contour_frame_hsv',mask_1)\n",
    "\n",
    "    if cv2.waitKey() == ord('q'): #press q to close the output image window\n",
    "        cv2.destroyAllWindows()\n",
    "else:\n",
    "    print('length of contours: ',len(contours))\n",
    "    \n",
    "\n",
    "if cv2.waitKey() == ord('q'): #press q to close the output image window\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "def crop_minAreaRect(img, rect):\n",
    "\n",
    "    # rotate img\n",
    "    angle = rect[2]\n",
    "    rows,cols = img.shape[0], img.shape[1]\n",
    "    M = cv2.getRotationMatrix2D((cols/2,rows/2),angle,1)\n",
    "    img_rot = cv2.warpAffine(img,M,(cols,rows))\n",
    "\n",
    "    # rotate bounding box\n",
    "    rect0 = (rect[0], rect[1], 0.0) \n",
    "    box = cv2.boxPoints(rect0)\n",
    "    pts = np.int0(cv2.transform(np.array([box]), M))[0]    \n",
    "    pts[pts < 0] = 0\n",
    "\n",
    "    # crop\n",
    "    img_crop = img_rot[pts[1][1]:pts[0][1], \n",
    "                       pts[1][0]:pts[2][0]]\n",
    "\n",
    "    return img_crop\n",
    "\n",
    "\n",
    "# find contours / rectangle\n",
    "imgray=cv2.cvtColor(mask,cv2.COLOR_BGR2GRAY)\n",
    "_,contours,_ = cv2.findContours(imgray, 1, 1)\n",
    "rect = cv2.minAreaRect(contours[0])\n",
    "\n",
    "# crop\n",
    "img_croped = crop_minAreaRect(rgb, rect)\n",
    "\n",
    "# show\n",
    "import matplotlib.pylab as plt\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(rgb)\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(img_croped)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stack overflow\n",
    "# https://stackoverflow.com/questions/56376996/how-to-crop-object-get-the-location-information-from-an-image-using-opencv-conto/56385149#56385149"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SM_CalgonitFinishKlarspueler_2\n",
      "enter in FOR loop\n",
      "enter in IF condition\n",
      "enter in FOR loop\n",
      "enter in IF condition\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "#SM_Couch_5\n",
    "# Chair_15\n",
    "# objet_list=['Chair_15','SM_CalgonitFinish_2','SM_SomatClassic_2','SM_CalgonitFinishKlarspueler_2']\n",
    "n=-2\n",
    "print(objet_list[n])\n",
    "original_image=cv2.imread('F:/unreal_cv_documentation/my_dir/'+objet_list[n]+'/2_'+objet_list[n]+'_0_85_lit.png')\n",
    "# print(rgb)\n",
    "image = cv2.imread('F:/unreal_cv_documentation/my_dir/'+objet_list[n]+'/2_'+objet_list[n]+'_0_85_object_mask.png')\n",
    "\n",
    "# original_image = cv2.imread(rgb)\n",
    "original_copy = original_image.copy()\n",
    "# image = cv2.imread(mask)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "canny = cv2.Canny(gray, 130, 255, 1)\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "dilate = cv2.dilate(canny, kernel, iterations=1)\n",
    "\n",
    "cnts = cv2.findContours(dilate, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "\n",
    "for c in cnts:\n",
    "    print('enter in FOR loop')\n",
    "    peri = cv2.arcLength(c, True)\n",
    "    approx = cv2.approxPolyDP(c, 0.01 * peri, True)\n",
    "    x,y,w,h = cv2.boundingRect(approx)\n",
    "    aspect_ratio = w / float(h)\n",
    "\n",
    "    if (aspect_ratio >= 0.1 and aspect_ratio <= 1.6):\n",
    "        print('enter in IF condition')\n",
    "        ROI = original_copy[y:y+h, x:x+w]\n",
    "        cv2.rectangle(original_image,(x,y),(x+w,y+h),(0,255,0),3)\n",
    "cv2.imshow('gray',gray)\n",
    "cv2.imshow('canny', canny)\n",
    "cv2.imshow('dilate', dilate)\n",
    "cv2.imshow('original image', original_image)\n",
    "cv2.imshow('ROI', ROI)\n",
    "# cv2.imwrite('F:/unreal_cv_documentation/my_dir/canny.png',canny)\n",
    "# cv2.imwrite('F:/unreal_cv_documentation/my_dir/dilate.png',dilate)\n",
    "# cv2.imwrite('F:/unreal_cv_documentation/my_dir/ROI.png',ROI)\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "if cv2.waitKey() == ord('q'): #press q to close the output image window\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# https://stackoverflow.com/questions/43061143/extract-object-from-the-image-of-a-box-having-object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SM_CalgonitFinishKlarspueler_2\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.1) C:\\Miniconda3\\conda-bld\\opencv-suite_1533128839831\\work\\modules\\imgproc\\src\\color.cpp:11147: error: (-215) scn == 3 || scn == 4 in function cv::cvtColor\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-3fbeb418c0a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# convert to grayscale\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mempty_g\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0mfull_g\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(3.4.1) C:\\Miniconda3\\conda-bld\\opencv-suite_1533128839831\\work\\modules\\imgproc\\src\\color.cpp:11147: error: (-215) scn == 3 || scn == 4 in function cv::cvtColor\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "#SM_Couch_5\n",
    "# Chair_15\n",
    "# objet_list=['Chair_15','SM_CalgonitFinish_2','SM_SomatClassic_2','SM_CalgonitFinishKlarspueler_2']\n",
    "n=-2\n",
    "print(objet_list[n])\n",
    "full=cv2.imread('F:/unreal_cv_documentation/my_dir/'+objet_list[n]+'/2_'+objet_list[n]+'_0_85_lit.png')\n",
    "mask = cv2.imread('F:/unreal_cv_documentation/my_dir/'+objet_list[n]+'/2_'+objet_list[n]+'_0_85_object_mask.png')\n",
    "empty=cv2.imread('F:/unreal_cv_documentation/my_dir/'+objet_list[n]+'/2_env.png')\n",
    "\n",
    "# save color copy for visualization\n",
    "full_c = full.copy()\n",
    "\n",
    "# convert to grayscale\n",
    "empty_g = cv2.cvtColor(empty, cv2.COLOR_BGR2GRAY)\n",
    "full_g = cv2.cvtColor(full, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# blur to account for small camera movement\n",
    "# you could try if maybe different values will maybe\n",
    "# more reliable for broader cases\n",
    "m_1=50\n",
    "n_1=0\n",
    "empty_g = cv2.GaussianBlur(empty_g, (n_1,n_1), m_1)\n",
    "full_g = cv2.GaussianBlur(full_g, (n_1,n_1), m_1)\n",
    "\n",
    "# get the difference between full and empty box\n",
    "diff = full_g - empty_g\n",
    "# cv2.imwrite(\"diff.jpg\", diff)\n",
    "cv2.imshow('diff',diff)\n",
    "\n",
    "# inverse thresholding to change every pixel above 190\n",
    "# to black (that means without the bag)\n",
    "_, diff_th = cv2.threshold(diff, 127, 255,0)\n",
    "# cv2.imwrite(\"diff_th.jpg\", diff_th)\n",
    "cv2.imshow('diff_th',diff_th)\n",
    "\n",
    "ret,thresh = cv2.threshold(diff,127,255,0)\n",
    "\n",
    "# combine the difference image and the inverse threshold\n",
    "# will give us just the bag\n",
    "bag = cv2.bitwise_and(diff, diff_th, None)\n",
    "# cv2.imwrite(\"just_the_bag.jpg\", bag)\n",
    "cv2.imshow('object',bag)\n",
    "\n",
    "\n",
    "image_11, contours, hierarchy =  cv2.findContours(diff_th,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "cv2.drawContours(mask,contours,-1,(255,255,255))\n",
    "cv2.imshow('contour_frame_on_mask',image_11)\n",
    "# print(thresh)\n",
    "if len(contours)>0:\n",
    "    print('here length of contours: ',len(contours))\n",
    "    cnt=contours[0]\n",
    "    print(cnt.shape)\n",
    "    x,y,w,h = cv2.boundingRect(cnt)\n",
    "\n",
    "    draw_contour_mask=cv2.rectangle(mask,(x,y),(x+w,y+h),(0,0,0),1) #draw this box on masked image\n",
    "    cv2.imshow('rec_mask',draw_contour_mask)\n",
    "\n",
    "    draw_contour_rgb=cv2.rectangle(full,(x,y),(x+w,y+h),(0,0,0),10) #draw this box on rgb image\n",
    "#     cv2.imshow('rec_rgb',draw_contour_rgb)\n",
    "\n",
    "    crop_rgb = draw_contour_rgb[y:y+h, x:x+w] #to crop the applied bounded box\n",
    "    cv2.imshow(\"cropped_object\", crop_rgb)\n",
    "\n",
    "\n",
    "    if cv2.waitKey() == ord('q'): #press q to close the output image window\n",
    "        cv2.destroyAllWindows()\n",
    "else:\n",
    "    print('Now length of contours: ',len(contours))\n",
    "    pass\n",
    "\n",
    "if cv2.waitKey() == ord('q'): #press q to close the output image window\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SM_CalgonitFinishKlarspueler_2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "#SM_Couch_5\n",
    "# Chair_15\n",
    "# objet_list=['Chair_15','SM_Couch_5','SM_CalgonitFinish_2','SM_Rock_2','SM_SomatClassic_2']\n",
    "n=-2\n",
    "print(objet_list[n])\n",
    "im=cv2.imread('F:/unreal_cv_documentation/my_dir/'+objet_list[n]+'/1_'+objet_list[n]+'_0_90_lit.png',cv2.IMREAD_GRAYSCALE)\n",
    "mask = cv2.imread('F:/unreal_cv_documentation/my_dir/'+objet_list[n]+'/1_'+objet_list[n]+'_0_90_object_mask.png')\n",
    "# Set up the detector with default parameters.\n",
    "# Setup SimpleBlobDetector parameters.\n",
    "params = cv2.SimpleBlobDetector_Params()\n",
    "\n",
    "# Change thresholds\n",
    "params.minThreshold = 127\n",
    "params.maxThreshold = 255\n",
    "\n",
    "\n",
    "# Filter by Area.\n",
    "params.filterByArea = True\n",
    "params.minArea = 1500\n",
    "\n",
    "# Filter by Circularity\n",
    "params.filterByCircularity = True\n",
    "params.minCircularity = 0.1\n",
    "\n",
    "# Filter by Convexity\n",
    "params.filterByConvexity = True\n",
    "params.minConvexity = 0.87\n",
    "    \n",
    "# Filter by Inertia\n",
    "params.filterByInertia = True\n",
    "params.minInertiaRatio = 0.01\n",
    "\n",
    "# Create a detector with the parameters\n",
    "ver = (cv2.__version__).split('.')\n",
    "if int(ver[0]) < 3 :\n",
    "\tdetector = cv2.SimpleBlobDetector(params)\n",
    "else : \n",
    "\tdetector = cv2.SimpleBlobDetector_create(params)\n",
    "\n",
    "\n",
    "# Detect blobs.\n",
    "keypoints = detector.detect(im)\n",
    "\n",
    "# Draw detected blobs as red circles.\n",
    "# cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS ensures\n",
    "# the size of the circle corresponds to the size of blob\n",
    "\n",
    "im_with_keypoints = cv2.drawKeypoints(im, keypoints, np.array([]), (0,0,255), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "# Show blobs\n",
    "cv2.imshow(\"Keypoints\", im_with_keypoints)\n",
    "\n",
    "\n",
    "if cv2.waitKey() == ord('q'): #press q to close the output image window\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# operation with image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "#SM_Couch_5\n",
    "# Chair_15\n",
    "# objet_list=['Chair_15','SM_CalgonitFinish_2','SM_SomatClassic_2','SM_CalgonitFinishKlarspueler_2','SM_CalgonitFinishMaschinenpfleger_5']\n",
    "n=0\n",
    "print(objet_list[n])\n",
    "rgb=cv2.imread('F:/unreal_cv_documentation/my_dir/'+objet_list[n]+'/1_'+objet_list[n]+'_0_90_lit.png')\n",
    "mask = cv2.imread('F:/unreal_cv_documentation/my_dir/'+objet_list[n]+'/1_'+objet_list[n]+'_0_90_object_mask.png')\n",
    "empty=cv2.imread('F:/unreal_cv_documentation/my_dir/'+objet_list[n]+'/1_env.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(rgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('rgb',rgb)\n",
    "r=rgb - empty\n",
    "cv2.imshow('r',r)\n",
    "\n",
    "if cv2.waitKey() == ord('q'): #press q to close the output image window\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rgb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_bw = cv2.cvtColor(rgb, cv2.COLOR_BGR2GRAY)\n",
    "empty_bw = cv2.cvtColor(empty, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "print(rgb_bw.shape)\n",
    "print(empty_bw.shape)\n",
    "\n",
    "# cv2.imshow('rgb_bw',rgb_bw)\n",
    "# cv2.imshow('empty_bw',empty_bw)\n",
    "\n",
    "if cv2.waitKey() == ord('q'): #press q to close the output image window\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rgb_bw.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=[]\n",
    "print(type(A))\n",
    "A=np.array(A)\n",
    "print(type(A))\n",
    "for i in rgb_bw:\n",
    "    for j in empty_bw:\n",
    "        if i != j:\n",
    "            A=np.append(i)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B=[]\n",
    "C=np.array(B)\n",
    "for i,index_1 in enumerate(rgb_bw):\n",
    "    for k in i:\n",
    "        print(index_1)\n",
    "#         np.append(C,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cv2.imshow('C',E)\n",
    "\n",
    "if cv2.waitKey() == ord('q'): #press q to close the output image window\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(C.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E = np.reshape(C, (-1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rgb_bw.shape)\n",
    "print(rgb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rgb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D=np.zeros((rgb_bw.shape[0],rgb_bw.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in rgb_bw:\n",
    "    for k in empty_bw:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "S=np.random.rand(1,7)\n",
    "print(S.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "## Read\n",
    "img = cv2.imread('F:/unreal_cv_documentation/my_crop/1_SM_CalgonitFinishKlarspueler_2_0_90_lit.png')\n",
    "\n",
    "## convert to hsv\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "mask_im = cv2.imread('F:/unreal_cv_documentation/my_crop/1_SM_CalgonitFinishKlarspueler_2_0_90_object_mask.png')\n",
    "## mask of green (36,0,0) ~ (70, 255,255)\n",
    "mask1 = cv2.inRange(hsv, (0, 100, 100), (20, 255,255))\n",
    "\n",
    "## mask o yellow (15,0,0) ~ (36, 255, 255)\n",
    "mask2 = cv2.inRange(hsv, (15,0,0), (36, 255, 255))\n",
    "\n",
    "## final mask and masked\n",
    "mask = cv2.bitwise_or(mask1, mask2)\n",
    "target = cv2.bitwise_and(img,img, mask=mask)\n",
    "cv2.imshow('target',target)\n",
    "\n",
    "# cv2.imwrite(\"target.png\", target)\n",
    "\n",
    "if cv2.waitKey() == ord('q'): #press q to close the output image window\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
